{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4a08692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import Loader\n",
    "import tensorflow as tf\n",
    "import Transformer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "#use for dark mode\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0072d151",
   "metadata": {},
   "source": [
    "# W/O PCA DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4c608dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2717, 210)\n",
      "0 \b:\t docking_score_max \t [0.54137366 1.19078303 1.51548771]\n",
      "1 \b:\t fusion_score_max \t [0.38503803 1.38435903 0.75411238]\n",
      "2 \b:\t maxestateindex \t [0.53662893 0.59213859 0.87885812]\n",
      "3 \b:\t minestateindex \t [0.41512156 0.32720124 0.25886781]\n",
      "4 \b:\t maxabsestateindex \t [0.53662893 0.59213859 0.87885812]\n",
      "5 \b:\t minabsestateindex \t [-0.54759767 -0.75333746 -0.54125143]\n",
      "6 \b:\t qed \t [-0.0384085  -0.98114022 -0.64268662]\n",
      "7 \b:\t molwt \t [0.0205034  0.59591013 0.62484715]\n",
      "8 \b:\t heavyatommolwt \t [-0.04414949  0.60039371  0.65886811]\n",
      "9 \b:\t exactmolwt \t [0.02268469 0.59813693 0.62320799]\n",
      "10 \b:\t numvalenceelectrons \t [0.19907627 0.67184484 0.54290795]\n",
      "11 \b:\t numradicalelectrons \t [0. 0. 0.]\n",
      "12 \b:\t maxpartialcharge \t [-0.01918824 -0.01918824 -0.01918824]\n",
      "13 \b:\t minpartialcharge \t [-0.48187808 -1.05673424 -0.88605919]\n",
      "14 \b:\t maxabspartialcharge \t [-0.01918824 -0.01918824 -0.01918824]\n",
      "15 \b:\t minabspartialcharge \t [ 0.14395419  0.08354775 -0.71162518]\n",
      "16 \b:\t fpdensitymorgan1 \t [-0.50911309 -0.22651605  0.41162914]\n",
      "17 \b:\t fpdensitymorgan2 \t [-0.363915    0.41799135  0.97136382]\n",
      "18 \b:\t fpdensitymorgan3 \t [-0.56394946  0.60323905  1.33685689]\n",
      "19 \b:\t bcut2d_mwhi \t [-1.11208043 -0.86696715  0.56425094]\n",
      "20 \b:\t bcut2d_mwlow \t [-0.19888022 -0.19267649 -0.56564145]\n",
      "21 \b:\t bcut2d_chghi \t [0.14903697 0.09185018 0.85720199]\n",
      "22 \b:\t bcut2d_chglo \t [-0.40254342 -0.34988073 -0.92763804]\n",
      "23 \b:\t bcut2d_logphi \t [-0.09137252  0.02291326  0.63978498]\n",
      "24 \b:\t bcut2d_logplow \t [-0.28136705 -0.11588314 -0.39077963]\n",
      "25 \b:\t bcut2d_mrhi \t [-0.6351105  -0.76815047 -0.40189062]\n",
      "26 \b:\t bcut2d_mrlow \t [-0.21540946 -0.22812482 -0.29391998]\n",
      "27 \b:\t balabanj \t [ 0.19109143 -0.42208302 -0.65425736]\n",
      "28 \b:\t bertzct \t [-0.077233    0.97271408  1.11362918]\n",
      "29 \b:\t chi0 \t [0.19702979 0.69500907 0.51971027]\n",
      "30 \b:\t chi0n \t [0.44043609 0.70424791 0.54700423]\n",
      "31 \b:\t chi0v \t [0.29644396 0.56242937 0.55658982]\n",
      "32 \b:\t chi1 \t [0.2545304  0.92175523 0.80672674]\n",
      "33 \b:\t chi1n \t [0.48168534 0.8346414  0.72692135]\n",
      "34 \b:\t chi1v \t [0.24013305 0.58132471 0.59676825]\n",
      "35 \b:\t chi2n \t [0.6394732  0.52656135 0.57787384]\n",
      "36 \b:\t chi2v \t [0.31165663 0.20600745 0.4059322 ]\n",
      "37 \b:\t chi3n \t [0.36034769 0.72131011 0.97936558]\n",
      "38 \b:\t chi3v \t [0.01881458 0.34498877 0.68943116]\n",
      "39 \b:\t chi4n \t [0.31883151 0.78433295 1.10892973]\n",
      "40 \b:\t chi4v \t [-0.03150539  0.38208627  0.77460652]\n",
      "41 \b:\t hallkieralpha \t [-0.38092601 -1.47634458 -0.97558181]\n",
      "42 \b:\t ipc \t [-0.01922525 -0.01922524 -0.01922524]\n",
      "43 \b:\t kappa1 \t [0.16135053 0.5200225  0.25376382]\n",
      "44 \b:\t kappa2 \t [0.21365399 0.73158981 0.15640408]\n",
      "45 \b:\t kappa3 \t [ 0.05588714  0.31976885 -0.37506873]\n",
      "46 \b:\t labuteasa \t [0.23578153 0.75072696 0.71484292]\n",
      "47 \b:\t peoe_vsa1 \t [-0.65999608  0.36444574 -0.12562018]\n",
      "48 \b:\t peoe_vsa10 \t [-0.50537606  0.73314742  0.14082874]\n",
      "49 \b:\t peoe_vsa11 \t [0.36448502 0.36448502 0.37523964]\n",
      "50 \b:\t peoe_vsa12 \t [-0.41418777 -0.41418777  0.48986778]\n",
      "51 \b:\t peoe_vsa13 \t [ 0.56273059  0.56273059 -0.87926906]\n",
      "52 \b:\t peoe_vsa14 \t [-0.35462348 -0.35462348 -0.35462348]\n",
      "53 \b:\t peoe_vsa2 \t [0.97033906 0.28039974 0.99832747]\n",
      "54 \b:\t peoe_vsa3 \t [-0.91055348 -0.15616792 -0.05417854]\n",
      "55 \b:\t peoe_vsa4 \t [-0.58337495 -0.58337495  0.40487761]\n",
      "56 \b:\t peoe_vsa5 \t [-0.36761008 -0.36761008 -0.36761008]\n",
      "57 \b:\t peoe_vsa6 \t [ 1.14959926 -0.47054782  0.08278505]\n",
      "58 \b:\t peoe_vsa7 \t [ 0.69405265  2.45130666 -0.25080846]\n",
      "59 \b:\t peoe_vsa8 \t [0.05403157 0.08106155 1.2847362 ]\n",
      "60 \b:\t peoe_vsa9 \t [-0.94952423 -0.34428163  1.24078462]\n",
      "61 \b:\t smr_vsa1 \t [-0.4300408   0.38466099 -0.40261409]\n",
      "62 \b:\t smr_vsa10 \t [-1.07852913 -1.50799791  0.61094143]\n",
      "63 \b:\t smr_vsa2 \t [-0.44208749 -0.44208749 -0.44208749]\n",
      "64 \b:\t smr_vsa3 \t [-0.46462607  0.19721188  1.52963151]\n",
      "65 \b:\t smr_vsa4 \t [-0.66235225 -0.66235225 -0.66235225]\n",
      "66 \b:\t smr_vsa5 \t [1.08516772 0.22912559 0.19146969]\n",
      "67 \b:\t smr_vsa6 \t [-0.97301202 -0.85094991  0.03389151]\n",
      "68 \b:\t smr_vsa7 \t [0.94849412 2.25914627 0.7033593 ]\n",
      "69 \b:\t smr_vsa8 \t [0. 0. 0.]\n",
      "70 \b:\t smr_vsa9 \t [-0.72051056  0.12733176  0.12733176]\n",
      "71 \b:\t slogp_vsa1 \t [-0.21229402 -0.92217507 -0.23591564]\n",
      "72 \b:\t slogp_vsa10 \t [-0.16657469 -0.35052351 -0.16657469]\n",
      "73 \b:\t slogp_vsa11 \t [-0.51939     0.61122274  0.61122274]\n",
      "74 \b:\t slogp_vsa12 \t [-0.94542938 -0.94542938  0.4134198 ]\n",
      "75 \b:\t slogp_vsa2 \t [-1.01825492 -0.53021407  0.2444625 ]\n",
      "76 \b:\t slogp_vsa3 \t [-0.59549488  1.42278422 -0.12096543]\n",
      "77 \b:\t slogp_vsa4 \t [-0.85723663 -0.22025479 -0.85723663]\n",
      "78 \b:\t slogp_vsa5 \t [1.86663095 0.90062619 0.58108215]\n",
      "79 \b:\t slogp_vsa6 \t [1.08163472 1.61654054 0.62226779]\n",
      "80 \b:\t slogp_vsa7 \t [-0.76815301 -0.76815301  0.83399904]\n",
      "81 \b:\t slogp_vsa8 \t [-0.88725882 -0.88725882  0.54311791]\n",
      "82 \b:\t slogp_vsa9 \t [0. 0. 0.]\n",
      "83 \b:\t tpsa \t [-0.54158797 -0.0617485   0.35167721]\n",
      "84 \b:\t estate_vsa1 \t [-0.66860477 -0.09844125 -0.6988567 ]\n",
      "85 \b:\t estate_vsa10 \t [-0.63166701  0.29545467 -0.63166701]\n",
      "86 \b:\t estate_vsa11 \t [-0.08953768 -0.08953768 -0.08953768]\n",
      "87 \b:\t estate_vsa2 \t [0.57302719 0.6817352  0.19987001]\n",
      "88 \b:\t estate_vsa3 \t [-0.88305414 -0.44574993  1.62879986]\n",
      "89 \b:\t estate_vsa4 \t [0.58645099 1.26896163 0.51211914]\n",
      "90 \b:\t estate_vsa5 \t [ 0.47213678  0.9133176  -0.39730664]\n",
      "91 \b:\t estate_vsa6 \t [0.62514237 2.19960446 0.62514237]\n",
      "92 \b:\t estate_vsa7 \t [ 0.28547758 -0.90945353  0.22803644]\n",
      "93 \b:\t estate_vsa8 \t [ 0.96704769 -0.63427623  0.53610549]\n",
      "94 \b:\t estate_vsa9 \t [-0.75746407 -0.75746407  0.64512437]\n",
      "95 \b:\t vsa_estate1 \t [-0.54984999  0.08796957 -0.52835966]\n",
      "96 \b:\t vsa_estate10 \t [-0.86716712 -0.86716712  0.78259182]\n",
      "97 \b:\t vsa_estate2 \t [0.10631672 0.10572753 0.41820921]\n",
      "98 \b:\t vsa_estate3 \t [-0.71044183  0.39044316  0.23932436]\n",
      "99 \b:\t vsa_estate4 \t [ 0.2641566   1.00124214 -0.77434619]\n",
      "100 \b:\t vsa_estate5 \t [ 0.22048148 -0.16925985  0.88888789]\n",
      "101 \b:\t vsa_estate6 \t [0.53082322 0.75058932 0.33482897]\n",
      "102 \b:\t vsa_estate7 \t [1.99185199 1.61161785 1.36792289]\n",
      "103 \b:\t vsa_estate8 \t [ 0.97832402 -0.86583946 -0.67630273]\n",
      "104 \b:\t vsa_estate9 \t [0.14793483 0.14793483 0.14793483]\n",
      "105 \b:\t fractioncsp3 \t [ 0.18903229 -0.50427113 -0.17835927]\n",
      "106 \b:\t heavyatomcount \t [0.23302885 0.82685681 0.70809122]\n",
      "107 \b:\t nhohcount \t [-0.68073424 -0.04558488 -0.04558488]\n",
      "108 \b:\t nocount \t [-0.48898249 -0.12658057  0.59822326]\n",
      "109 \b:\t numaliphaticcarbocycles \t [ 0.98627293  0.98627293 -0.52172007]\n",
      "110 \b:\t numaliphaticheterocycles \t [-1.22063861 -1.22063861  1.43572912]\n",
      "111 \b:\t numaliphaticrings \t [-0.24772125 -0.24772125  0.6870824 ]\n",
      "112 \b:\t numaromaticcarbocycles \t [-0.6783444   0.54061178  0.54061178]\n",
      "113 \b:\t numaromaticheterocycles \t [1.39887527 1.39887527 1.39887527]\n",
      "114 \b:\t numaromaticrings \t [0.4552267  1.34955132 1.34955132]\n",
      "115 \b:\t numhacceptors \t [-0.58482501 -0.12624794  0.33232913]\n",
      "116 \b:\t numhdonors \t [-0.66911996  0.00847934  0.00847934]\n",
      "117 \b:\t numheteroatoms \t [-0.88661375 -0.23940001  0.40781374]\n",
      "118 \b:\t numrotatablebonds \t [-0.15276249  0.65369285 -0.42158094]\n",
      "119 \b:\t numsaturatedcarbocycles \t [ 1.12024679 -0.50306549 -0.50306549]\n",
      "120 \b:\t numsaturatedheterocycles \t [-0.89820391 -0.89820391  0.51817451]\n",
      "121 \b:\t numsaturatedrings \t [ 0.05280617 -0.89110418  0.05280617]\n",
      "122 \b:\t ringcount \t [0.20108179 1.02512286 1.84916394]\n",
      "123 \b:\t mollogp \t [1.40621811 1.01694966 0.82388788]\n",
      "124 \b:\t molmr \t [0.38907434 0.74537388 0.72874471]\n",
      "125 \b:\t fr_al_coo \t [-0.14182281 -0.14182281 -0.14182281]\n",
      "126 \b:\t fr_al_oh \t [-0.24811414 -0.24811414 -0.24811414]\n",
      "127 \b:\t fr_al_oh_notert \t [-0.224494 -0.224494 -0.224494]\n",
      "128 \b:\t fr_arn \t [-0.14045436 -0.14045436 -0.14045436]\n",
      "129 \b:\t fr_ar_coo \t [-0.09144844 -0.09144844 -0.09144844]\n",
      "130 \b:\t fr_ar_n \t [-0.13084461 -0.13084461  2.39644065]\n",
      "131 \b:\t fr_ar_nh \t [-0.45135745 -0.45135745  1.96745555]\n",
      "132 \b:\t fr_ar_oh \t [-0.15570102  1.95949728 -0.15570102]\n",
      "133 \b:\t fr_coo \t [-0.16913534 -0.16913534 -0.16913534]\n",
      "134 \b:\t fr_coo2 \t [-0.16913534 -0.16913534 -0.16913534]\n",
      "135 \b:\t fr_c_o \t [-0.004383 -0.004383 -0.004383]\n",
      "136 \b:\t fr_c_o_nocoo \t [0.0189983 0.0189983 0.0189983]\n",
      "137 \b:\t fr_c_s \t [-0.0512499 -0.0512499 -0.0512499]\n",
      "138 \b:\t fr_hoccn \t [-0.13552054 -0.13552054 -0.13552054]\n",
      "139 \b:\t fr_imine \t [-0.08115909 -0.08115909 -0.08115909]\n",
      "140 \b:\t fr_nh0 \t [0.03784601 0.03784601 1.4180825 ]\n",
      "141 \b:\t fr_nh1 \t [-0.50740714 -0.50740714  0.28218347]\n",
      "142 \b:\t fr_nh2 \t [-0.28217397 -0.28217397 -0.28217397]\n",
      "143 \b:\t fr_n_o \t [-0.06016624 -0.06016624 -0.06016624]\n",
      "144 \b:\t fr_ndealkylation1 \t [-0.27084469 -0.27084469 -0.27084469]\n",
      "145 \b:\t fr_ndealkylation2 \t [-0.42012329 -0.42012329  2.13923763]\n",
      "146 \b:\t fr_nhpyrrole \t [-0.45135745 -0.45135745  1.96745555]\n",
      "147 \b:\t fr_sh \t [-0.04859116 -0.04859116 -0.04859116]\n",
      "148 \b:\t fr_aldehyde \t [-0.23043605 -0.23043605 -0.23043605]\n",
      "149 \b:\t fr_alkyl_carbamate \t [-0.31529781 -0.31529781 -0.31529781]\n",
      "150 \b:\t fr_alkyl_halide \t [-0.31575811 -0.31575811 -0.31575811]\n",
      "151 \b:\t fr_allylic_oxid \t [-0.10444389 -0.10444389 -0.10444389]\n",
      "152 \b:\t fr_amide \t [0.18203812 0.18203812 0.18203812]\n",
      "153 \b:\t fr_amidine \t [-0.06825741 -0.06825741 -0.06825741]\n",
      "154 \b:\t fr_aniline \t [ 0.42332651 -0.89266677  0.42332651]\n",
      "155 \b:\t fr_aryl_methyl \t [-0.4058757   1.45690178 -0.4058757 ]\n",
      "156 \b:\t fr_azide \t [0. 0. 0.]\n",
      "157 \b:\t fr_azo \t [0. 0. 0.]\n",
      "158 \b:\t fr_barbitur \t [-0.01918824 -0.01918824 -0.01918824]\n",
      "159 \b:\t fr_benzene \t [-0.6775045   0.54074813  0.54074813]\n",
      "160 \b:\t fr_benzodiazepine \t [-0.02714126 -0.02714126 -0.02714126]\n",
      "161 \b:\t fr_bicyclic \t [-0.8694946   0.06316108  0.99581676]\n",
      "162 \b:\t fr_diazo \t [0. 0. 0.]\n",
      "163 \b:\t fr_dihydropyridine \t [-0.05546661 -0.05546661 -0.05546661]\n",
      "164 \b:\t fr_epoxide \t [-0.03839769 -0.03839769 -0.03839769]\n",
      "165 \b:\t fr_ester \t [-0.21049491 -0.21049491 -0.21049491]\n",
      "166 \b:\t fr_ether \t [-0.71635844 -0.71635844  0.27314124]\n",
      "167 \b:\t fr_furan \t [ 5.97636729  5.97636729 -0.16268372]\n",
      "168 \b:\t fr_guanido \t [-0.0446256 -0.0446256 -0.0446256]\n",
      "169 \b:\t fr_halogen \t [-0.76728591 -0.01738813 -0.01738813]\n",
      "170 \b:\t fr_hdrzine \t [-0.10386862 -0.10386862 -0.10386862]\n",
      "171 \b:\t fr_hdrzone \t [-0.06616345 -0.06616345 -0.06616345]\n",
      "172 \b:\t fr_imidazole \t [-0.21632971 -0.21632971 -0.21632971]\n",
      "173 \b:\t fr_imide \t [-0.12987181 -0.12987181 -0.12987181]\n",
      "174 \b:\t fr_isocyan \t [0. 0. 0.]\n",
      "175 \b:\t fr_isothiocyan \t [0. 0. 0.]\n",
      "176 \b:\t fr_ketone \t [-0.31218377 -0.31218377 -0.31218377]\n",
      "177 \b:\t fr_ketone_topliss \t [-0.30283755 -0.30283755 -0.30283755]\n",
      "178 \b:\t fr_lactam \t [-0.06077932 -0.06077932 -0.06077932]\n",
      "179 \b:\t fr_lactone \t [-0.06558369 -0.06558369 -0.06558369]\n",
      "180 \b:\t fr_methoxy \t [-0.41986264 -0.41986264 -0.41986264]\n",
      "181 \b:\t fr_morpholine \t [-0.18254857 -0.18254857 -0.18254857]\n",
      "182 \b:\t fr_nitrile \t [-0.43829798 -0.43829798 -0.43829798]\n",
      "183 \b:\t fr_nitro \t [-0.11749881 -0.11749881 -0.11749881]\n",
      "184 \b:\t fr_nitro_arom \t [-0.10566394 -0.10566394 -0.10566394]\n",
      "185 \b:\t fr_nitro_arom_nonortho \t [-0.09239854 -0.09239854 -0.09239854]\n",
      "186 \b:\t fr_nitroso \t [0. 0. 0.]\n",
      "187 \b:\t fr_oxazole \t [-0.15655607 -0.15655607 -0.15655607]\n",
      "188 \b:\t fr_oxime \t [-0.03839769 -0.03839769 -0.03839769]\n",
      "189 \b:\t fr_para_hydroxylation \t [-0.35910477 -0.35910477 -0.35910477]\n",
      "190 \b:\t fr_phenol \t [-0.14652967  2.04094902 -0.14652967]\n",
      "191 \b:\t fr_phenol_noorthohbond \t [-0.14583587  2.04331363 -0.14583587]\n",
      "192 \b:\t fr_phos_acid \t [-0.02714126 -0.02714126 -0.02714126]\n",
      "193 \b:\t fr_phos_ester \t [-0.02714126 -0.02714126 -0.02714126]\n",
      "194 \b:\t fr_piperdine \t [-0.34945266 -0.34945266  2.63627965]\n",
      "195 \b:\t fr_piperzine \t [-0.29786349 -0.29786349 -0.29786349]\n",
      "196 \b:\t fr_priamide \t [-0.20349306 -0.20349306 -0.20349306]\n",
      "197 \b:\t fr_prisulfonamd \t [0. 0. 0.]\n",
      "198 \b:\t fr_pyridine \t [1.00968262 1.00968262 1.00968262]\n",
      "199 \b:\t fr_quatn \t [-0.1078679 -0.1078679 -0.1078679]\n",
      "200 \b:\t fr_sulfide \t [-0.17681887 -0.17681887 -0.17681887]\n",
      "201 \b:\t fr_sulfonamd \t [-0.369154 -0.369154 -0.369154]\n",
      "202 \b:\t fr_sulfone \t [-0.18546855 -0.18546855 -0.18546855]\n",
      "203 \b:\t fr_term_acetylene \t [-0.06077932 -0.06077932 -0.06077932]\n",
      "204 \b:\t fr_tetrazole \t [-0.10386862 -0.10386862 -0.10386862]\n",
      "205 \b:\t fr_thiazole \t [-0.14706786 -0.14706786 -0.14706786]\n",
      "206 \b:\t fr_thiocyan \t [0. 0. 0.]\n",
      "207 \b:\t fr_thiophene \t [-0.19069575 -0.19069575 -0.19069575]\n",
      "208 \b:\t fr_unbrch_alkane \t [-0.14794553 -0.14794553 -0.14794553]\n",
      "209 \b:\t fr_urea \t [-0.22546464 -0.22546464 -0.22546464]\n"
     ]
    }
   ],
   "source": [
    "compoundsTrain, smilesTrain, labelsTrain, compoundDataTrain, activitiesTrain = Loader.getTrain(defaultValue=0)\n",
    "compoundsTest, smilesTest, labelsTest, compoundDataTest, activitiesTest = Loader.getTest(defaultValue=0)\n",
    "compoundsValidate, smilesValidate, labelsValidate, compoundDataValidate, activitiesValidate = Loader.getValidate(defaultValue=0)\n",
    "\n",
    "labelsMean, trainMean = Transformer.useAverageFD(labelsTrain, compoundDataTrain)\n",
    "_, testMean = Transformer.useAverageFD(labelsTest, compoundDataTest)\n",
    "_, valMean = Transformer.useAverageFD(labelsValidate, compoundDataValidate)\n",
    "\n",
    "labelsMax, trainMax = Transformer.useMaxFD(labelsTrain, compoundDataTrain)\n",
    "_, testMax = Transformer.useMaxFD(labelsTest, compoundDataTest)\n",
    "_, valMax = Transformer.useMaxFD(labelsValidate, compoundDataValidate)\n",
    "\n",
    "#after transformations are done assign data\n",
    "dataLabels = labelsMax\n",
    "trainData = trainMax\n",
    "testData = testMax\n",
    "valData = valMax\n",
    "\n",
    "trainData, testData, valData = Transformer.normalizeData(trainData, testData, valData, newMean=0, newStd=1)\n",
    "\n",
    "print(np.shape(trainData))\n",
    "for i in range(len(dataLabels)):\n",
    "    print(i, \"\\b:\\t\", dataLabels[i], \"\\t\", trainData[0:3,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcaa2e5",
   "metadata": {},
   "source": [
    "# With PCA DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8820bf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bcut2d retention: [0.99364773]\n",
      "\ttotal: 99.36477273412312%\n",
      "chi retention: [0.9541968]\n",
      "\ttotal: 95.41967968597893%\n",
      "paoe retention: [0.31495127 0.19509321 0.1390042  0.08838179 0.07155396 0.04590061\n",
      " 0.03243    0.02673268 0.02402293]\n",
      "\ttotal: 93.80706737004682%\n",
      "smr retention: [0.50634726 0.24568468 0.08792319 0.07435827]\n",
      "\ttotal: 91.43133907840047%\n",
      "slogp retention: [0.44620276 0.22134465 0.15753302 0.04213752 0.03159298 0.02850562]\n",
      "\ttotal: 92.7316547196898%\n",
      "estate_vsa retention: [0.29224011 0.18964809 0.14361318 0.10642656 0.07394495 0.06391846\n",
      " 0.05513575]\n",
      "\ttotal: 92.49271047439824%\n",
      "vsa_estate retention: [0.49255304 0.32866098 0.09719245]\n",
      "\ttotal: 91.84064669216801%\n",
      "fr retention: [0.32153498 0.12578177 0.09944384 0.0570485  0.05494644 0.04503917\n",
      " 0.03646285 0.02896244 0.02597271 0.02289905 0.01957315 0.01726898\n",
      " 0.01514304 0.01174669 0.01137907 0.00991642]\n",
      "\ttotal: 90.31191005387316%\n",
      "(2717, 95)\n",
      "0 \b:\t docking_score_max \t [7.9 8.  8.2]\n",
      "1 \b:\t fusion_score_max \t [4.96869707 5.44580412 5.37892819]\n",
      "2 \b:\t maxestateindex \t [12.08766007 13.99810705 12.74312922]\n",
      "3 \b:\t minestateindex \t [-0.41582625 -0.60769496 -0.13256294]\n",
      "4 \b:\t maxabsestateindex \t [12.08766007 13.99810705 12.74312922]\n",
      "5 \b:\t minabsestateindex \t [0.4136685  0.04075942 0.13256294]\n",
      "6 \b:\t qed \t [0.65449875 0.4831373  0.30609727]\n",
      "7 \b:\t molwt \t [357.171 462.893 458.974]\n",
      "8 \b:\t heavyatommolwt \t [348.099 443.741 439.822]\n",
      "9 \b:\t exactmolwt \t [356.00212101 462.10948277 458.09680991]\n",
      "10 \b:\t numvalenceelectrons \t [108. 166. 158.]\n",
      "11 \b:\t numradicalelectrons \t [0. 0. 0.]\n",
      "12 \b:\t maxpartialcharge \t [0.3232812  0.32518684 0.22835489]\n",
      "13 \b:\t minpartialcharge \t [-0.30660881 -0.49318938 -0.33146038]\n",
      "14 \b:\t maxabspartialcharge \t [0.3232812  0.49318938 0.33146038]\n",
      "15 \b:\t minabspartialcharge \t [0.30660881 0.32518684 0.22835489]\n",
      "16 \b:\t fpdensitymorgan1 \t [1.18181818 1.18181818 1.0625    ]\n",
      "17 \b:\t fpdensitymorgan2 \t [1.95454545 2.03030303 1.9375    ]\n",
      "18 \b:\t fpdensitymorgan3 \t [2.72727273 2.87878788 2.84375   ]\n",
      "19 \b:\t bcut2d_0 \t [50.92674303  6.4164894   6.46738116]\n",
      "20 \b:\t balabanj \t [1.84867265 1.63496821 1.34039856]\n",
      "21 \b:\t bertzct \t [ 897.72960816 1474.05622047 1458.12457476]\n",
      "22 \b:\t chi_0 \t [-15.74921464  -0.78846669  -1.01151447]\n",
      "23 \b:\t hallkieralpha \t [-2.92 -3.91 -3.48]\n",
      "24 \b:\t ipc \t [  161777.37108188 41095031.15588387 27774513.90179397]\n",
      "25 \b:\t kappa1 \t [14.03569782 20.96301115 20.42421185]\n",
      "26 \b:\t kappa2 \t [5.82932803 8.5542844  8.57121926]\n",
      "27 \b:\t kappa3 \t [2.61697206 4.00561783 4.41872446]\n",
      "28 \b:\t labuteasa \t [133.00678336 192.36629085 193.64791886]\n",
      "29 \b:\t paoe_0 \t [-17.3609989   -4.77544678  16.75998943]\n",
      "30 \b:\t paoe_1 \t [  2.6105304  -23.4197482   -7.72125185]\n",
      "31 \b:\t paoe_2 \t [ 25.95236248 -12.96821367  -3.78777043]\n",
      "32 \b:\t paoe_3 \t [ -4.47268858   6.51479523 -13.15261307]\n",
      "33 \b:\t paoe_4 \t [ 4.39381871 15.57557113 13.6003507 ]\n",
      "34 \b:\t paoe_5 \t [1.26963681 4.10178371 1.38058942]\n",
      "35 \b:\t paoe_6 \t [-0.75382057 -3.63787907  4.76174783]\n",
      "36 \b:\t paoe_7 \t [ 0.77649001 -6.22029549 -1.56467533]\n",
      "37 \b:\t paoe_8 \t [0.80779711 2.93536686 0.97185039]\n",
      "38 \b:\t smr_0 \t [-27.43560707 -37.56673511 -39.20197868]\n",
      "39 \b:\t smr_1 \t [-29.39244024  23.4842371   15.03049142]\n",
      "40 \b:\t smr_2 \t [-0.31908092 -5.97708497 12.22256819]\n",
      "41 \b:\t smr_3 \t [-18.65696385  -4.50878466 -32.39642702]\n",
      "42 \b:\t slogp_0 \t [-32.82060612 -29.55059815 -46.67976061]\n",
      "43 \b:\t slogp_1 \t [-24.51009302  12.69112526   6.94424516]\n",
      "44 \b:\t slogp_2 \t [-4.38489743 -4.60709219 -7.09570533]\n",
      "45 \b:\t slogp_3 \t [-4.672245    0.42401801  5.19349487]\n",
      "46 \b:\t slogp_4 \t [2.18792757 3.41501136 5.73569547]\n",
      "47 \b:\t slogp_5 \t [13.59324353 -0.02744423 12.71914035]\n",
      "48 \b:\t tpsa \t [106.49 108.15  66.91]\n",
      "49 \b:\t estate_vsa_0 \t [-20.02463808  -2.29353013 -37.38823929]\n",
      "50 \b:\t estate_vsa_1 \t [-13.89145974  -9.9862294    7.59499416]\n",
      "51 \b:\t estate_vsa_2 \t [  2.13539086 -14.47378562   3.14671934]\n",
      "52 \b:\t estate_vsa_3 \t [-6.82621413  1.47637584  4.15523968]\n",
      "53 \b:\t estate_vsa_4 \t [14.23552562 -4.00331862  4.05570184]\n",
      "54 \b:\t estate_vsa_5 \t [ 2.05923281  4.76857975 20.55468196]\n",
      "55 \b:\t estate_vsa_6 \t [-30.44710755  -1.92038844   0.66221794]\n",
      "56 \b:\t vsa_estate_0 \t [-11.94053562 -14.90245471 -14.19423625]\n",
      "57 \b:\t vsa_estate_1 \t [-20.66363734  12.59265994 -14.20451106]\n",
      "58 \b:\t vsa_estate_2 \t [ 17.2712215  -10.25147755  -0.5176948 ]\n",
      "59 \b:\t fractioncsp3 \t [0.         0.16666667 0.08      ]\n",
      "60 \b:\t heavyatomcount \t [22. 33. 32.]\n",
      "61 \b:\t nhohcount \t [3. 2. 2.]\n",
      "62 \b:\t nocount \t [7. 8. 5.]\n",
      "63 \b:\t numaliphaticcarbocycles \t [0. 0. 0.]\n",
      "64 \b:\t numaliphaticheterocycles \t [0. 1. 0.]\n",
      "65 \b:\t numaliphaticrings \t [0. 1. 0.]\n",
      "66 \b:\t numaromaticcarbocycles \t [2. 2. 3.]\n",
      "67 \b:\t numaromaticheterocycles \t [1. 2. 2.]\n",
      "68 \b:\t numaromaticrings \t [3. 4. 5.]\n",
      "69 \b:\t numhacceptors \t [4. 5. 5.]\n",
      "70 \b:\t numhdonors \t [3. 2. 2.]\n",
      "71 \b:\t numheteroatoms \t [8. 9. 7.]\n",
      "72 \b:\t numrotatablebonds \t [2. 4. 5.]\n",
      "73 \b:\t numsaturatedcarbocycles \t [0. 0. 0.]\n",
      "74 \b:\t numsaturatedheterocycles \t [0. 0. 0.]\n",
      "75 \b:\t numsaturatedrings \t [0. 0. 0.]\n",
      "76 \b:\t ringcount \t [3. 5. 5.]\n",
      "77 \b:\t mollogp \t [3.23608 3.3643  6.73112]\n",
      "78 \b:\t molmr \t [ 85.3871 124.9214 133.1684]\n",
      "79 \b:\t fr_0 \t [-1.22025736 -1.67256086 -1.96905171]\n",
      "80 \b:\t fr_1 \t [1.70591049 0.5272139  0.26152622]\n",
      "81 \b:\t fr_2 \t [-0.95226025 -0.84773146 -0.41072221]\n",
      "82 \b:\t fr_3 \t [-1.61878504 -1.35562338 -1.5882654 ]\n",
      "83 \b:\t fr_4 \t [-0.35405843  0.79253383  1.11977689]\n",
      "84 \b:\t fr_5 \t [1.50892052 2.1504189  0.28846829]\n",
      "85 \b:\t fr_6 \t [-0.65941764  0.19951693 -1.50042437]\n",
      "86 \b:\t fr_7 \t [-0.65570216 -0.33868379 -0.85240613]\n",
      "87 \b:\t fr_8 \t [ 0.5499453  -0.27090861  0.71995371]\n",
      "88 \b:\t fr_9 \t [ 0.54881467 -0.29770903  0.5260514 ]\n",
      "89 \b:\t fr_10 \t [ 0.58430824 -0.15543842 -0.47483102]\n",
      "90 \b:\t fr_11 \t [ 0.58870861 -0.12691673 -0.15867396]\n",
      "91 \b:\t fr_12 \t [ 0.12492131 -0.52861618  0.9340416 ]\n",
      "92 \b:\t fr_13 \t [ 0.60643277  0.73009346 -0.34858636]\n",
      "93 \b:\t fr_14 \t [ 0.10558448 -0.1222001   0.62601798]\n",
      "94 \b:\t fr_15 \t [ 0.02650194 -0.02008317 -0.05093355]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "compoundsTrain, smilesTrain, labelsTrain, compoundDataTrain, activitiesTrain = Loader.getTrain(defaultValue=0)\n",
    "compoundsTest, smilesTest, labelsTest, compoundDataTest, activitiesTest = Loader.getTest(defaultValue=0)\n",
    "compoundsValidate, smilesValidate, labelsValidate, compoundDataValidate, activitiesValidate = Loader.getValidate(defaultValue=0)\n",
    "\n",
    "labelsPCA, trainPCA, testPCA, valPCA = Transformer.applyPCA(labelsTrain,  compoundDataTrain, \n",
    "                                                            compoundDataTest, compoundDataValidate,\n",
    "                                                            endDims=[1,1,9,4,6,7,3,16])\n",
    "\n",
    "labelsMeanPCA, trainMeanPCA = Transformer.useAverageFD(labelsPCA, trainPCA)\n",
    "_, testMeanPCA = Transformer.useAverageFD(labelsPCA, testPCA)\n",
    "_, valMeanPCA = Transformer.useAverageFD(labelsPCA, valPCA)\n",
    "\n",
    "labelsMaxPCA, trainMaxPCA = Transformer.useMaxFD(labelsPCA, trainPCA)\n",
    "_, testMaxPCA = Transformer.useMaxFD(labelsPCA, testPCA)\n",
    "_, valMaxPCA = Transformer.useMaxFD(labelsPCA, valPCA)\n",
    "\n",
    "#after transformations are done assign data\n",
    "dataLabels = labelsMaxPCA\n",
    "trainData = trainMaxPCA\n",
    "testData = testMaxPCA\n",
    "valData = valMaxPCA\n",
    "\n",
    "trainDataPCA, testDataPCA, valDataPCA = Transformer.normalizeData(trainData, testData, valData, newMean=0, newStd=1)\n",
    "\n",
    "classTrain = Transformer.toBinaryClassification(activitiesTrain)\n",
    "classVal = Transformer.toBinaryClassification(activitiesValidate)\n",
    "classTest = Transformer.toBinaryClassification(activitiesTest)\n",
    "#print(trainDataPCA)\n",
    "\n",
    "print(np.shape(trainDataPCA))\n",
    "for i in range(len(dataLabels)):\n",
    "    print(i, \"\\b:\\t\", dataLabels[i], \"\\t\", trainData[0:3,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7999cba",
   "metadata": {},
   "source": [
    "# SVM Soft Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "26db3ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2717, 95)\n",
      "2717\n",
      "Percent:  1.0  Len:  2717 Ein Acc:  0.9536253220463746 Eval Acc:  0.9147058823529411\n",
      "2445\n",
      "Percent:  0.9  Len:  2445 Ein Acc:  0.9529652351738241 Eval Acc:  0.9205882352941176\n",
      "2037\n",
      "Percent:  0.75  Len:  2037 Ein Acc:  0.9479626902307314 Eval Acc:  0.9117647058823529\n",
      "1358\n",
      "Percent:  0.5  Len:  1358 Ein Acc:  0.9543446244477173 Eval Acc:  0.888235294117647\n",
      "679\n",
      "Percent:  0.25  Len:  679 Ein Acc:  0.9499263622974963 Eval Acc:  0.8852941176470588\n",
      "271\n",
      "Percent:  0.1  Len:  271 Ein Acc:  0.948339483394834 Eval Acc:  0.8794117647058823\n"
     ]
    }
   ],
   "source": [
    "classTrain = Transformer.toBinaryClassification(activitiesTrain)\n",
    "classVal = Transformer.toBinaryClassification(activitiesValidate)\n",
    "classTest = Transformer.toBinaryClassification(activitiesTest)\n",
    "x = -.01\n",
    "maxC=10**x\n",
    "clf=svm.SVC(\n",
    "    C=maxC,                          # The regularization parameter\n",
    "    kernel='rbf',                   # The kernel type used \n",
    "    degree=4,                       # Degree of polynomial function \n",
    "    gamma='scale',                  # The kernel coefficient\n",
    "    coef0=0.0,                      # If kernel = 'poly'/'sigmoid'\n",
    "    shrinking=True,                 # To use shrinking heuristic\n",
    "    probability=False,              # Enable probability estimates\n",
    "    tol=0.001,                      # Stopping crierion\n",
    "    cache_size=200,                 # Size of kernel cache\n",
    "    class_weight=None,              # The weight of each class\n",
    "    verbose=False,                  # Enable verbose output\n",
    "    max_iter=- 1,                   # Hard limit on iterations\n",
    "    decision_function_shape='ovr',  # One-vs-rest or one-vs-one\n",
    "    break_ties=False,               # How to handle breaking ties\n",
    "    random_state=None               # Random state of the model\n",
    ")\n",
    "\n",
    "type(trainData)\n",
    "#my_data = np.array(trainData)\n",
    "print(trainData.shape)\n",
    "\n",
    "\n",
    "dataPercents = [1.0,0.9,.75,.5,.25,.1]\n",
    "for percent in dataPercents:\n",
    "    df = pd.DataFrame(trainDataPCA)\n",
    "    df['labels'] = classTrain\n",
    "    #display(df,int(len(df)*.9),len(df)*.9)\n",
    "    samp = int(len(df)*percent)\n",
    "    df = df.sample(n = samp)\n",
    "    print(len(df))\n",
    "    Ytrain = df['labels']\n",
    "    del df['labels']\n",
    "    Xtrain = df.values\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    predictions = clf.predict(Xtrain)\n",
    "    val_pred = clf.predict(valDataPCA)\n",
    "    print(\"Percent: \", percent, \" Len: \", samp, \"Ein Acc: \", accuracy_score(Ytrain, predictions),\n",
    "         \"Eval Acc: \", accuracy_score(classVal, val_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e354b9",
   "metadata": {},
   "source": [
    "# Automated Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7ead8fd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "StagingError",
     "evalue": "in user code:\n\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:756 train_step\n        _minimize(self.distribute_strategy, tape, self.optimizer, loss,\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2722 _minimize\n        gradients = tape.gradient(loss, trainable_variables)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1067 gradient\n        flat_grad = imperative_grad.imperative_grad(\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:71 imperative_grad\n        return pywrap_tfe.TFE_Py_TapeGradient(\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:151 _gradient_function\n        grad_fn = ops._gradient_registry.lookup(op_name)  # pylint: disable=protected-access\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\registry.py:96 lookup\n        raise LookupError(\n\n    LookupError: gradient registry has no entry for: shap_AddN\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStagingError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-ddbd4ea8c008>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'MeanSquaredError'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m history = model.fit(trainData, Transformer.toClassification(activitiesTrain), \n\u001b[0m\u001b[0;32m     21\u001b[0m                     validation_data = (valData, classVal), epochs=3, batch_size=4)\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStagingError\u001b[0m: in user code:\n\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:756 train_step\n        _minimize(self.distribute_strategy, tape, self.optimizer, loss,\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2722 _minimize\n        gradients = tape.gradient(loss, trainable_variables)\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1067 gradient\n        flat_grad = imperative_grad.imperative_grad(\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:71 imperative_grad\n        return pywrap_tfe.TFE_Py_TapeGradient(\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:151 _gradient_function\n        grad_fn = ops._gradient_registry.lookup(op_name)  # pylint: disable=protected-access\n    C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\registry.py:96 lookup\n        raise LookupError(\n\n    LookupError: gradient registry has no entry for: shap_AddN\n"
     ]
    }
   ],
   "source": [
    "def getData():\n",
    "\n",
    "    import csv\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import Loader\n",
    "    import Transformer\n",
    "\n",
    "    compoundsTrain, smilesTrain, labelsTrain, compoundDataTrain, activitiesTrain = Loader.getTrain(defaultValue=0)\n",
    "    compoundsTest, smilesTest, labelsTest, compoundDataTest, activitiesTest = Loader.getTest(defaultValue=0)\n",
    "    compoundsValidate, smilesValidate, labelsValidate, compoundDataValidate, activitiesValidate = Loader.getValidate(defaultValue=0)\n",
    "\n",
    "    labelsPCA, trainPCA, testPCA, valPCA = Transformer.applyPCA(labelsTrain,  compoundDataTrain, \n",
    "                                                                compoundDataTest, compoundDataValidate,\n",
    "                                                                endDims=[1,1,9,4,6,7,3,16])\n",
    "\n",
    "    labelsMeanPCA, trainMeanPCA = Transformer.useAverageFD(labelsPCA, trainPCA)\n",
    "    _, testMeanPCA = Transformer.useAverageFD(labelsPCA, testPCA)\n",
    "    _, valMeanPCA = Transformer.useAverageFD(labelsPCA, valPCA)\n",
    "\n",
    "    labelsMaxPCA, trainMaxPCA = Transformer.useMaxFD(labelsPCA, trainPCA)\n",
    "    _, testMaxPCA = Transformer.useMaxFD(labelsPCA, testPCA)\n",
    "    _, valMaxPCA = Transformer.useMaxFD(labelsPCA, valPCA)\n",
    "\n",
    "    #after transformations are done assign data\n",
    "    dataLabels = labelsMaxPCA\n",
    "    trainData = trainMaxPCA\n",
    "    testData = testMaxPCA\n",
    "    valData = valMaxPCA\n",
    "\n",
    "    trainDataPCA, testDataPCA, valDataPCA = Transformer.normalizeData(trainData, testData, valData, newMean=0, newStd=1)\n",
    "\n",
    "    classTrain = Transformer.toBinaryClassification(activitiesTrain)\n",
    "    classVal = Transformer.toBinaryClassification(activitiesValidate)\n",
    "    classTest = Transformer.toBinaryClassification(activitiesTest)\n",
    "    \n",
    "    return  trainDataPCA, testDataPCA, valDataPCA, classTrain, classVal, classTest\n",
    "\n",
    "def aggregation(percent,rounds,model,feature_num):\n",
    "    import csv\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn import model_selection\n",
    "    from tensorflow import keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from sklearn import svm\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from tensorflow.keras.losses import BinaryCrossentropy\n",
    "    from tensorflow.keras.losses import MeanSquaredError\n",
    "    \n",
    "    trainDataPCA, testDataPCA, valDataPCA, classTrain, classVal, classTest = getData()\n",
    "    \n",
    "    \n",
    "    for x in rounds:\n",
    "        \n",
    "        curr_zero = numpy.ones(feature_num)\n",
    "        aggregate = int(feature_num*percent)\n",
    "        curr_zero[:aggregate] = 0\n",
    "        np.random.shuffle(curr_zero)\n",
    "\n",
    "\n",
    "        model.compile(loss='MeanSquaredError', optimizer=\"adam\", metrics=['accuracy'])\n",
    "        history = model.fit(trainData, Transformer.toClassification(activitiesTrain), \n",
    "                        validation_data = (valData, classVal), epochs=3, batch_size=4)\n",
    "        \n",
    "        curr_acc = mean(history.history[\"val_accuracy\"])\n",
    "        if rounds == 0:\n",
    "            best_acc = curr\n",
    "            prev_zero  = curr_zero\n",
    "            \n",
    "        elif curr_acc > best_acc:\n",
    "            best_acc = mean(history.history[\"val_accuracy\"])\n",
    "            new_features = np.equal(curr_zero,prev_zero) \n",
    "            idx = np.where(new_features==False)\n",
    "    \n",
    "        else:\n",
    "            prev_zero = curr_zero\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "l1Reg = 0.001\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(200, input_dim=np.shape(trainData)[1], activation='softmax', kernel_regularizer = keras.regularizers.L2(l1Reg)))\n",
    "model.add(Dense(150, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model.add(Dense(75, activation='relu', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model.add(Dense(100, activation='relu', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model.add(Dense(100, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model.add(Dense(1, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "\n",
    "model.compile(loss='MeanSquaredError', optimizer=\"adam\", metrics=['accuracy'])\n",
    "history = model.fit(trainData, Transformer.toClassification(activitiesTrain), \n",
    "                    validation_data = (valData, classVal), epochs=3, batch_size=4)\n",
    "\n",
    "# import shap\n",
    "\n",
    "# # load your data here, e.g. X and y\n",
    "# # create and fit your model here\n",
    "\n",
    "# # load JS visualization code to notebook\n",
    "# shap.initjs()\n",
    "\n",
    "# # explain the model's predictions using SHAP\n",
    "# # (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)\n",
    "# explainer = shap.DeepExplainer(model,trainData)\n",
    "# shap_values = explainer.shap_values(trainData)\n",
    "# #print(explainer.explain_row())\n",
    "\n",
    "# # visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
    "# shap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:])\n",
    "\n",
    "# shap.summary_plot(shap_values,trainData, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9120470b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1], dtype=int64),)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [1,0]\n",
    "B = [1,1]\n",
    "C = [A == B]\n",
    "G = np.equal(A,B)\n",
    "print(G)\n",
    "np.where(G==False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
