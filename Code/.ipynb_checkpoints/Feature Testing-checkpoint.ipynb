{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ba41ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Tim\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import Loader\n",
    "import tensorflow as tf\n",
    "import Transformer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "#use for dark mode\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b988a0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 % complete\n",
      "[44 45 45 50 45 50 55 49 50 50 50 55 50 50 49 50 45 50 45 50 50 55 60 50\n",
      " 55 45 49 45 50 55 50 45 49 50 50 55 40 49 49 49 45 55 60 49 53 50 50 49\n",
      " 50 49 49 50 50 50 45 50 50 55 50 50 45 55 55 45 50 55 45 50 49 49 45 49\n",
      " 60 50 60 50 49 50 45 53 50 60 50 49 49 50 50 55 50 60 50 49 40 55 50 45\n",
      " 55 50 50 45 50 50 45 55 49 49 50 50 49 55 60 45 55 55 55 50 50 53 40 50\n",
      " 40 50 50 45 50 50 45 53 45 50 45 60 50 45 53 50 49 45 55 50 55 49 49 45\n",
      " 50 50 55 50 45 45 55 45 50 50 50 55 50 50 49 50 49 45 49 50 50 55 45 48\n",
      " 55 49 45 45 49 49 50 49 40 45 53 50 50 50 50 55 49 50 49 45 49 45 49 55\n",
      " 50 50 53 50 55 45 50 45 40 50 45 55 55 45 55 45 45 50]\n",
      "20.0 % complete\n",
      "[39 45 44 50 53 50 55 43 50 49 55 53 45 50 44 60 40 55 40 55 44 51 64 49\n",
      " 60 49 58 40 40 60 36 40 44 45 60 47 44 46 49 49 45 53 59 53 57 49 50 44\n",
      " 50 39 58 49 50 49 45 49 49 60 55 55 49 49 54 45 44 49 40 55 44 42 39 52\n",
      " 59 50 64 49 49 50 45 58 44 48 50 53 47 49 49 60 50 53 40 58 39 49 44 40\n",
      " 60 49 40 40 50 40 45 66 53 44 44 52 44 49 66 40 60 60 49 40 50 57 36 53\n",
      " 32 55 50 40 50 60 40 42 49 50 40 60 55 32 51 55 48 49 53 60 53 58 44 40\n",
      " 53 45 60 50 45 40 60 49 45 45 50 60 50 49 58 60 53 44 44 44 55 44 40 48\n",
      " 44 53 44 44 44 58 49 44 40 44 51 55 45 55 45 54 53 40 48 42 49 45 58 63\n",
      " 44 50 53 58 54 40 66 45 48 55 44 60 53 40 49 49 45 44]\n",
      "30.0 % complete\n",
      "[42 49 57 49 42 54 55 42 44 48 54 58 49 53 48 60 48 59 52 55 37 48 68 48\n",
      " 52 39 62 44 36 42 38 52 44 44 64 47 44 46 49 38 58 52 58 53 54 39 40 42\n",
      " 55 41 82 44 66 58 58 38 44 63 66 39 44 47 57 42 52 63 44 66 44 37 38 49\n",
      " 53 48 62 42 49 45 53 63 51 38 45 52 61 51 44 64 48 52 39 46 39 58 48 41\n",
      " 64 55 40 44 45 40 45 62 47 42 35 46 44 49 77 42 56 66 52 39 60 57 35 58\n",
      " 35 49 45 40 45 58 36 41 44 49 44 57 59 32 61 54 45 35 51 64 56 57 43 40\n",
      " 45 57 77 51 40 38 54 39 40 53 47 70 53 58 41 57 57 52 46 52 72 48 35 52\n",
      " 44 58 44 35 39 53 47 44 32 35 45 72 40 53 58 53 47 39 62 41 52 49 50 62\n",
      " 42 50 63 58 57 36 70 44 42 48 48 54 45 32 39 58 44 31]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-749119414db0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msorted_rslt_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;31m#for x in rslt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameter_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-749119414db0>\u001b[0m in \u001b[0;36mparameter_rank\u001b[1;34m(top_x, epochs, avg_std_runs)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mXtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_temp_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mXval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_temp_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunBasicSVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[0mcurr_val_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassVal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-749119414db0>\u001b[0m in \u001b[0;36mrunBasicSVM\u001b[1;34m(Xtrain, Ytrain, valData)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m#Xtrain,_,valData = Transformer.normalizeData(Xtrain, compoundDataTest, compoundDataValidate, newMean=0, newStd=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mval_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_pred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    622\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    625\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[0msvm_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLIBSVM_IMPL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m         return libsvm.predict(\n\u001b[0m\u001b[0;32m    362\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_vectors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_support\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dual_coef_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_intercept_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def runBasicSVM(Xtrain, Ytrain, valData):\n",
    "    maxC=10**-.01\n",
    "    clf=svm.SVC(\n",
    "        C=maxC,                          # The regularization parameter\n",
    "        kernel='rbf',                   # The kernel type used \n",
    "        degree=4,                       # Degree of polynomial function \n",
    "        gamma='scale',                  # The kernel coefficient\n",
    "        coef0=0.0,                      # If kernel = 'poly'/'sigmoid'\n",
    "        shrinking=True,                 # To use shrinking heuristic\n",
    "        probability=False,              # Enable probability estimates\n",
    "        tol=0.001,                      # Stopping crierion\n",
    "        cache_size=200,                 # Size of kernel cache\n",
    "        class_weight=None,              # The weight of each class\n",
    "        verbose=False,                  # Enable verbose output\n",
    "        max_iter=- 1,                   # Hard limit on iterations\n",
    "        decision_function_shape='ovr',  # One-vs-rest or one-vs-one\n",
    "        break_ties=False,               # How to handle breaking ties\n",
    "        random_state=None               # Random state of the model\n",
    "    )\n",
    "    #Xtrain,_,valData = Transformer.normalizeData(Xtrain, compoundDataTest, compoundDataValidate, newMean=0, newStd=1)\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    predictions = clf.predict(Xtrain)\n",
    "    val_pred = clf.predict(valData)\n",
    "    return [predictions, val_pred]\n",
    "\n",
    "def get_data():\n",
    "    compoundsTrain, smilesTrain, labelsTrain, compoundDataTrain, activitiesTrain = Loader.getTrain(defaultValue=0)\n",
    "    compoundsTest, smilesTest, labelsTest, compoundDataTest, activitiesTest = Loader.getTest(defaultValue=0)\n",
    "    compoundsValidate, smilesValidate, labelsValidate, compoundDataValidate, activitiesValidate = Loader.getValidate(defaultValue=0)\n",
    "\n",
    "    labelsMean, trainMean = Transformer.useAverageFD(labelsTrain, compoundDataTrain)\n",
    "    _, testMean = Transformer.useAverageFD(labelsTest, compoundDataTest)\n",
    "    _, valMean = Transformer.useAverageFD(labelsValidate, compoundDataValidate)\n",
    "\n",
    "    labelsMax, trainMax = Transformer.useMaxFD(labelsTrain, compoundDataTrain)\n",
    "    _, testMax = Transformer.useMaxFD(labelsTest, compoundDataTest)\n",
    "    _, valMax = Transformer.useMaxFD(labelsValidate, compoundDataValidate)\n",
    "\n",
    "    #after transformations are done assign data\n",
    "    dataLabels = labelsMax\n",
    "    trainData = trainMax\n",
    "    testData = testMax\n",
    "    valData = valMax\n",
    "\n",
    "    trainData, testData, valData = Transformer.normalizeData(trainData, testData, valData, newMean=0, newStd=1)\n",
    "    \n",
    "    classTrain = Transformer.toBinaryClassification(activitiesTrain)\n",
    "    classVal = Transformer.toBinaryClassification(activitiesValidate)\n",
    "    classTest = Transformer.toBinaryClassification(activitiesTest)\n",
    "    \n",
    "    return trainData, testData, valData, classTrain, classTest, classVal, dataLabels\n",
    "\n",
    "\n",
    "def parameter_rank(top_x, epochs, avg_std_runs):\n",
    "    \n",
    "    trainData, testData, valData, classTrain, classTest, classVal, dataLabels = get_data()\n",
    "    col_idx = np.arange(0,210)\n",
    "    probs = []\n",
    "    for i in range(210):\n",
    "        probs.append(50)\n",
    "    probs = np.array(probs)\n",
    "    eval_set = []\n",
    "\n",
    "    for x in range(epochs):\n",
    "        \n",
    "        train_data_df = pd.DataFrame(trainData, columns = dataLabels)\n",
    "        train_temp_df = train_data_df.copy()\n",
    "        val_data_df = pd.DataFrame(valData, columns = dataLabels)\n",
    "        val_temp_df = val_data_df.copy()\n",
    "\n",
    "        values = probs\n",
    "        \n",
    "        arr1 = values / values.min()\n",
    "        arr1 = arr1 / arr1.sum()\n",
    "        #print(arr1, arr1.sum())\n",
    "        #display(values, sum(values))\n",
    "        test_cols = np.random.choice(col_idx, top_x, replace=False, p = arr1)\n",
    "        # using set() to perform task\n",
    "        test_cols_set = set(test_cols)\n",
    "        col_idx_set = set(col_idx)\n",
    "        zero_cols = list(col_idx_set - test_cols_set)\n",
    "        \n",
    "        train_temp_df.iloc[:, zero_cols] *= 0\n",
    "        val_temp_df.iloc[:, zero_cols] *= 0\n",
    "        \n",
    "        \n",
    "        Xtrain = train_temp_df.values\n",
    "        Xval = val_temp_df.values\n",
    "        accuracy = runBasicSVM(Xtrain,classTrain, Xval)\n",
    "        curr_val_acc = accuracy_score(classVal, accuracy[1])\n",
    "        \n",
    "        if(x < avg_std_runs):\n",
    "            eval_set.append(curr_val_acc)\n",
    "        else:\n",
    "            \n",
    "            if curr_val_acc > np.average(eval_set) + np.std(eval_set):\n",
    "                np.multiply.at(probs,test_cols,1.1)\n",
    "            elif curr_val_acc < np.average(eval_set) - np.std(eval_set):\n",
    "                np.multiply.at(probs,test_cols,.9)\n",
    "                prev_val_acc = accuracy[1]\n",
    "            else:\n",
    "                prev_val_acc = accuracy[1]\n",
    "                \n",
    "            eval_set.pop(0)\n",
    "            eval_set.append(curr_val_acc)\n",
    "        \n",
    "        if((((x+1)/epochs)*100)%10 == 0):\n",
    "            print(((x+1)/epochs)*100, \"% complete\")\n",
    "            print(probs)\n",
    "\n",
    "    result = [dataLabels, probs]\n",
    "    #display(results, results.shape)\n",
    "    rslt_df = pd.DataFrame(data = np.transpose(result), columns=['Feature','Probability Weight'])\n",
    "    sorted_rslt_df = rslt_df.sort_values(by='Probability Weight', ascending=False)\n",
    "\n",
    "    return sorted_rslt_df\n",
    "#for x in rslt\n",
    "display(parameter_rank(50,300,20))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "ad689242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df = parameter_rank(20, 10)\n",
    "display(final_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
