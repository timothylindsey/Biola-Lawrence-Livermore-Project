{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cd92637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import Loader\n",
    "import tensorflow as tf\n",
    "import Transformer\n",
    "from sklearn import preprocessing\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc3252c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2717 340 340\n"
     ]
    }
   ],
   "source": [
    "compoundsTrain, smilesTrain, labelsTrain, compoundDataTrain, activitiesTrain = Loader.getTrain(defaultValue=0)\n",
    "compoundsTest, smilesTest, labelsTest, compoundDataTest, activitiesTest = Loader.getTest(defaultValue=0)\n",
    "compoundsValidate, smilesValidate, labelsValidate, compoundDataValidate, activitiesValidate = Loader.getValidate(defaultValue=0)\n",
    "\n",
    "#print(labelsTrain)\n",
    "#print(compoundsTrain)\n",
    "#print(smilesTrain)\n",
    "#print(activitiesTrain)\n",
    "\n",
    "#for i in range(len(labelsTrain)):\n",
    "#    print(labelsTrain[i] + \": \", compoundDataTrain[0,i])\n",
    "\n",
    "def toClassification(y): # The resulting array will contain values of -1 if it is below 4.5 and 1 if it is above\n",
    "    y = np.array(y)\n",
    "    classification = (y.astype(float)>4).astype(int)\n",
    "    return classification * 2 - 1\n",
    "\n",
    "def normalizeData(train,test,validate):\n",
    "    for i in range(np.shape(train)[1]):\n",
    "        std = np.std(train[:,i])\n",
    "        mean = np.mean(train[:,i])\n",
    "        if(std == 0):\n",
    "            std = 1\n",
    "        train[:,i] = (train[:,i] - mean) / std\n",
    "        test[:,i] = (test[:,i] - mean) / std\n",
    "        validate[:,i] = (validate[:,i] - mean) / std\n",
    "    return train, test, validate\n",
    "\n",
    "def makeAverage(arr): # Averages the ten values for each score and creates a new array\n",
    "    arr = np.array(arr)\n",
    "    newArr = np.empty((np.shape(arr)[0], np.shape(arr)[1] - 18))\n",
    "    newArr[:,0] = np.mean(arr[:,:10], axis = 1)\n",
    "    newArr[:,1] = np.mean(arr[:,10:20], axis = 1)\n",
    "    newArr[:,2:] = arr[:,20:]\n",
    "    return newArr\n",
    "\n",
    "def averageScores(train, test, validate): #wrapper function to handle all conversions at once\n",
    "    newTrain = makeAverage(train)\n",
    "    newTest = makeAverage(test)\n",
    "    newValid = makeAverage(validate)\n",
    "    return newTrain, newTest, newValid\n",
    "    \n",
    "compoundDataTrain, compoundDataTest, compoundDataValidate = averageScores(compoundDataTrain, compoundDataTest, compoundDataValidate)\n",
    "compoundDataTrain, compoundDataTest, compoundDataValidate = normalizeData(compoundDataTrain, compoundDataTest, compoundDataValidate)\n",
    "print(len(compoundsTrain), len(compoundsTest), len(compoundsValidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b30c8f1",
   "metadata": {},
   "source": [
    "# Testing by taking votes from full networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d003fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def takeVote(models, xValidate, yValidate):\n",
    "    yAggregate = np.zeros(len(yValidate))\n",
    "    numOfModels = len(models)\n",
    "    for model in models:\n",
    "        yAggregate = yAggregate + np.sign(model.predict(xValidate))\n",
    "    return np.sign(yAggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8d98c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "85/85 [==============================] - 1s 3ms/step - loss: 5.5696 - accuracy: 0.0000e+00\n",
      "Epoch 2/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.5090 - accuracy: 0.0000e+00\n",
      "Epoch 3/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 5.4587 - accuracy: 0.0000e+00\n",
      "Epoch 4/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 5.4080 - accuracy: 0.0000e+00\n",
      "Epoch 5/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.3580 - accuracy: 0.0000e+00\n",
      "Epoch 6/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.3069 - accuracy: 0.0000e+00\n",
      "Epoch 7/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.2570 - accuracy: 0.0000e+00\n",
      "Epoch 8/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 5.2081 - accuracy: 0.0000e+00\n",
      "Epoch 9/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.1596 - accuracy: 0.0000e+00\n",
      "Epoch 10/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 5.1095 - accuracy: 0.0000e+00\n",
      "Epoch 11/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 5.0606 - accuracy: 0.0000e+00\n",
      "Epoch 12/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.0112 - accuracy: 0.0000e+00\n",
      "Epoch 13/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.9595 - accuracy: 0.0000e+00\n",
      "Epoch 14/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.9132 - accuracy: 0.0000e+00\n",
      "Epoch 15/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.8599 - accuracy: 0.0000e+00\n",
      "Epoch 16/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.8070 - accuracy: 0.0000e+00\n",
      "Epoch 17/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.7495 - accuracy: 0.0000e+00\n",
      "Epoch 18/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.6927 - accuracy: 0.0015\n",
      "Epoch 19/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.6270 - accuracy: 0.0434\n",
      "Epoch 20/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.5555 - accuracy: 0.0905\n",
      "Epoch 21/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.4843 - accuracy: 0.1384\n",
      "Epoch 22/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.4038 - accuracy: 0.1770\n",
      "Epoch 23/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.3261 - accuracy: 0.2043\n",
      "Epoch 24/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.2544 - accuracy: 0.2352\n",
      "Epoch 25/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.1801 - accuracy: 0.2584\n",
      "Epoch 26/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.0911 - accuracy: 0.2922\n",
      "Epoch 27/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.0122 - accuracy: 0.3187\n",
      "Epoch 28/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.9456 - accuracy: 0.3482\n",
      "Epoch 29/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 3.8718 - accuracy: 0.3850\n",
      "Epoch 30/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.8091 - accuracy: 0.4185\n",
      "Epoch 31/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.7345 - accuracy: 0.4387\n",
      "Epoch 32/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.6597 - accuracy: 0.4663\n",
      "Epoch 33/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.5871 - accuracy: 0.4844\n",
      "Epoch 34/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.5356 - accuracy: 0.4844\n",
      "Epoch 35/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.4969 - accuracy: 0.4943\n",
      "Epoch 36/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.4400 - accuracy: 0.5013\n",
      "Epoch 37/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.3854 - accuracy: 0.5075\n",
      "Epoch 38/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.3468 - accuracy: 0.5083\n",
      "Epoch 39/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.2993 - accuracy: 0.5171\n",
      "Epoch 40/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 3.2489 - accuracy: 0.5179\n",
      "Epoch 41/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 3.1995 - accuracy: 0.5237\n",
      "Epoch 42/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.1630 - accuracy: 0.5256\n",
      "Epoch 43/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.1145 - accuracy: 0.5259\n",
      "Epoch 44/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.0640 - accuracy: 0.5300\n",
      "Epoch 45/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.0341 - accuracy: 0.5326\n",
      "Epoch 46/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 2.9898 - accuracy: 0.5359\n",
      "Epoch 47/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.9451 - accuracy: 0.5359\n",
      "Epoch 48/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.9102 - accuracy: 0.5355\n",
      "Epoch 49/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.8671 - accuracy: 0.5407\n",
      "Epoch 50/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 2.8279 - accuracy: 0.5421\n",
      "Epoch 51/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.7936 - accuracy: 0.5403\n",
      "Epoch 52/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.7478 - accuracy: 0.5436\n",
      "Epoch 53/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.7134 - accuracy: 0.5444\n",
      "Epoch 54/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.6736 - accuracy: 0.5469\n",
      "Epoch 55/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.6359 - accuracy: 0.5473\n",
      "Epoch 56/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.5939 - accuracy: 0.5466\n",
      "Epoch 57/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.5601 - accuracy: 0.5506\n",
      "Epoch 58/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.5182 - accuracy: 0.5539\n",
      "Epoch 59/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.4905 - accuracy: 0.5554\n",
      "Epoch 60/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.4473 - accuracy: 0.5591\n",
      "Epoch 61/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.4118 - accuracy: 0.5583\n",
      "Epoch 62/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.3791 - accuracy: 0.5613\n",
      "Epoch 63/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.3462 - accuracy: 0.5631\n",
      "Epoch 64/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.3094 - accuracy: 0.5620\n",
      "Epoch 65/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.2791 - accuracy: 0.5628\n",
      "Epoch 66/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.2447 - accuracy: 0.5650\n",
      "Epoch 67/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.2130 - accuracy: 0.5620\n",
      "Epoch 68/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.1784 - accuracy: 0.5705\n",
      "Epoch 69/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.1473 - accuracy: 0.5697\n",
      "Epoch 70/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 2.1167 - accuracy: 0.5716\n",
      "Epoch 71/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.0859 - accuracy: 0.5712\n",
      "Epoch 72/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 2.0524 - accuracy: 0.5738\n",
      "Epoch 73/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.0223 - accuracy: 0.5749\n",
      "Epoch 74/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.9934 - accuracy: 0.5745\n",
      "Epoch 75/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.9606 - accuracy: 0.5756\n",
      "Epoch 76/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.9363 - accuracy: 0.5764\n",
      "Epoch 77/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.9036 - accuracy: 0.5786\n",
      "Epoch 78/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.8740 - accuracy: 0.5760\n",
      "Epoch 79/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.8492 - accuracy: 0.5782\n",
      "Epoch 80/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.8198 - accuracy: 0.5804\n",
      "Epoch 81/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.7934 - accuracy: 0.5804\n",
      "Epoch 82/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 2ms/step - loss: 1.7640 - accuracy: 0.5797\n",
      "Epoch 83/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.7383 - accuracy: 0.5819\n",
      "Epoch 84/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.7119 - accuracy: 0.5834\n",
      "Epoch 85/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.6848 - accuracy: 0.5856\n",
      "Epoch 86/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.6604 - accuracy: 0.5841\n",
      "Epoch 87/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.6346 - accuracy: 0.5848\n",
      "Epoch 88/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.6094 - accuracy: 0.5870\n",
      "Epoch 89/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5836 - accuracy: 0.5870\n",
      "Epoch 90/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5594 - accuracy: 0.5896\n",
      "Epoch 91/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5361 - accuracy: 0.5874\n",
      "Epoch 92/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5106 - accuracy: 0.5870\n",
      "Epoch 93/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.4868 - accuracy: 0.5885\n",
      "Epoch 94/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.4635 - accuracy: 0.5870\n",
      "Epoch 95/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.4416 - accuracy: 0.5911\n",
      "Epoch 96/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.4177 - accuracy: 0.5893\n",
      "Epoch 97/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.3962 - accuracy: 0.5904\n",
      "Epoch 98/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.3729 - accuracy: 0.5904\n",
      "Epoch 99/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.3512 - accuracy: 0.5904\n",
      "Epoch 100/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.3310 - accuracy: 0.5896\n",
      "Epoch 101/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.3084 - accuracy: 0.5929\n",
      "Epoch 102/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.2872 - accuracy: 0.5918\n",
      "Epoch 103/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.2662 - accuracy: 0.5915\n",
      "Epoch 104/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.2466 - accuracy: 0.5926\n",
      "Epoch 105/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.2247 - accuracy: 0.5926\n",
      "Epoch 106/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.2038 - accuracy: 0.5940\n",
      "Epoch 107/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1866 - accuracy: 0.5929\n",
      "Epoch 108/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1666 - accuracy: 0.5944\n",
      "Epoch 109/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1467 - accuracy: 0.5962\n",
      "Epoch 110/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1280 - accuracy: 0.5955\n",
      "Epoch 111/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1099 - accuracy: 0.5955\n",
      "Epoch 112/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0913 - accuracy: 0.5970\n",
      "Epoch 113/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0740 - accuracy: 0.5962\n",
      "Epoch 114/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.0556 - accuracy: 0.5981\n",
      "Epoch 115/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0387 - accuracy: 0.5981\n",
      "Epoch 116/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0210 - accuracy: 0.5959\n",
      "Epoch 117/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0051 - accuracy: 0.5966\n",
      "Epoch 118/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.9876 - accuracy: 0.5992\n",
      "Epoch 119/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.9724 - accuracy: 0.5977\n",
      "Epoch 120/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.9551 - accuracy: 0.5996\n",
      "Epoch 121/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.9400 - accuracy: 0.5977\n",
      "Epoch 122/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.9240 - accuracy: 0.5988\n",
      "Epoch 123/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.9082 - accuracy: 0.5985\n",
      "Epoch 124/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.8931 - accuracy: 0.6003\n",
      "Epoch 125/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.8796 - accuracy: 0.5992\n",
      "Epoch 126/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.8645 - accuracy: 0.6010\n",
      "Epoch 127/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.8505 - accuracy: 0.6003\n",
      "Epoch 128/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.8371 - accuracy: 0.6010\n",
      "Epoch 129/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.8223 - accuracy: 0.6007\n",
      "Epoch 130/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.8095 - accuracy: 0.5988\n",
      "Epoch 131/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7967 - accuracy: 0.6010\n",
      "Epoch 132/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7832 - accuracy: 0.6007\n",
      "Epoch 133/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7702 - accuracy: 0.6010\n",
      "Epoch 134/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7588 - accuracy: 0.6032\n",
      "Epoch 135/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7452 - accuracy: 0.6010\n",
      "Epoch 136/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7332 - accuracy: 0.6025\n",
      "Epoch 137/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7219 - accuracy: 0.6003\n",
      "Epoch 138/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7098 - accuracy: 0.6029\n",
      "Epoch 139/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6989 - accuracy: 0.6014\n",
      "Epoch 140/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.6014\n",
      "Epoch 141/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6766 - accuracy: 0.6025\n",
      "Epoch 142/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6657 - accuracy: 0.6018\n",
      "Epoch 143/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.6032\n",
      "Epoch 144/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.6021\n",
      "Epoch 145/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.6040\n",
      "Epoch 146/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.6032\n",
      "Epoch 147/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6160 - accuracy: 0.6029\n",
      "Epoch 148/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.6025\n",
      "Epoch 149/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.5973 - accuracy: 0.6029\n",
      "Epoch 150/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.6021\n",
      "Epoch 151/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.6040\n",
      "Epoch 152/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.6032\n",
      "Epoch 153/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.6040\n",
      "Epoch 154/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.6032\n",
      "Epoch 155/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.6021\n",
      "Epoch 156/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.6062\n",
      "Epoch 157/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.6040\n",
      "Epoch 158/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.6043\n",
      "Epoch 159/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.6043\n",
      "Epoch 160/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.6032\n",
      "Epoch 161/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.6054\n",
      "Epoch 162/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.6058\n",
      "Epoch 163/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.6058\n",
      "Epoch 164/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.6043\n",
      "Epoch 165/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.6062\n",
      "Epoch 166/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.6058\n",
      "Epoch 167/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.6051\n",
      "Epoch 168/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.6066\n",
      "Epoch 169/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.6054\n",
      "Epoch 170/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.6069\n",
      "Epoch 171/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.6062\n",
      "Epoch 172/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.6066\n",
      "Epoch 173/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.6080\n",
      "Epoch 174/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.6073\n",
      "Epoch 175/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.6088\n",
      "Epoch 176/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.6073\n",
      "Epoch 177/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.6069\n",
      "Epoch 178/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.6069\n",
      "Epoch 179/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.6080\n",
      "Epoch 180/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4020 - accuracy: 0.6080\n",
      "Epoch 181/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.6077\n",
      "Epoch 182/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.6084\n",
      "Epoch 183/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.6080\n",
      "Epoch 184/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.6080\n",
      "Epoch 185/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.6091\n",
      "Epoch 186/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.6091\n",
      "Epoch 187/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.6084\n",
      "Epoch 188/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.6077\n",
      "Epoch 189/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.6088\n",
      "Epoch 190/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.6095\n",
      "Epoch 191/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.6088\n",
      "Epoch 192/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.6095\n",
      "Epoch 193/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.6095\n",
      "Epoch 194/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.6095\n",
      "Epoch 195/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3458 - accuracy: 0.6095\n",
      "Epoch 196/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.6102\n",
      "Epoch 197/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.6099\n",
      "Epoch 198/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.6099\n",
      "Epoch 199/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.6099\n",
      "Epoch 200/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.6102\n",
      "Epoch 201/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.6102\n",
      "Epoch 202/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.6095\n",
      "Epoch 203/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.6102\n",
      "Epoch 204/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.6099\n",
      "Epoch 205/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.6099\n",
      "Epoch 206/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.6106\n",
      "Epoch 207/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.6102\n",
      "Epoch 208/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.6102\n",
      "Epoch 209/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.6102\n",
      "Epoch 210/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.6106\n",
      "Epoch 211/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.6102\n",
      "Epoch 212/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.6106\n",
      "Epoch 213/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.6106\n",
      "Epoch 214/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.6102\n",
      "Epoch 215/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.6102\n",
      "Epoch 216/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2978 - accuracy: 0.6106\n",
      "Epoch 217/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.6106\n",
      "Epoch 218/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2944 - accuracy: 0.6102\n",
      "Epoch 219/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2925 - accuracy: 0.6106\n",
      "Epoch 220/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2911 - accuracy: 0.6102\n",
      "Epoch 221/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.6102\n",
      "Epoch 222/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2880 - accuracy: 0.6102\n",
      "Epoch 223/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2867 - accuracy: 0.6106\n",
      "Epoch 224/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2852 - accuracy: 0.6106\n",
      "Epoch 225/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2840 - accuracy: 0.6110\n",
      "Epoch 226/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2825 - accuracy: 0.6106\n",
      "Epoch 227/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2810 - accuracy: 0.6106\n",
      "Epoch 228/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.6110\n",
      "Epoch 229/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2785 - accuracy: 0.6113\n",
      "Epoch 230/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.6110\n",
      "Epoch 231/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2761 - accuracy: 0.6106\n",
      "Epoch 232/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2750 - accuracy: 0.6110\n",
      "Epoch 233/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2738 - accuracy: 0.6106\n",
      "Epoch 234/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.6117\n",
      "Epoch 235/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2715 - accuracy: 0.6110\n",
      "Epoch 236/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2702 - accuracy: 0.6113\n",
      "Epoch 237/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2693 - accuracy: 0.6110\n",
      "Epoch 238/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.6110\n",
      "Epoch 239/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.6113\n",
      "Epoch 240/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.6113\n",
      "Epoch 241/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2649 - accuracy: 0.6113\n",
      "Epoch 242/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.6110\n",
      "Epoch 243/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.6113\n",
      "Epoch 244/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2617 - accuracy: 0.6110\n",
      "Epoch 245/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.6113\n",
      "Epoch 246/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2598 - accuracy: 0.6110\n",
      "Epoch 247/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.6113\n",
      "Epoch 248/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2579 - accuracy: 0.6113\n",
      "Epoch 249/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2569 - accuracy: 0.6110\n",
      "Epoch 250/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2560 - accuracy: 0.6110\n",
      "Epoch 251/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.6110\n",
      "Epoch 252/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.6113\n",
      "Epoch 253/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.6110\n",
      "Epoch 254/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.6113\n",
      "Epoch 255/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.6110\n",
      "Epoch 256/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.6117\n",
      "Epoch 257/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.6110\n",
      "Epoch 258/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.6110\n",
      "Epoch 259/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.6113\n",
      "Epoch 260/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.6110\n",
      "Epoch 261/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.6110\n",
      "Epoch 262/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.6113\n",
      "Epoch 263/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.6110\n",
      "Epoch 264/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2435 - accuracy: 0.6110\n",
      "Epoch 265/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2429 - accuracy: 0.6110\n",
      "Epoch 266/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.6113\n",
      "Epoch 267/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2412 - accuracy: 0.6113\n",
      "Epoch 268/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.6110\n",
      "Epoch 269/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.6113\n",
      "Epoch 270/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.6113\n",
      "Epoch 271/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2380 - accuracy: 0.6113\n",
      "Epoch 272/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.6110\n",
      "Epoch 273/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2364 - accuracy: 0.6113\n",
      "Epoch 274/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.6113\n",
      "Epoch 275/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2351 - accuracy: 0.6113\n",
      "Epoch 276/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.6113\n",
      "Epoch 277/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.6113\n",
      "Epoch 278/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2325 - accuracy: 0.6117\n",
      "Epoch 279/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.6113\n",
      "Epoch 280/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2311 - accuracy: 0.6110\n",
      "Epoch 281/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2303 - accuracy: 0.6117\n",
      "Epoch 282/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2296 - accuracy: 0.6113\n",
      "Epoch 283/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 0.6113\n",
      "Epoch 284/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2281 - accuracy: 0.6113\n",
      "Epoch 285/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2274 - accuracy: 0.6113\n",
      "Epoch 286/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2266 - accuracy: 0.6113\n",
      "Epoch 287/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.6113\n",
      "Epoch 288/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.6113\n",
      "Epoch 289/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2246 - accuracy: 0.6113\n",
      "Epoch 290/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.6110\n",
      "Epoch 291/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.6110\n",
      "Epoch 292/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.6117\n",
      "Epoch 293/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.6121\n",
      "Epoch 294/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.6121\n",
      "Epoch 295/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2203 - accuracy: 0.6110\n",
      "Epoch 296/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.6117\n",
      "Epoch 297/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.6117\n",
      "Epoch 298/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.6117\n",
      "Epoch 299/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.6117\n",
      "Epoch 300/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.6117\n",
      "Epoch 301/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.6117\n",
      "Epoch 302/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2162 - accuracy: 0.6117\n",
      "Epoch 303/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.6117\n",
      "Epoch 304/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2149 - accuracy: 0.6117\n",
      "Epoch 305/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2142 - accuracy: 0.6121\n",
      "Epoch 306/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.6117\n",
      "Epoch 307/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.6117\n",
      "Epoch 308/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2122 - accuracy: 0.6121\n",
      "Epoch 309/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2117 - accuracy: 0.6117\n",
      "Epoch 310/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2109 - accuracy: 0.6121\n",
      "Epoch 311/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.6117\n",
      "Epoch 312/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.6117\n",
      "Epoch 313/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2090 - accuracy: 0.6117\n",
      "Epoch 314/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.6121\n",
      "Epoch 315/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.6121\n",
      "Epoch 316/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2073 - accuracy: 0.6117\n",
      "Epoch 317/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2068 - accuracy: 0.6117\n",
      "Epoch 318/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.6121\n",
      "Epoch 319/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2055 - accuracy: 0.6121\n",
      "Epoch 320/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.6117\n",
      "Epoch 321/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.6117\n",
      "Epoch 322/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2040 - accuracy: 0.6121\n",
      "Epoch 323/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.6121\n",
      "Epoch 324/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2028 - accuracy: 0.6124\n",
      "Epoch 325/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 0.6121\n",
      "Epoch 326/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2019 - accuracy: 0.6124\n",
      "Epoch 327/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2014 - accuracy: 0.6121\n",
      "Epoch 328/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2008 - accuracy: 0.6124\n",
      "Epoch 329/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2003 - accuracy: 0.6121\n",
      "Epoch 330/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.6124\n",
      "Epoch 331/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.6124\n",
      "Epoch 332/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.6121\n",
      "Epoch 333/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.6128\n",
      "Epoch 334/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.6128\n",
      "Epoch 335/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1972 - accuracy: 0.6121\n",
      "Epoch 336/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1968 - accuracy: 0.6124\n",
      "Epoch 337/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.6128\n",
      "Epoch 338/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.1958 - accuracy: 0.6124\n",
      "Epoch 339/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.1953 - accuracy: 0.6128\n",
      "Epoch 340/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.1949 - accuracy: 0.6124\n",
      "Epoch 341/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.6124\n",
      "Epoch 342/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.6124\n",
      "Epoch 343/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.6124\n",
      "Epoch 344/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.6128\n",
      "Epoch 345/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1927 - accuracy: 0.6128\n",
      "Epoch 346/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.6128\n",
      "Epoch 347/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1917 - accuracy: 0.6128\n",
      "Epoch 348/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.6132\n",
      "Epoch 349/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.6132\n",
      "Epoch 350/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.6132\n",
      "Epoch 351/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1900 - accuracy: 0.6132\n",
      "Epoch 352/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1897 - accuracy: 0.6132\n",
      "Epoch 353/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.6128\n",
      "Epoch 354/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.6132\n",
      "Epoch 355/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.6132\n",
      "Epoch 356/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.1880 - accuracy: 0.6132\n",
      "Epoch 357/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1877 - accuracy: 0.6132\n",
      "Epoch 358/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.6128\n",
      "Epoch 359/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.6132\n",
      "Epoch 360/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.6128\n",
      "Epoch 361/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.6132\n",
      "Epoch 362/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1856 - accuracy: 0.6132\n",
      "Epoch 363/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1853 - accuracy: 0.6132\n",
      "Epoch 364/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.6128\n",
      "Epoch 365/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.6135\n",
      "Epoch 366/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1841 - accuracy: 0.6132\n",
      "Epoch 367/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.6132\n",
      "Epoch 368/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.6132\n",
      "Epoch 369/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.6132\n",
      "Epoch 370/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.6132\n",
      "Epoch 371/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.1823 - accuracy: 0.6132\n",
      "Epoch 372/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.6132\n",
      "Epoch 373/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.6132\n",
      "Epoch 374/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.6132\n",
      "Epoch 375/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1808 - accuracy: 0.6132\n",
      "Epoch 376/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1804 - accuracy: 0.6128\n",
      "Epoch 377/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.6132\n",
      "Epoch 378/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.6132\n",
      "Epoch 379/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.6132\n",
      "Epoch 380/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.6128\n",
      "Epoch 381/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.6132\n",
      "Epoch 382/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.6132\n",
      "Epoch 383/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.6132\n",
      "Epoch 384/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1776 - accuracy: 0.6132\n",
      "Epoch 385/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1772 - accuracy: 0.6132\n",
      "Epoch 386/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.1769 - accuracy: 0.6132\n",
      "Epoch 387/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1765 - accuracy: 0.6132\n",
      "Epoch 388/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.6132\n",
      "Epoch 389/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.6132\n",
      "Epoch 390/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.6132\n",
      "Epoch 391/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.6132\n",
      "Epoch 392/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.1749 - accuracy: 0.6132\n",
      "Epoch 393/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1745 - accuracy: 0.6132\n",
      "Epoch 394/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.6128\n",
      "Epoch 395/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1739 - accuracy: 0.6132\n",
      "Epoch 396/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.6132\n",
      "Epoch 397/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.1733 - accuracy: 0.6132\n",
      "Epoch 398/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1730 - accuracy: 0.6132\n",
      "Epoch 399/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1727 - accuracy: 0.6132\n",
      "Epoch 400/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1723 - accuracy: 0.6132\n"
     ]
    }
   ],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=20000,\n",
    "    decay_rate=0.9)\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(200, input_dim=np.shape(compoundDataTrain)[1], activation='softmax', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model1.add(Dense(150, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model1.add(Dense(75, activation='relu', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model1.add(Dense(100, activation='relu', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model1.add(Dense(100, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model1.add(Dense(1, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "\n",
    "model1.compile(loss='MeanSquaredError', optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model1.fit(compoundDataTrain, toClassification(activitiesTrain),epochs=400, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25389ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 1.0907 - accuracy: 0.3658\n",
      "Epoch 2/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.4183 - accuracy: 0.5285\n",
      "Epoch 3/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3624 - accuracy: 0.5429\n",
      "Epoch 4/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3211 - accuracy: 0.5543\n",
      "Epoch 5/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.2952 - accuracy: 0.5613\n",
      "Epoch 6/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.2783 - accuracy: 0.5690\n",
      "Epoch 7/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.2612 - accuracy: 0.5701\n",
      "Epoch 8/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.2465 - accuracy: 0.5745\n",
      "Epoch 9/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.2467 - accuracy: 0.5749\n",
      "Epoch 10/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.2375 - accuracy: 0.5745\n",
      "Epoch 11/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.2246 - accuracy: 0.5793\n",
      "Epoch 12/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.2169 - accuracy: 0.5812\n",
      "Epoch 13/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.2143 - accuracy: 0.5826\n",
      "Epoch 14/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.2023 - accuracy: 0.5834\n",
      "Epoch 15/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1910 - accuracy: 0.5885\n",
      "Epoch 16/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1876 - accuracy: 0.5885\n",
      "Epoch 17/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1781 - accuracy: 0.5900\n",
      "Epoch 18/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1752 - accuracy: 0.5922\n",
      "Epoch 19/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1682 - accuracy: 0.5933\n",
      "Epoch 20/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1607 - accuracy: 0.5951\n",
      "Epoch 21/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1553 - accuracy: 0.5974\n",
      "Epoch 22/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1672 - accuracy: 0.5959\n",
      "Epoch 23/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1548 - accuracy: 0.5959\n",
      "Epoch 24/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1642 - accuracy: 0.5937\n",
      "Epoch 25/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1457 - accuracy: 0.6003\n",
      "Epoch 26/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1531 - accuracy: 0.5962\n",
      "Epoch 27/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1501 - accuracy: 0.5977\n",
      "Epoch 28/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1578 - accuracy: 0.5929\n",
      "Epoch 29/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1414 - accuracy: 0.5974\n",
      "Epoch 30/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1492 - accuracy: 0.5988\n",
      "Epoch 31/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1521 - accuracy: 0.5955\n",
      "Epoch 32/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1435 - accuracy: 0.5970\n",
      "Epoch 33/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1307 - accuracy: 0.6007\n",
      "Epoch 34/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1247 - accuracy: 0.6029\n",
      "Epoch 35/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.1349 - accuracy: 0.6014\n",
      "Epoch 36/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1677 - accuracy: 0.5922\n",
      "Epoch 37/400\n",
      "680/680 [==============================] - 2s 3ms/step - loss: 0.1452 - accuracy: 0.5974\n",
      "Epoch 38/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1435 - accuracy: 0.5988\n",
      "Epoch 39/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1304 - accuracy: 0.6018\n",
      "Epoch 40/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1307 - accuracy: 0.6014\n",
      "Epoch 41/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1404 - accuracy: 0.5992\n",
      "Epoch 42/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1349 - accuracy: 0.5981\n",
      "Epoch 43/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1338 - accuracy: 0.5992\n",
      "Epoch 44/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.1340 - accuracy: 0.5992\n",
      "Epoch 45/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.1218 - accuracy: 0.6040\n",
      "Epoch 46/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.1225 - accuracy: 0.6025\n",
      "Epoch 47/400\n",
      "680/680 [==============================] - 2s 3ms/step - loss: 0.1269 - accuracy: 0.6025\n",
      "Epoch 48/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.1297 - accuracy: 0.6007\n",
      "Epoch 49/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1247 - accuracy: 0.6029\n",
      "Epoch 50/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1215 - accuracy: 0.6029\n",
      "Epoch 51/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1394 - accuracy: 0.5977\n",
      "Epoch 52/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1238 - accuracy: 0.6025\n",
      "Epoch 53/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1198 - accuracy: 0.6040\n",
      "Epoch 54/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1178 - accuracy: 0.6036\n",
      "Epoch 55/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1297 - accuracy: 0.6010\n",
      "Epoch 56/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.1213 - accuracy: 0.6032\n",
      "Epoch 57/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1267 - accuracy: 0.6010\n",
      "Epoch 58/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1240 - accuracy: 0.6021\n",
      "Epoch 59/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1266 - accuracy: 0.6010\n",
      "Epoch 60/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1300 - accuracy: 0.5999\n",
      "Epoch 61/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.1205 - accuracy: 0.6047\n",
      "Epoch 62/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1090 - accuracy: 0.6073\n",
      "Epoch 63/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.1139 - accuracy: 0.6036\n",
      "Epoch 64/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.1200 - accuracy: 0.6047\n",
      "Epoch 65/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1349 - accuracy: 0.6025\n",
      "Epoch 66/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1235 - accuracy: 0.6014\n",
      "Epoch 67/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1112 - accuracy: 0.6040\n",
      "Epoch 68/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1192 - accuracy: 0.6010\n",
      "Epoch 69/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1213 - accuracy: 0.6036\n",
      "Epoch 70/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1187 - accuracy: 0.6047\n",
      "Epoch 71/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1103 - accuracy: 0.6062\n",
      "Epoch 72/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1226 - accuracy: 0.6007\n",
      "Epoch 73/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1203 - accuracy: 0.6021\n",
      "Epoch 74/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1230 - accuracy: 0.6014\n",
      "Epoch 75/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1182 - accuracy: 0.6047\n",
      "Epoch 76/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1038 - accuracy: 0.6073\n",
      "Epoch 77/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1055 - accuracy: 0.6077\n",
      "Epoch 78/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1119 - accuracy: 0.6051\n",
      "Epoch 79/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1213 - accuracy: 0.6010\n",
      "Epoch 80/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1200 - accuracy: 0.6003\n",
      "Epoch 81/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680/680 [==============================] - 2s 2ms/step - loss: 0.1096 - accuracy: 0.6051\n",
      "Epoch 82/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1129 - accuracy: 0.6051\n",
      "Epoch 83/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1309 - accuracy: 0.5999\n",
      "Epoch 84/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1231 - accuracy: 0.6029\n",
      "Epoch 85/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1054 - accuracy: 0.6066\n",
      "Epoch 86/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1189 - accuracy: 0.6032\n",
      "Epoch 87/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1141 - accuracy: 0.6058\n",
      "Epoch 88/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1247 - accuracy: 0.6014\n",
      "Epoch 89/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1119 - accuracy: 0.6014\n",
      "Epoch 90/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1102 - accuracy: 0.6054\n",
      "Epoch 91/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1297 - accuracy: 0.6007\n",
      "Epoch 92/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1047 - accuracy: 0.6062\n",
      "Epoch 93/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1118 - accuracy: 0.6047\n",
      "Epoch 94/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1282 - accuracy: 0.5996\n",
      "Epoch 95/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1158 - accuracy: 0.6047\n",
      "Epoch 96/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1085 - accuracy: 0.6051\n",
      "Epoch 97/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1177 - accuracy: 0.6025\n",
      "Epoch 98/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1137 - accuracy: 0.6036\n",
      "Epoch 99/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1170 - accuracy: 0.6043\n",
      "Epoch 100/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1095 - accuracy: 0.6047\n",
      "Epoch 101/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1206 - accuracy: 0.6032\n",
      "Epoch 102/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1112 - accuracy: 0.6047\n",
      "Epoch 103/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1054 - accuracy: 0.6069\n",
      "Epoch 104/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1093 - accuracy: 0.6054\n",
      "Epoch 105/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1019 - accuracy: 0.6066\n",
      "Epoch 106/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1207 - accuracy: 0.6029\n",
      "Epoch 107/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1154 - accuracy: 0.6051\n",
      "Epoch 108/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1124 - accuracy: 0.6043\n",
      "Epoch 109/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1080 - accuracy: 0.6058\n",
      "Epoch 110/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.6088\n",
      "Epoch 111/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1122 - accuracy: 0.6036\n",
      "Epoch 112/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1048 - accuracy: 0.6058\n",
      "Epoch 113/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1176 - accuracy: 0.6040\n",
      "Epoch 114/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1008 - accuracy: 0.6080\n",
      "Epoch 115/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1110 - accuracy: 0.6051\n",
      "Epoch 116/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1000 - accuracy: 0.6073\n",
      "Epoch 117/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.6080\n",
      "Epoch 118/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0987 - accuracy: 0.6073\n",
      "Epoch 119/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1131 - accuracy: 0.6047\n",
      "Epoch 120/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1058 - accuracy: 0.6069\n",
      "Epoch 121/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1049 - accuracy: 0.6058\n",
      "Epoch 122/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1023 - accuracy: 0.6058\n",
      "Epoch 123/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1135 - accuracy: 0.6025\n",
      "Epoch 124/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1027 - accuracy: 0.6062\n",
      "Epoch 125/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1005 - accuracy: 0.6088\n",
      "Epoch 126/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1122 - accuracy: 0.6047\n",
      "Epoch 127/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1009 - accuracy: 0.6058\n",
      "Epoch 128/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.6091\n",
      "Epoch 129/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1151 - accuracy: 0.6043\n",
      "Epoch 130/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.6073\n",
      "Epoch 131/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.6084\n",
      "Epoch 132/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1083 - accuracy: 0.6066\n",
      "Epoch 133/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0988 - accuracy: 0.6062\n",
      "Epoch 134/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.6069\n",
      "Epoch 135/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.6073\n",
      "Epoch 136/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0869 - accuracy: 0.6102\n",
      "Epoch 137/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.6084\n",
      "Epoch 138/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.6077\n",
      "Epoch 139/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1200 - accuracy: 0.6040\n",
      "Epoch 140/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0908 - accuracy: 0.6077\n",
      "Epoch 141/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.6073\n",
      "Epoch 142/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1011 - accuracy: 0.6073\n",
      "Epoch 143/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.6069\n",
      "Epoch 144/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.6095\n",
      "Epoch 145/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0836 - accuracy: 0.6121\n",
      "Epoch 146/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1117 - accuracy: 0.6043\n",
      "Epoch 147/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1030 - accuracy: 0.6073\n",
      "Epoch 148/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0935 - accuracy: 0.6091\n",
      "Epoch 149/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1083 - accuracy: 0.6043\n",
      "Epoch 150/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.6091\n",
      "Epoch 151/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0831 - accuracy: 0.6110\n",
      "Epoch 152/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0814 - accuracy: 0.6128\n",
      "Epoch 153/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1075 - accuracy: 0.6066\n",
      "Epoch 154/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0939 - accuracy: 0.6077\n",
      "Epoch 155/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.6073\n",
      "Epoch 156/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1065 - accuracy: 0.6051\n",
      "Epoch 157/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1003 - accuracy: 0.6088\n",
      "Epoch 158/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0872 - accuracy: 0.6106\n",
      "Epoch 159/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0911 - accuracy: 0.6091\n",
      "Epoch 160/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.6077\n",
      "Epoch 161/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1092 - accuracy: 0.6054\n",
      "Epoch 162/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.6091\n",
      "Epoch 163/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.6091\n",
      "Epoch 164/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0875 - accuracy: 0.6088\n",
      "Epoch 165/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0897 - accuracy: 0.6095\n",
      "Epoch 166/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.6084\n",
      "Epoch 167/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.6099\n",
      "Epoch 168/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0884 - accuracy: 0.6099\n",
      "Epoch 169/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0935 - accuracy: 0.6088\n",
      "Epoch 170/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.6069\n",
      "Epoch 171/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1110 - accuracy: 0.6043\n",
      "Epoch 172/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.6069\n",
      "Epoch 173/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0941 - accuracy: 0.6077\n",
      "Epoch 174/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.6062\n",
      "Epoch 175/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0837 - accuracy: 0.6099\n",
      "Epoch 176/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.6095\n",
      "Epoch 177/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0805 - accuracy: 0.6135\n",
      "Epoch 178/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0875 - accuracy: 0.6110\n",
      "Epoch 179/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1039 - accuracy: 0.6062\n",
      "Epoch 180/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1027 - accuracy: 0.6051\n",
      "Epoch 181/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1042 - accuracy: 0.6084\n",
      "Epoch 182/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.6084\n",
      "Epoch 183/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.6084\n",
      "Epoch 184/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1001 - accuracy: 0.6084\n",
      "Epoch 185/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.6088\n",
      "Epoch 186/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0866 - accuracy: 0.6102\n",
      "Epoch 187/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.6088\n",
      "Epoch 188/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.6062\n",
      "Epoch 189/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0881 - accuracy: 0.6102\n",
      "Epoch 190/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1052 - accuracy: 0.6047\n",
      "Epoch 191/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0998 - accuracy: 0.6084\n",
      "Epoch 192/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0828 - accuracy: 0.6113\n",
      "Epoch 193/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1138 - accuracy: 0.6047\n",
      "Epoch 194/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0903 - accuracy: 0.6099\n",
      "Epoch 195/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0852 - accuracy: 0.6106\n",
      "Epoch 196/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0881 - accuracy: 0.6088\n",
      "Epoch 197/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0939 - accuracy: 0.6088\n",
      "Epoch 198/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1093 - accuracy: 0.6066\n",
      "Epoch 199/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.6106\n",
      "Epoch 200/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0790 - accuracy: 0.6124\n",
      "Epoch 201/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1009 - accuracy: 0.6058\n",
      "Epoch 202/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.6077\n",
      "Epoch 203/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.6069\n",
      "Epoch 204/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0862 - accuracy: 0.6106\n",
      "Epoch 205/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0904 - accuracy: 0.6102\n",
      "Epoch 206/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0911 - accuracy: 0.6091\n",
      "Epoch 207/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.6080\n",
      "Epoch 208/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1100 - accuracy: 0.6058\n",
      "Epoch 209/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1022 - accuracy: 0.6040\n",
      "Epoch 210/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0874 - accuracy: 0.6099\n",
      "Epoch 211/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0902 - accuracy: 0.6095\n",
      "Epoch 212/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0837 - accuracy: 0.6102\n",
      "Epoch 213/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0886 - accuracy: 0.6099\n",
      "Epoch 214/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1026 - accuracy: 0.6062\n",
      "Epoch 215/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.6091\n",
      "Epoch 216/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.6102\n",
      "Epoch 217/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0860 - accuracy: 0.6102\n",
      "Epoch 218/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0873 - accuracy: 0.6095\n",
      "Epoch 219/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1078 - accuracy: 0.6062\n",
      "Epoch 220/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0880 - accuracy: 0.6091\n",
      "Epoch 221/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.6102\n",
      "Epoch 222/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0821 - accuracy: 0.6132\n",
      "Epoch 223/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0751 - accuracy: 0.6143\n",
      "Epoch 224/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0868 - accuracy: 0.6099\n",
      "Epoch 225/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.1228 - accuracy: 0.6014\n",
      "Epoch 226/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1067 - accuracy: 0.6040\n",
      "Epoch 227/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.6091\n",
      "Epoch 228/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0852 - accuracy: 0.6106\n",
      "Epoch 229/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0859 - accuracy: 0.6110\n",
      "Epoch 230/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.6088\n",
      "Epoch 231/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0864 - accuracy: 0.6110\n",
      "Epoch 232/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1034 - accuracy: 0.6058\n",
      "Epoch 233/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1034 - accuracy: 0.6066\n",
      "Epoch 234/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.6069\n",
      "Epoch 235/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0903 - accuracy: 0.6084\n",
      "Epoch 236/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.6095\n",
      "Epoch 237/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1101 - accuracy: 0.6043\n",
      "Epoch 238/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0877 - accuracy: 0.6102\n",
      "Epoch 239/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0841 - accuracy: 0.6113\n",
      "Epoch 240/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0891 - accuracy: 0.6099\n",
      "Epoch 241/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1058 - accuracy: 0.6054\n",
      "Epoch 242/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.6080\n",
      "Epoch 243/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0890 - accuracy: 0.6102\n",
      "Epoch 244/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1006 - accuracy: 0.6073\n",
      "Epoch 245/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.6095\n",
      "Epoch 246/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0849 - accuracy: 0.6110\n",
      "Epoch 247/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0850 - accuracy: 0.6091\n",
      "Epoch 248/400\n",
      "680/680 [==============================] - 2s 3ms/step - loss: 0.1029 - accuracy: 0.6077\n",
      "Epoch 249/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0886 - accuracy: 0.6095\n",
      "Epoch 250/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0910 - accuracy: 0.6095\n",
      "Epoch 251/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0954 - accuracy: 0.6099\n",
      "Epoch 252/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1001 - accuracy: 0.6066\n",
      "Epoch 253/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.6080\n",
      "Epoch 254/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1011 - accuracy: 0.6073\n",
      "Epoch 255/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1039 - accuracy: 0.6062\n",
      "Epoch 256/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0876 - accuracy: 0.6084\n",
      "Epoch 257/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0780 - accuracy: 0.6128\n",
      "Epoch 258/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0877 - accuracy: 0.6110\n",
      "Epoch 259/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.6084\n",
      "Epoch 260/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.6084\n",
      "Epoch 261/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.6099\n",
      "Epoch 262/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0838 - accuracy: 0.6106\n",
      "Epoch 263/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0889 - accuracy: 0.6113\n",
      "Epoch 264/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0891 - accuracy: 0.6088\n",
      "Epoch 265/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0988 - accuracy: 0.6073\n",
      "Epoch 266/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0891 - accuracy: 0.6110\n",
      "Epoch 267/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.6080\n",
      "Epoch 268/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1065 - accuracy: 0.6066\n",
      "Epoch 269/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.6088\n",
      "Epoch 270/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1015 - accuracy: 0.6062\n",
      "Epoch 271/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.6088\n",
      "Epoch 272/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0819 - accuracy: 0.6128\n",
      "Epoch 273/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0840 - accuracy: 0.6110\n",
      "Epoch 274/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1034 - accuracy: 0.6077\n",
      "Epoch 275/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.6062\n",
      "Epoch 276/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0947 - accuracy: 0.6069\n",
      "Epoch 277/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0960 - accuracy: 0.6077\n",
      "Epoch 278/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0840 - accuracy: 0.6110\n",
      "Epoch 279/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0939 - accuracy: 0.6077\n",
      "Epoch 280/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1001 - accuracy: 0.6077\n",
      "Epoch 281/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.1018 - accuracy: 0.6066\n",
      "Epoch 282/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0971 - accuracy: 0.6084\n",
      "Epoch 283/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0925 - accuracy: 0.6084\n",
      "Epoch 284/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1020 - accuracy: 0.6066\n",
      "Epoch 285/400\n",
      "680/680 [==============================] - 2s 3ms/step - loss: 0.0858 - accuracy: 0.6099\n",
      "Epoch 286/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0869 - accuracy: 0.6110\n",
      "Epoch 287/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.1053 - accuracy: 0.6054\n",
      "Epoch 288/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.6091\n",
      "Epoch 289/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0812 - accuracy: 0.6117\n",
      "Epoch 290/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.6091\n",
      "Epoch 291/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0841 - accuracy: 0.6113\n",
      "Epoch 292/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.6095\n",
      "Epoch 293/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0888 - accuracy: 0.6102\n",
      "Epoch 294/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0903 - accuracy: 0.6099\n",
      "Epoch 295/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.6095\n",
      "Epoch 296/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1068 - accuracy: 0.6069\n",
      "Epoch 297/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.6069\n",
      "Epoch 298/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0854 - accuracy: 0.6113\n",
      "Epoch 299/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0876 - accuracy: 0.6099\n",
      "Epoch 300/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1058 - accuracy: 0.6073\n",
      "Epoch 301/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0888 - accuracy: 0.6099\n",
      "Epoch 302/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0880 - accuracy: 0.6099\n",
      "Epoch 303/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1076 - accuracy: 0.6066\n",
      "Epoch 304/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0892 - accuracy: 0.6091\n",
      "Epoch 305/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.6099\n",
      "Epoch 306/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0856 - accuracy: 0.6110\n",
      "Epoch 307/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.6091\n",
      "Epoch 308/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0828 - accuracy: 0.6106\n",
      "Epoch 309/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1098 - accuracy: 0.6051\n",
      "Epoch 310/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.6102\n",
      "Epoch 311/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0867 - accuracy: 0.6113\n",
      "Epoch 312/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0987 - accuracy: 0.6066\n",
      "Epoch 313/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1051 - accuracy: 0.6080\n",
      "Epoch 314/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0911 - accuracy: 0.6091\n",
      "Epoch 315/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.6099\n",
      "Epoch 316/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0839 - accuracy: 0.6132\n",
      "Epoch 317/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0854 - accuracy: 0.6121\n",
      "Epoch 318/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.6069\n",
      "Epoch 319/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.6066\n",
      "Epoch 320/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.6113\n",
      "Epoch 321/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0815 - accuracy: 0.6113\n",
      "Epoch 322/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0886 - accuracy: 0.6091\n",
      "Epoch 323/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.6084\n",
      "Epoch 324/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0988 - accuracy: 0.6073\n",
      "Epoch 325/400\n",
      "680/680 [==============================] - 2s 3ms/step - loss: 0.0992 - accuracy: 0.6077\n",
      "Epoch 326/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0877 - accuracy: 0.6113\n",
      "Epoch 327/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0897 - accuracy: 0.6102\n",
      "Epoch 328/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0903 - accuracy: 0.6106\n",
      "Epoch 329/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0879 - accuracy: 0.6095\n",
      "Epoch 330/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0882 - accuracy: 0.6113\n",
      "Epoch 331/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0857 - accuracy: 0.6106\n",
      "Epoch 332/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.6091\n",
      "Epoch 333/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0933 - accuracy: 0.6080\n",
      "Epoch 334/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0857 - accuracy: 0.6110\n",
      "Epoch 335/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0910 - accuracy: 0.6095\n",
      "Epoch 336/400\n",
      "680/680 [==============================] - 2s 3ms/step - loss: 0.0828 - accuracy: 0.6110\n",
      "Epoch 337/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0964 - accuracy: 0.6084\n",
      "Epoch 338/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.6084\n",
      "Epoch 339/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0872 - accuracy: 0.6102\n",
      "Epoch 340/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0947 - accuracy: 0.6099\n",
      "Epoch 341/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.6051\n",
      "Epoch 342/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0808 - accuracy: 0.6110\n",
      "Epoch 343/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.6102\n",
      "Epoch 344/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.6080\n",
      "Epoch 345/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0859 - accuracy: 0.6117\n",
      "Epoch 346/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0912 - accuracy: 0.6095\n",
      "Epoch 347/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0853 - accuracy: 0.6110\n",
      "Epoch 348/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.6088\n",
      "Epoch 349/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.6058\n",
      "Epoch 350/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1042 - accuracy: 0.6062\n",
      "Epoch 351/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0816 - accuracy: 0.6121\n",
      "Epoch 352/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0809 - accuracy: 0.6113\n",
      "Epoch 353/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1020 - accuracy: 0.6088\n",
      "Epoch 354/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.6080\n",
      "Epoch 355/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.6088\n",
      "Epoch 356/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0778 - accuracy: 0.6139\n",
      "Epoch 357/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0886 - accuracy: 0.6102\n",
      "Epoch 358/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.6080\n",
      "Epoch 359/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0904 - accuracy: 0.6091\n",
      "Epoch 360/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0826 - accuracy: 0.6121\n",
      "Epoch 361/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1097 - accuracy: 0.6054\n",
      "Epoch 362/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0843 - accuracy: 0.6113\n",
      "Epoch 363/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0903 - accuracy: 0.6091\n",
      "Epoch 364/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0919 - accuracy: 0.6102\n",
      "Epoch 365/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.6084\n",
      "Epoch 366/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0837 - accuracy: 0.6124\n",
      "Epoch 367/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0900 - accuracy: 0.6084\n",
      "Epoch 368/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0796 - accuracy: 0.6121\n",
      "Epoch 369/400\n",
      "680/680 [==============================] - 2s 3ms/step - loss: 0.0832 - accuracy: 0.6113\n",
      "Epoch 370/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0805 - accuracy: 0.6124\n",
      "Epoch 371/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0834 - accuracy: 0.6121\n",
      "Epoch 372/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1171 - accuracy: 0.6025\n",
      "Epoch 373/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0979 - accuracy: 0.6091\n",
      "Epoch 374/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0919 - accuracy: 0.6084\n",
      "Epoch 375/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0880 - accuracy: 0.6099\n",
      "Epoch 376/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0892 - accuracy: 0.6099\n",
      "Epoch 377/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0833 - accuracy: 0.6106\n",
      "Epoch 378/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.6080\n",
      "Epoch 379/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0783 - accuracy: 0.6132\n",
      "Epoch 380/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0789 - accuracy: 0.6132\n",
      "Epoch 381/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.6095\n",
      "Epoch 382/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.6099\n",
      "Epoch 383/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0780 - accuracy: 0.6117\n",
      "Epoch 384/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0936 - accuracy: 0.6088\n",
      "Epoch 385/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0811 - accuracy: 0.6106\n",
      "Epoch 386/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.6088\n",
      "Epoch 387/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.6062\n",
      "Epoch 388/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1037 - accuracy: 0.6062\n",
      "Epoch 389/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.6091\n",
      "Epoch 390/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.6062\n",
      "Epoch 391/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.6091\n",
      "Epoch 392/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0844 - accuracy: 0.6110\n",
      "Epoch 393/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0855 - accuracy: 0.6124\n",
      "Epoch 394/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0895 - accuracy: 0.6106\n",
      "Epoch 395/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.6069\n",
      "Epoch 396/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0820 - accuracy: 0.6113\n",
      "Epoch 397/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0774 - accuracy: 0.6128\n",
      "Epoch 398/400\n",
      "680/680 [==============================] - 2s 3ms/step - loss: 0.0872 - accuracy: 0.6106\n",
      "Epoch 399/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.1089 - accuracy: 0.6047\n",
      "Epoch 400/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0852 - accuracy: 0.6110\n"
     ]
    }
   ],
   "source": [
    "classTrain = Transformer.toClassification(activitiesTrain)\n",
    "classVal = Transformer.toClassification(activitiesValidate)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.01,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False\n",
    ")\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "l1Reg = 0.001\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(200, input_dim=np.shape(compoundDataTrain)[1], activation='softmax', kernel_regularizer = keras.regularizers.L2(l1Reg)))\n",
    "model2.add(Dense(150, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model2.add(Dense(75, activation='relu', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model2.add(Dense(100, activation='relu', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model2.add(Dense(100, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model2.add(Dense(1, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "\n",
    "model2.compile(loss='MeanSquaredError', optimizer=\"adam\", metrics=['accuracy'])\n",
    "history = model2.fit(compoundDataTrain, Transformer.toClassification(activitiesTrain), epochs=400, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8696cb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "85/85 [==============================] - 1s 2ms/step - loss: 1.8024 - accuracy: 0.6198\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5768 - accuracy: 0.6198\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5297 - accuracy: 0.6198\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5219 - accuracy: 0.6198\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5209 - accuracy: 0.6198\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 72/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 73/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 74/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 75/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 76/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 77/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 78/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 79/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 80/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 81/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 82/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 84/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 85/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 86/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 87/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 88/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 89/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 90/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 91/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 92/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 93/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 94/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 95/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 96/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 97/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 98/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 99/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 100/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(50, input_dim=np.shape(compoundDataTrain)[1], activation='softmax', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model3.add(Dense(100, activation='softmax', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model3.add(Dense(50, activation='relu', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model3.add(Dense(75, activation='relu', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model3.add(Dense(100, activation='relu', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model3.add(Dense(75, activation='relu', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model3.add(Dense(100, activation='relu', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model3.add(Dense(1, activation='softmax', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "\n",
    "model3.compile(loss='MeanSquaredError', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model3.fit(compoundDataTrain, toClassification(activitiesTrain), epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10ae6a36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 7ms/step\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 5ms/step\n",
      "0.5282698961937716\n",
      "11/11 [==============================] - 0s 4ms/step\n",
      "0.5230103806228373\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "0.5216955017301038\n",
      "11/11 [==============================] - 0s 5ms/step\n",
      "0.611764705882353\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(toClassification(activitiesValidate) == takeVote([model1,model2,model3], compoundDataValidate, toClassification(activitiesValidate))))\n",
    "print(np.mean(toClassification(activitiesValidate) == np.sign(model1.predict(compoundDataValidate))))\n",
    "print(np.mean(toClassification(activitiesValidate) == np.sign(model2.predict(compoundDataValidate))))\n",
    "print(np.mean(toClassification(activitiesValidate) == np.sign(model3.predict(compoundDataValidate))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf7d172",
   "metadata": {},
   "source": [
    "# Using the PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31714ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bcut2d retention: [0.99364773]\n",
      "\ttotal: 99.36477273412302%\n",
      "chi retention: [0.9541968]\n",
      "\ttotal: 95.41967968597899%\n",
      "paoe retention: [0.31495127 0.19509321 0.1390042  0.08838179 0.07155396 0.04590061\n",
      " 0.03243    0.02673268 0.02402293]\n",
      "\ttotal: 93.80706737004664%\n",
      "smr retention: [0.50634726 0.24568468 0.08792319 0.07435827]\n",
      "\ttotal: 91.43133907840063%\n",
      "slogp retention: [0.44620276 0.22134465 0.15753302 0.04213752 0.03159298 0.02850562]\n",
      "\ttotal: 92.73165471968959%\n",
      "estate_vsa retention: [0.29224011 0.18964809 0.14361318 0.10642656 0.07394495 0.06391846\n",
      " 0.05513575]\n",
      "\ttotal: 92.49271047439834%\n",
      "vsa_estate retention: [0.49255304 0.32866098 0.09719245]\n",
      "\ttotal: 91.8406466921681%\n",
      "fr retention: [0.32153498 0.12578177 0.09944384 0.0570485  0.05494644 0.04503917\n",
      " 0.03646285 0.02896244 0.02597271 0.02289905 0.01957315 0.01726898\n",
      " 0.01514303 0.01174714 0.01137825 0.00991646]\n",
      "\ttotal: 90.3118780556795%\n",
      "(2717, 95)\n",
      "0:\t docking_score_max \t [ 0.54137366 -0.97391487  0.43313876]\n",
      "1:\t fusion_score_max \t [ 0.22982864 -0.21361802 -0.43605853]\n",
      "2:\t maxestateindex \t [ 0.71432919 -0.56599863  0.21930044]\n",
      "3:\t minestateindex \t [ 0.48385507  0.79904217 -1.7931574 ]\n",
      "4:\t maxabsestateindex \t [ 0.71432919 -0.56599863  0.21930044]\n",
      "5:\t minabsestateindex \t [-0.06456096  0.18949075 -0.24529827]\n",
      "6:\t qed \t [ 0.60721136  1.31222335 -1.23602991]\n",
      "7:\t molwt \t [-0.27660027 -1.44215299  0.99425952]\n",
      "8:\t heavyatommolwt \t [-0.28960766 -1.41156473  0.97272789]\n",
      "9:\t exactmolwt \t [-0.27415287 -1.44359213  0.99605943]\n",
      "10:\t numvalenceelectrons \t [-0.14475542 -1.4771032   1.05865548]\n",
      "11:\t numradicalelectrons \t [0. 0. 0.]\n",
      "12:\t maxpartialcharge \t [-0.01918824 -0.01918824 -0.01918824]\n",
      "13:\t minpartialcharge \t [ 0.4220889   0.90020181 -3.88640448]\n",
      "14:\t maxabspartialcharge \t [-0.01918824 -0.01918824 -0.01918824]\n",
      "15:\t minabspartialcharge \t [ 0.65606526 -0.81298354  1.78677514]\n",
      "16:\t fpdensitymorgan1 \t [ 0.08342908  1.39774406 -0.23795451]\n",
      "17:\t fpdensitymorgan2 \t [-0.46067125  1.69820278 -0.63886403]\n",
      "18:\t fpdensitymorgan3 \t [-0.66103366  1.82492852 -0.89312556]\n",
      "19:\t bcut2d_0 \t [-0.86725643  0.56074928  0.28408309]\n",
      "20:\t balabanj \t [0.99292347 0.20145137 0.1562656 ]\n",
      "21:\t bertzct \t [ 0.29834167 -0.98750398  0.39154174]\n",
      "22:\t chi_0 \t [-0.19001188 -1.51595199  0.93625562]\n",
      "23:\t hallkieralpha \t [-0.66260507  0.67276232 -0.45395392]\n",
      "24:\t ipc \t [-0.01922525 -0.01922525 -0.01922524]\n",
      "25:\t kappa1 \t [-0.09391701 -1.48518679  1.24505763]\n",
      "26:\t kappa2 \t [-0.16916625 -1.29636776  1.4347257 ]\n",
      "27:\t kappa3 \t [-0.34990588 -1.11242498  1.72283944]\n",
      "28:\t labuteasa \t [-0.22770266 -1.44545582  0.91890831]\n",
      "29:\t paoe_0 \t [ 0.26717753 -1.03842931  1.63415448]\n",
      "30:\t paoe_1 \t [ 0.1265938  -1.16791151 -1.05564712]\n",
      "31:\t paoe_2 \t [1.22722575 1.02271031 0.93436834]\n",
      "32:\t paoe_3 \t [-0.53830346 -0.16010623  1.55109242]\n",
      "33:\t paoe_4 \t [-0.58285634  2.19808805 -0.25855801]\n",
      "34:\t paoe_5 \t [ 0.11014234 -0.31727908 -0.06928123]\n",
      "35:\t paoe_6 \t [-0.50979752 -0.57563653  0.8065238 ]\n",
      "36:\t paoe_7 \t [-0.70954064 -0.58130068  1.58415506]\n",
      "37:\t paoe_8 \t [ 2.08615955 -0.23355752 -0.1114474 ]\n",
      "38:\t smr_0 \t [-0.66705942 -0.75399095  0.58126347]\n",
      "39:\t smr_1 \t [ 0.97782086 -0.87021184  1.13215409]\n",
      "40:\t smr_2 \t [-0.87578583 -0.74339035 -0.47963795]\n",
      "41:\t smr_3 \t [ 0.81434065 -1.11223516 -0.00851804]\n",
      "42:\t slogp_0 \t [-0.28283817 -1.14433037  0.55986442]\n",
      "43:\t slogp_1 \t [ 0.0606956  -0.98033892  1.10041637]\n",
      "44:\t slogp_2 \t [-1.32486408 -0.10401736  0.33030096]\n",
      "45:\t slogp_3 \t [-1.45400729  0.4500064  -0.00923648]\n",
      "46:\t slogp_4 \t [-1.20830698 -0.12851074 -1.26879123]\n",
      "47:\t slogp_5 \t [ 1.52824194 -0.46419297 -0.42881777]\n",
      "48:\t tpsa \t [ 0.0691815  -0.65472856  1.79522788]\n",
      "49:\t estate_vsa_0 \t [ 0.12295516 -0.5559309   0.18617765]\n",
      "50:\t estate_vsa_1 \t [ 0.30264699 -1.22797379  2.83297702]\n",
      "51:\t estate_vsa_2 \t [-0.26266906  0.07522526 -1.00566628]\n",
      "52:\t estate_vsa_3 \t [-1.58114828 -0.41222223 -1.60649386]\n",
      "53:\t estate_vsa_4 \t [ 0.37939916 -0.57873168  0.51705809]\n",
      "54:\t estate_vsa_5 \t [-0.6704072   0.52604179 -0.07558698]\n",
      "55:\t estate_vsa_6 \t [ 1.35916044 -1.06609115 -0.79445585]\n",
      "56:\t vsa_estate_0 \t [-0.18522007 -0.67727467  0.98605622]\n",
      "57:\t vsa_estate_1 \t [ 0.48120394 -0.68728237  0.68849454]\n",
      "58:\t vsa_estate_2 \t [-1.15595038 -0.48802421  0.60098862]\n",
      "59:\t fractioncsp3 \t [-0.48984341 -1.46422972  0.55642384]\n",
      "60:\t heavyatomcount \t [-0.12326793 -1.42968945  0.9456224 ]\n",
      "61:\t nhohcount \t [ 0.58956448 -0.04558488  1.22471384]\n",
      "62:\t nocount \t [-0.12658057 -0.85138441  1.3230271 ]\n",
      "63:\t numaliphaticcarbocycles \t [-0.52172007 -0.52172007 -0.52172007]\n",
      "64:\t numaliphaticheterocycles \t [-1.22063861 -1.22063861  0.10754525]\n",
      "65:\t numaliphaticrings \t [-1.18252489 -1.18252489 -0.24772125]\n",
      "66:\t numaromaticcarbocycles \t [ 0.54061178 -0.6783444   0.54061178]\n",
      "67:\t numaromaticheterocycles \t [ 0.08601029  1.39887527 -1.22685468]\n",
      "68:\t numaromaticrings \t [ 0.4552267   0.4552267  -0.43909792]\n",
      "69:\t numhacceptors \t [-0.12624794 -1.04340208  1.24948328]\n",
      "70:\t numhdonors \t [0.00847934 0.00847934 1.36367795]\n",
      "71:\t numheteroatoms \t [-0.23940001 -0.88661375  1.05502749]\n",
      "72:\t numrotatablebonds \t [-0.15276249 -0.95921783  1.72896664]\n",
      "73:\t numsaturatedcarbocycles \t [-0.50306549 -0.50306549 -0.50306549]\n",
      "74:\t numsaturatedheterocycles \t [-0.89820391 -0.89820391  0.51817451]\n",
      "75:\t numsaturatedrings \t [-0.89110418 -0.89110418  0.05280617]\n",
      "76:\t ringcount \t [-0.62295928 -0.62295928 -0.62295928]\n",
      "77:\t mollogp \t [-0.24151028 -0.35061494 -0.82036947]\n",
      "78:\t molmr \t [-0.05866906 -1.42996965  0.81601639]\n",
      "79:\t fr_0 \t [-0.72077301 -0.61863198  1.13457513]\n",
      "80:\t fr_1 \t [ 0.08763615  0.4400934  -1.05976407]\n",
      "81:\t fr_2 \t [-0.11609331 -0.35559331 -0.11303387]\n",
      "82:\t fr_3 \t [-0.4886912  -1.230091   -0.09889361]\n",
      "83:\t fr_4 \t [-1.03793866 -0.5773771  -0.5624848 ]\n",
      "84:\t fr_5 \t [0.48940829 1.41403927 0.11513954]\n",
      "85:\t fr_6 \t [-0.79367874  0.35416397 -0.10014704]\n",
      "86:\t fr_7 \t [-0.86225407 -0.19004573 -0.75753721]\n",
      "87:\t fr_8 \t [ 0.57083627 -0.06425118  0.26186175]\n",
      "88:\t fr_9 \t [-0.38182447 -0.18104489  1.12066257]\n",
      "89:\t fr_10 \t [-1.13681931 -0.72819738 -0.58025705]\n",
      "90:\t fr_11 \t [ 0.77784503 -1.1681435   1.04323923]\n",
      "91:\t fr_12 \t [ 1.07204049 -0.42261854 -0.83921541]\n",
      "92:\t fr_13 \t [-0.29500432  0.76181309 -1.53432523]\n",
      "93:\t fr_14 \t [ 2.68588745 -0.43773941 -1.20223751]\n",
      "94:\t fr_15 \t [-1.4508937  -0.18868834  0.52723152]\n"
     ]
    }
   ],
   "source": [
    "compoundsTrain, smilesTrain, labelsTrain, compoundDataTrain, activitiesTrain = Loader.getTrain(defaultValue=0)\n",
    "compoundsTest, smilesTest, labelsTest, compoundDataTest, activitiesTest = Loader.getTest(defaultValue=0)\n",
    "compoundsValidate, smilesValidate, labelsValidate, compoundDataValidate, activitiesValidate = Loader.getValidate(defaultValue=0)\n",
    "\n",
    "\n",
    "labelsPCA, trainPCA, testPCA, valPCA = Transformer.applyPCA(labelsTrain,  compoundDataTrain, \n",
    "                                                            compoundDataTest, compoundDataValidate,\n",
    "                                                            endDims=[1,1,9,4,6,7,3,16])\n",
    "\n",
    "labelsMeanPCA, trainMeanPCA = Transformer.useAverageFD(labelsPCA, trainPCA)\n",
    "_, testMeanPCA = Transformer.useAverageFD(labelsPCA, testPCA)\n",
    "_, valMeanPCA = Transformer.useAverageFD(labelsPCA, valPCA)\n",
    "\n",
    "labelsMaxPCA, trainMaxPCA = Transformer.useMaxFD(labelsPCA, trainPCA)\n",
    "_, testMaxPCA = Transformer.useMaxFD(labelsPCA, testPCA)\n",
    "_, valMaxPCA = Transformer.useMaxFD(labelsPCA, valPCA)\n",
    "\n",
    "#after transformations are done assign data\n",
    "dataLabels = labelsMaxPCA\n",
    "trainData = trainMaxPCA\n",
    "testData = testMaxPCA\n",
    "valData = valMaxPCA\n",
    "\n",
    "trainData, testData, valData = Transformer.normalizeData(trainData, testData, valData, newMean=0, newStd=1)\n",
    "\n",
    "print(np.shape(trainData))\n",
    "for i in range(len(dataLabels)):\n",
    "    print(i, \"\\b:\\t\", dataLabels[i], \"\\t\", trainData[0:3,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b715df4d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a3cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=20000,\n",
    "    decay_rate=0.9)\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(200, input_dim=np.shape(trainData[79:])[1], activation='softmax', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model1.add(Dense(150, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model1.add(Dense(100, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model1.add(Dense(1, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "\n",
    "model1.compile(loss='MeanSquaredError', optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model1.fit(trainData[79:], toClassification(activitiesTrain),epochs=400, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
