{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "babd4f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import Loader\n",
    "import tensorflow as tf\n",
    "import Transformer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "compoundsTrain, smilesTrain, labelsTrain, compoundDataTrain, activitiesTrain = Loader.getTrain(defaultValue=0)\n",
    "compoundsTest, smilesTest, labelsTest, compoundDataTest, activitiesTest = Loader.getTest(defaultValue=0)\n",
    "compoundsValidate, smilesValidate, labelsValidate, compoundDataValidate, activitiesValidate = Loader.getValidate(defaultValue=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55df6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l1Reg = keras.regularizers.L1(.001)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False\n",
    ")\n",
    "\n",
    "\n",
    "def runPCASVM(Xtrain, Ytrain, labelsTrain, compoundDataTest, compoundDataValidate):\n",
    "    \n",
    "    labelsPCA, trainPCA, testPCA, valPCA = Transformer.applyPCA(labelsTrain,  Xtrain, \n",
    "                                                        compoundDataTest, compoundDataValidate,\n",
    "                                                        endDims=[1,1,9,4,6,7,3,16], muted = True)\n",
    "\n",
    "    labelsMeanPCA, trainMeanPCA = Transformer.useAverageFD(labelsPCA, trainPCA)\n",
    "    _, testMeanPCA = Transformer.useAverageFD(labelsPCA, testPCA)\n",
    "    _, valMeanPCA = Transformer.useAverageFD(labelsPCA, valPCA)\n",
    "\n",
    "    labelsMaxPCA, trainMaxPCA = Transformer.useMaxFD(labelsPCA, trainPCA)\n",
    "    _, testMaxPCA = Transformer.useMaxFD(labelsPCA, testPCA)\n",
    "    _, valMaxPCA = Transformer.useMaxFD(labelsPCA, valPCA)\n",
    "\n",
    "    #after transformations are done assign data\n",
    "    dataLabels = labelsMaxPCA\n",
    "    trainData = trainMaxPCA\n",
    "    testData = testMaxPCA\n",
    "    valData = valMaxPCA\n",
    "\n",
    "    Xtrain,_,valData = Transformer.normalizeData(trainData, testData, valData, newMean=0, newStd=1)\n",
    "    \n",
    "    \n",
    "    maxC=10**-.01\n",
    "    clf=svm.SVC(\n",
    "        C=maxC,                          # The regularization parameter\n",
    "        kernel='rbf',                   # The kernel type used \n",
    "        degree=4,                       # Degree of polynomial function \n",
    "        gamma='scale',                  # The kernel coefficient\n",
    "        coef0=0.0,                      # If kernel = 'poly'/'sigmoid'\n",
    "        shrinking=True,                 # To use shrinking heuristic\n",
    "        probability=False,              # Enable probability estimates\n",
    "        tol=0.001,                      # Stopping crierion\n",
    "        cache_size=200,                 # Size of kernel cache\n",
    "        class_weight=None,              # The weight of each class\n",
    "        verbose=False,                  # Enable verbose output\n",
    "        max_iter=- 1,                   # Hard limit on iterations\n",
    "        decision_function_shape='ovr',  # One-vs-rest or one-vs-one\n",
    "        break_ties=False,               # How to handle breaking ties\n",
    "        random_state=None               # Random state of the model\n",
    "    )\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    predictions = clf.predict(Xtrain)\n",
    "    val_pred = clf.predict(valData)\n",
    "    return [predictions, val_pred]\n",
    "    \n",
    "def runBacicSVM(Xtrain, Ytrain, compoundDataTest, compoundDataValidate):\n",
    "    maxC=10**-.01\n",
    "    clf=svm.SVC(\n",
    "        C=maxC,                          # The regularization parameter\n",
    "        kernel='rbf',                   # The kernel type used \n",
    "        degree=4,                       # Degree of polynomial function \n",
    "        gamma='scale',                  # The kernel coefficient\n",
    "        coef0=0.0,                      # If kernel = 'poly'/'sigmoid'\n",
    "        shrinking=True,                 # To use shrinking heuristic\n",
    "        probability=False,              # Enable probability estimates\n",
    "        tol=0.001,                      # Stopping crierion\n",
    "        cache_size=200,                 # Size of kernel cache\n",
    "        class_weight=None,              # The weight of each class\n",
    "        verbose=False,                  # Enable verbose output\n",
    "        max_iter=- 1,                   # Hard limit on iterations\n",
    "        decision_function_shape='ovr',  # One-vs-rest or one-vs-one\n",
    "        break_ties=False,               # How to handle breaking ties\n",
    "        random_state=None               # Random state of the model\n",
    "    )\n",
    "    Xtrain,_,valData = Transformer.normalizeData(Xtrain, compoundDataTest, compoundDataValidate, newMean=0, newStd=1)\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    predictions = clf.predict(Xtrain)\n",
    "    val_pred = clf.predict(valData)\n",
    "    return [predictions, val_pred]\n",
    "\n",
    "def runMinPCA(Xtrain,Ytrain, labelsTrain, compoundDataTest, compoundDataValidate, classVal):\n",
    "    acc = 0\n",
    "    labelsPCA, trainPCA, testPCA, valPCA = Transformer.applyPCA(labelsTrain,  Xtrain, \n",
    "                                                            compoundDataTest, compoundDataValidate,\n",
    "                                                            endDims=[1,1,2,1,2,3,2,4], muted = True)\n",
    "\n",
    "    labelsMeanPCA, trainMeanPCA = Transformer.useAverageFD(labelsPCA, trainPCA)\n",
    "    _, testMeanPCA = Transformer.useAverageFD(labelsPCA, testPCA)\n",
    "    _, valMeanPCA = Transformer.useAverageFD(labelsPCA, valPCA)\n",
    "\n",
    "    labelsMaxPCA, trainMaxPCA = Transformer.useMaxFD(labelsPCA, trainPCA)\n",
    "    _, testMaxPCA = Transformer.useMaxFD(labelsPCA, testPCA)\n",
    "    _, valMaxPCA = Transformer.useMaxFD(labelsPCA, valPCA)\n",
    "\n",
    "    #after transformations are done assign data\n",
    "    dataLabels = labelsMaxPCA\n",
    "    trainData = trainMaxPCA\n",
    "    testData = testMaxPCA\n",
    "    valData = valMaxPCA\n",
    "\n",
    "    trainData,_,valData = Transformer.normalizeData(trainData, testData, valData, newMean=0, newStd=1)\n",
    "\n",
    "    \n",
    "        \n",
    "    while(acc < .7):\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(len(dataLabels), activation='relu', kernel_regularizer = l1Reg),\n",
    "            tf.keras.layers.Dense(80, activation='relu', kernel_regularizer = l1Reg),\n",
    "            tf.keras.layers.Dense(120, activation='relu', kernel_regularizer = l1Reg),\n",
    "            tf.keras.layers.Dense(100, activation='relu', kernel_regularizer = l1Reg),\n",
    "            tf.keras.layers.Dense(80, activation='relu', kernel_regularizer = l1Reg),\n",
    "            tf.keras.layers.Dense(40, activation='relu', kernel_regularizer = l1Reg),\n",
    "            tf.keras.layers.Dense(2, activation='relu', kernel_regularizer = l1Reg)\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=optimizer,loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                   metrics=['accuracy'])\n",
    "    \n",
    "        history = model.fit(trainData, Ytrain, validation_data = (valData, classVal), epochs=100, batch_size=4, verbose = 0)\n",
    "        predictionsTrain = np.argmax(model.predict(trainData), axis=1)\n",
    "        predictionsTest = np.argmax(model.predict(valData), axis=1)\n",
    "        acc = np.mean(predictionsTrain == Ytrain)\n",
    "    return [ predictionsTrain, predictionsTest ]\n",
    "\n",
    "\n",
    "\n",
    "def runBasicNN(Xtrain,Ytrain, labelsTrain, compoundDataTest, compoundDataValidate, classVal):\n",
    "    acc = 0\n",
    "    while(acc < .7):\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(len(labelsTrain), activation='relu', kernel_regularizer = l1Reg),\n",
    "            tf.keras.layers.Dense(200, activation='relu', kernel_regularizer = l1Reg),\n",
    "            tf.keras.layers.Dense(300, activation='relu', kernel_regularizer = l1Reg),\n",
    "            tf.keras.layers.Dense(200, activation='relu', kernel_regularizer = l1Reg),\n",
    "            tf.keras.layers.Dense(100, activation='relu', kernel_regularizer = l1Reg),\n",
    "            tf.keras.layers.Dense(50, activation='relu', kernel_regularizer = l1Reg),\n",
    "            tf.keras.layers.Dense(10, activation='relu', kernel_regularizer = l1Reg),\n",
    "            tf.keras.layers.Dense(2)\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=optimizer,loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "\n",
    "        Xtrain,_,valData = Transformer.normalizeData(Xtrain, compoundDataTest, compoundDataValidate, newMean=0, newStd=1)\n",
    "\n",
    "        history = model.fit(Xtrain, Ytrain, validation_data = (valData, classVal), epochs=100, batch_size=4, verbose = 0)\n",
    "        predictionsTrain = np.argmax(model.predict(Xtrain), axis=1)\n",
    "        predictionsVal = np.argmax(model.predict(valData), axis=1)\n",
    "        acc = np.mean(predictionsTrain == Ytrain)\n",
    "        #print(acc)\n",
    "    return [ predictionsTrain, predictionsVal ]\n",
    "\n",
    "\n",
    "def runPCANN(Xtrain,Ytrain, labelsTrain, compoundDataTest, compoundDataValidate, classVal):\n",
    "    acc = 0\n",
    "    labelsPCA, trainPCA, testPCA, valPCA = Transformer.applyPCA(labelsTrain,  Xtrain, \n",
    "                                                            compoundDataTest, compoundDataValidate,\n",
    "                                                            endDims=[1,1,9,4,6,7,3,16], muted = True)\n",
    "\n",
    "    labelsMeanPCA, trainMeanPCA = Transformer.useAverageFD(labelsPCA, trainPCA)\n",
    "    _, testMeanPCA = Transformer.useAverageFD(labelsPCA, testPCA)\n",
    "    _, valMeanPCA = Transformer.useAverageFD(labelsPCA, valPCA)\n",
    "\n",
    "    labelsMaxPCA, trainMaxPCA = Transformer.useMaxFD(labelsPCA, trainPCA)\n",
    "    _, testMaxPCA = Transformer.useMaxFD(labelsPCA, testPCA)\n",
    "    _, valMaxPCA = Transformer.useMaxFD(labelsPCA, valPCA)\n",
    "\n",
    "    #after transformations are done assign data\n",
    "    dataLabels = labelsMaxPCA\n",
    "    trainData = trainMaxPCA\n",
    "    testData = testMaxPCA\n",
    "    valData = valMaxPCA\n",
    "\n",
    "    Xtrain,_,valData = Transformer.normalizeData(trainData, testData, valData, newMean=0, newStd=1)\n",
    "\n",
    "    \n",
    "    while(acc < .7):\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(len(dataLabels), activation='relu', kernel_regularizer = l1Reg),\n",
    "            tf.keras.layers.Dense(200, activation='relu', kernel_regularizer = l1Reg),\n",
    "            tf.keras.layers.Dense(300, activation='relu', kernel_regularizer = l1Reg),\n",
    "            tf.keras.layers.Dense(200, activation='relu', kernel_regularizer = l1Reg),\n",
    "            tf.keras.layers.Dense(100, activation='relu', kernel_regularizer = l1Reg),\n",
    "            tf.keras.layers.Dense(50, activation='relu', kernel_regularizer = l1Reg),\n",
    "            tf.keras.layers.Dense(10, activation='relu', kernel_regularizer = l1Reg),\n",
    "            tf.keras.layers.Dense(2)\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=optimizer,loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "        history = model.fit(Xtrain, Ytrain, validation_data = (valData, classVal), epochs=100, batch_size=4, verbose = 0)\n",
    "        predictionsTrain = np.argmax(model.predict(Xtrain), axis=1)\n",
    "        predictionsTest = np.argmax(model.predict(valData), axis=1)\n",
    "        acc = np.mean(predictionsTrain == Ytrain)\n",
    "    return [ predictionsTrain, predictionsTest ]\n",
    "\n",
    "\n",
    "def averageValues(acc, valAcc):\n",
    "    accPlot = []\n",
    "    valAccPlot = []\n",
    "    for i in range(len(acc)):\n",
    "        accuracy = 0\n",
    "        valAccuracy = 0\n",
    "        added = 0\n",
    "\n",
    "        for j in range(len(acc[i])):\n",
    "            if(acc[i][j] > 0.7):\n",
    "                added += 1\n",
    "                accuracy += acc[i][j]\n",
    "                valAccuracy += valAcc[i][j]\n",
    "        if(added == 0):\n",
    "            added = 1\n",
    "        accuracy /= added\n",
    "        valAccuracy /= added\n",
    "        accPlot.append(accuracy)\n",
    "        valAccPlot.append(valAccuracy)\n",
    "    return accPlot, valAccPlot\n",
    "\n",
    "def aggregate(predictions):\n",
    "    yAggregate = np.zeros(len(predictions[0]))\n",
    "    for prediction in predictions:\n",
    "        yAggregate += prediction\n",
    "    return 1 * np.array(yAggregate > (len(predictions) / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2c98a34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 0 % Run: 1\n",
      "85/85 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 4ms/step\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 4ms/step\n",
      "85/85 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "85/85 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "85/85 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "Dropped: 0 % Run: 2\n",
      "85/85 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "85/85 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "Dropped: 0 % Run: 3\n",
      "85/85 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "85/85 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-2938838a0ccc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mcurrentPNNValAccs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistPNN\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mclassVal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mhistMIN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunMinPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelsTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompoundDataTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompoundDataValidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassVal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mcurrentMinAccs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistMIN\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mcurrentMinValAccs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistMIN\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mclassVal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-89ac13ab0af6>\u001b[0m in \u001b[0;36mrunMinPCA\u001b[1;34m(Xtrain, Ytrain, labelsTrain, compoundDataTest, compoundDataValidate, classVal)\u001b[0m\n\u001b[0;32m    119\u001b[0m                    metrics=['accuracy'])\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvalData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassVal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mpredictionsTrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mpredictionsTest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2494\u001b[0m       (graph_function,\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2497\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1863\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classTrain = Transformer.toBinaryClassification(activitiesTrain)\n",
    "classVal = Transformer.toBinaryClassification(activitiesValidate)\n",
    "classTest = Transformer.toBinaryClassification(activitiesTest)\n",
    "\n",
    "\n",
    "dataDropped = [0,.1,.25,.5,.75,.9]\n",
    "#dataDropped = [.75,.9]\n",
    "accBNN = []\n",
    "valAccBNN = []\n",
    "accPNN = []\n",
    "valAccPNN = []\n",
    "accMin = []\n",
    "valAccMin = []\n",
    "accPSVM = []\n",
    "valAccPSVM = []\n",
    "accBSVM = []\n",
    "valAccBSVM = []\n",
    "\n",
    "accAGG = []\n",
    "valAccAGG = []\n",
    "for percent in dataDropped:\n",
    "    currentBNNAccs = []\n",
    "    currentBNNValAccs = []\n",
    "    currentPNNAccs = []\n",
    "    currentPNNValAccs = []\n",
    "    currentMinAccs = []\n",
    "    currentMinValAccs = []\n",
    "    currentPSVMAccs = []\n",
    "    currentPSVMValAccs = []\n",
    "    currentBSVMAccs = []\n",
    "    currentBSVMValAccs = []\n",
    "    \n",
    "    currentAGGAccs = []\n",
    "    currentAGGValAccs = []\n",
    "    \n",
    "    for run in range(10):\n",
    "     \n",
    "        print(\"Dropped:\", percent * 100, \"% Run:\", run + 1)\n",
    "        \n",
    "        if(percent == 0):\n",
    "            Xtrain = compoundDataTrain\n",
    "            Ytrain = classTrain\n",
    "        else:\n",
    "            (Xtrain,_,Ytrain,_) = model_selection.train_test_split(compoundDataTrain, classTrain, test_size=percent)\n",
    "        \n",
    "        histBNN = runBasicNN(Xtrain, Ytrain, labelsTrain, compoundDataTest, compoundDataValidate,classVal)\n",
    "        currentBNNAccs.append(np.mean(histBNN[0] == Ytrain))\n",
    "        currentBNNValAccs.append(np.mean(histBNN[1] == classVal))\n",
    "        \n",
    "        histPNN = runPCANN(Xtrain, Ytrain, labelsTrain, compoundDataTest, compoundDataValidate,classVal)\n",
    "        currentPNNAccs.append(np.mean(histPNN[0] == Ytrain))\n",
    "        currentPNNValAccs.append(np.mean(histPNN[1] == classVal))\n",
    "        \n",
    "        histMIN = runMinPCA(Xtrain, Ytrain, labelsTrain, compoundDataTest, compoundDataValidate,classVal)\n",
    "        currentMinAccs.append(np.mean(histMIN[0] == Ytrain))\n",
    "        currentMinValAccs.append(np.mean(histMIN[1] == classVal))\n",
    "        \n",
    "        histPSVM = runPCASVM(Xtrain, Ytrain, labelsTrain, compoundDataTest, compoundDataValidate)\n",
    "        currentPSVMAccs.append(np.mean(histPSVM[0] == Ytrain))\n",
    "        currentPSVMValAccs.append(np.mean(histPSVM[1] == classVal))\n",
    "        \n",
    "        histBSVM = runBacicSVM(Xtrain, Ytrain , compoundDataTest, compoundDataValidate)\n",
    "        currentBSVMAccs.append(np.mean(histBSVM[0] == Ytrain))\n",
    "        currentBSVMValAccs.append(np.mean(histBSVM[1] == classVal))\n",
    "        \n",
    "        currentAGGAccs.append(np.mean(aggregate([histBNN[0], histPNN[0], histMIN[0], histPSVM[0], histBSVM[0]]) == Ytrain ))\n",
    "        currentAGGValAccs.append(np.mean(aggregate([histBNN[1], histPNN[1], histMIN[1], histPSVM[1], histBSVM[1]]) == classVal ))\n",
    "        #print(currentAGGValAccs)\n",
    "    accBNN.append(currentBNNAccs)\n",
    "    valAccBNN.append(currentBNNValAccs)\n",
    "    accPNN.append(currentPNNAccs)\n",
    "    valAccPNN.append(currentPNNValAccs)\n",
    "    accMin.append(currentMinAccs)\n",
    "    valAccMin.append(currentMinValAccs)\n",
    "    accPSVM.append(currentPSVMAccs)\n",
    "    valAccPSVM.append(currentPSVMValAccs)\n",
    "    accBSVM.append(currentBSVMAccs)\n",
    "    valAccBSVM.append(currentBSVMValAccs)\n",
    "    \n",
    "    accAGG.append(currentAGGAccs)\n",
    "    valAccAGG.append(currentAGGValAccs)\n",
    "        #if (tempHist.history[\"accuracy\"][-1] > .7 ): #Don't include the run if it was a constant guess\n",
    "         #   currentHist.append([tempHist.history[\"accuracy\"][-1], tempHist.history[\"val_accuracy\"][-1]])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "701cf303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNN Acc: [] \n",
      "BNN valAcc: []\n",
      "PNN Acc: [] \n",
      "PNN valAcc: []\n",
      "Min Acc: [] \n",
      "Min valAcc: []\n",
      "PSVM Acc: [] \n",
      "PSVM valAcc: []\n",
      "BSVM Acc: [] \n",
      "BSVM valAcc: []\n",
      "AGG Acc: [] \n",
      "AGG valAcc: []\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (6,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-cf5bcb02fdcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"AGG Acc:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccPlotAGG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\nAGG valAcc:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalAccPlotAGG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataDropped\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccPlotBNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Basic Neural Network\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataDropped\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccPlotPNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"PCA Neural Network\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataDropped\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccPlotMin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Min PCA Neural Network\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1741\u001b[0m         \"\"\"\n\u001b[0;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1743\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1744\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[0;32m    400\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (6,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,8))\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "\n",
    "accPlotBNN, valAccPlotBNN = averageValues(accBNN, valAccBNN)\n",
    "print(\"BNN Acc:\",accPlotBNN, \"\\nBNN valAcc:\", valAccPlotBNN)\n",
    "\n",
    "accPlotPNN, valAccPlotPNN = averageValues(accPNN, valAccPNN)\n",
    "print(\"PNN Acc:\",accPlotPNN, \"\\nPNN valAcc:\", valAccPlotPNN)\n",
    "\n",
    "accPlotMin, valAccPlotMin = averageValues(accMin, valAccMin)\n",
    "print(\"Min Acc:\",accPlotMin, \"\\nMin valAcc:\", valAccPlotMin)\n",
    "\n",
    "accPlotPSVM , valAccPlotPSVM = averageValues(accPSVM , valAccPSVM )\n",
    "print(\"PSVM Acc:\",accPlotPSVM , \"\\nPSVM valAcc:\", valAccPlotPSVM )\n",
    "\n",
    "accPlotBSVM , valAccPlotBSVM = averageValues(accBSVM , valAccBSVM )\n",
    "print(\"BSVM Acc:\",accPlotBSVM , \"\\nBSVM valAcc:\", valAccPlotBSVM )\n",
    "\n",
    "accPlotAGG, valAccPlotAGG = averageValues(accAGG, valAccAGG)\n",
    "print(\"AGG Acc:\",accPlotAGG, \"\\nAGG valAcc:\", valAccPlotAGG)\n",
    "\n",
    "ax.plot(dataDropped,accPlotBNN, label = \"Basic Neural Network\")\n",
    "ax.plot(dataDropped,accPlotPNN, label = \"PCA Neural Network\")\n",
    "ax.plot(dataDropped,accPlotMin, label = \"Min PCA Neural Network\")\n",
    "ax.plot(dataDropped,accPlotPSVM, label = \"PCA Support Vector Machine\")\n",
    "ax.plot(dataDropped,accPlotBSVM, label = \"Basic Support Vector Machine\")\n",
    "ax.plot(dataDropped,accPlotAGG, label = \"Aggregation\")\n",
    "\n",
    "ax.legend(loc = 'right', fontsize = 15)\n",
    "ax.set_title(\"Ein Accuracies at Different Data Percentages (Non PCA)\", fontsize = 20)\n",
    "ax.set_xlabel(\"Dropped Percentage\", fontsize = 20)\n",
    "ax.set_ylabel(\"Accuracy\", fontsize = 20)\n",
    "ax.set_facecolor(\"black\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,8))\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "\n",
    "ax.plot(dataDropped, valAccPlotBNN, label = \"Basic Neural Network\")\n",
    "ax.plot(dataDropped, valAccPlotPNN, label = \"PCA Neural Network\")\n",
    "ax.plot(dataDropped, valAccPlotMin, label = \"Min PCA Neural Network\")\n",
    "ax.plot(dataDropped, valAccPlotPSVM, label = \"PCA Support Vector Machine\")\n",
    "ax.plot(dataDropped, valAccPlotBSVM, label = \"Basic Support Vector Machine\")\n",
    "ax.plot(dataDropped, valAccPlotAGG, label = \"Aggregation\")\n",
    "\n",
    "ax.legend(loc = 'right', fontsize = 15)\n",
    "ax.set_title(\"Eval Accuracies at Different Data Percentages (Non PCA)\", fontsize = 20)\n",
    "ax.set_xlabel(\"Dropped Percentage\", fontsize = 20)\n",
    "ax.set_ylabel(\"Accuracy\", fontsize = 20)\n",
    "ax.set_facecolor(\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcef57b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
