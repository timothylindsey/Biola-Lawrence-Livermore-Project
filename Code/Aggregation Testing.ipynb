{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20bbd8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import Loader\n",
    "import tensorflow as tf\n",
    "import Transformer\n",
    "from sklearn import preprocessing\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "947b37be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2717 340 340\n"
     ]
    }
   ],
   "source": [
    "compoundsTrain, smilesTrain, labelsTrain, compoundDataTrain, activitiesTrain = Loader.getTrain(defaultValue=0)\n",
    "compoundsTest, smilesTest, labelsTest, compoundDataTest, activitiesTest = Loader.getTest(defaultValue=0)\n",
    "compoundsValidate, smilesValidate, labelsValidate, compoundDataValidate, activitiesValidate = Loader.getValidate(defaultValue=0)\n",
    "\n",
    "#print(labelsTrain)\n",
    "#print(compoundsTrain)\n",
    "#print(smilesTrain)\n",
    "#print(activitiesTrain)\n",
    "\n",
    "#for i in range(len(labelsTrain)):\n",
    "#    print(labelsTrain[i] + \": \", compoundDataTrain[0,i])\n",
    "\n",
    "def toClassification(y): # The resulting array will contain values of -1 if it is below 4.5 and 1 if it is above\n",
    "    y = np.array(y)\n",
    "    classification = (y.astype(float)>4).astype(int)\n",
    "    return classification * 2 - 1\n",
    "\n",
    "def normalizeData(train,test,validate):\n",
    "    for i in range(np.shape(train)[1]):\n",
    "        std = np.std(train[:,i])\n",
    "        mean = np.mean(train[:,i])\n",
    "        if(std == 0):\n",
    "            std = 1\n",
    "        train[:,i] = (train[:,i] - mean) / std\n",
    "        test[:,i] = (test[:,i] - mean) / std\n",
    "        validate[:,i] = (validate[:,i] - mean) / std\n",
    "    return train, test, validate\n",
    "\n",
    "def makeAverage(arr): # Averages the ten values for each score and creates a new array\n",
    "    arr = np.array(arr)\n",
    "    newArr = np.empty((np.shape(arr)[0], np.shape(arr)[1] - 18))\n",
    "    newArr[:,0] = np.mean(arr[:,:10], axis = 1)\n",
    "    newArr[:,1] = np.mean(arr[:,10:20], axis = 1)\n",
    "    newArr[:,2:] = arr[:,20:]\n",
    "    return newArr\n",
    "\n",
    "def averageScores(train, test, validate): #wrapper function to handle all conversions at once\n",
    "    newTrain = makeAverage(train)\n",
    "    newTest = makeAverage(test)\n",
    "    newValid = makeAverage(validate)\n",
    "    return newTrain, newTest, newValid\n",
    "    \n",
    "compoundDataTrain, compoundDataTest, compoundDataValidate = averageScores(compoundDataTrain, compoundDataTest, compoundDataValidate)\n",
    "compoundDataTrain, compoundDataTest, compoundDataValidate = normalizeData(compoundDataTrain, compoundDataTest, compoundDataValidate)\n",
    "print(len(compoundsTrain), len(compoundsTest), len(compoundsValidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752ed3b5",
   "metadata": {},
   "source": [
    "# Testing by taking votes from full networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bf8c8378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def takeVote(models, xValidate, yValidate, sameData = True, dataInds = []):\n",
    "    yAggregate = np.zeros(len(yValidate))\n",
    "    if(sameData):\n",
    "        for model in models:\n",
    "            yAggregate = yAggregate + np.sign(model.predict(xValidate))\n",
    "    else:\n",
    "        xValidate = np.array(xValidate)\n",
    "        for i in range(len(models)):\n",
    "            yAggregate = yAggregate + models[i].predict(xValidate[:,dataInds[i][0]:dataInds[i][1]])\n",
    "    return np.sign(yAggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4dc3b946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "85/85 [==============================] - 1s 2ms/step - loss: 5.5849 - accuracy: 0.0000e+00\n",
      "Epoch 2/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.5255 - accuracy: 0.0000e+00\n",
      "Epoch 3/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.4748 - accuracy: 0.0000e+00\n",
      "Epoch 4/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.4228 - accuracy: 0.0000e+00\n",
      "Epoch 5/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.3735 - accuracy: 0.0000e+00\n",
      "Epoch 6/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.3232 - accuracy: 0.0000e+00\n",
      "Epoch 7/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.2726 - accuracy: 0.0000e+00\n",
      "Epoch 8/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.2224 - accuracy: 0.0000e+00\n",
      "Epoch 9/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.1732 - accuracy: 0.0000e+00\n",
      "Epoch 10/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.1235 - accuracy: 0.0000e+00\n",
      "Epoch 11/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.0735 - accuracy: 0.0000e+00\n",
      "Epoch 12/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.0230 - accuracy: 0.0000e+00\n",
      "Epoch 13/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.9713 - accuracy: 0.0000e+00\n",
      "Epoch 14/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.9153 - accuracy: 3.6805e-04\n",
      "Epoch 15/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.8592 - accuracy: 0.0040\n",
      "Epoch 16/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.7957 - accuracy: 0.0372\n",
      "Epoch 17/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.7240 - accuracy: 0.1020\n",
      "Epoch 18/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.6496 - accuracy: 0.1542\n",
      "Epoch 19/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.5786 - accuracy: 0.1932\n",
      "Epoch 20/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.5127 - accuracy: 0.2127\n",
      "Epoch 21/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.4536 - accuracy: 0.2219\n",
      "Epoch 22/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.3840 - accuracy: 0.2282\n",
      "Epoch 23/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.3062 - accuracy: 0.2363\n",
      "Epoch 24/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.2182 - accuracy: 0.2477\n",
      "Epoch 25/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.1442 - accuracy: 0.2724\n",
      "Epoch 26/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.0620 - accuracy: 0.3114\n",
      "Epoch 27/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.9743 - accuracy: 0.3522\n",
      "Epoch 28/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.9091 - accuracy: 0.3861\n",
      "Epoch 29/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.8357 - accuracy: 0.4085\n",
      "Epoch 30/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.7726 - accuracy: 0.4384\n",
      "Epoch 31/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.7092 - accuracy: 0.4582\n",
      "Epoch 32/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.6521 - accuracy: 0.4674\n",
      "Epoch 33/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.5863 - accuracy: 0.4844\n",
      "Epoch 34/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.5358 - accuracy: 0.4958\n",
      "Epoch 35/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.4821 - accuracy: 0.4994\n",
      "Epoch 36/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.4400 - accuracy: 0.5024\n",
      "Epoch 37/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.3856 - accuracy: 0.5086\n",
      "Epoch 38/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.3446 - accuracy: 0.5134\n",
      "Epoch 39/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.2937 - accuracy: 0.5193\n",
      "Epoch 40/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.2586 - accuracy: 0.5175\n",
      "Epoch 41/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.2105 - accuracy: 0.5307\n",
      "Epoch 42/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.1615 - accuracy: 0.5282\n",
      "Epoch 43/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.1209 - accuracy: 0.5326\n",
      "Epoch 44/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.0699 - accuracy: 0.5355\n",
      "Epoch 45/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.0319 - accuracy: 0.5388\n",
      "Epoch 46/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.9848 - accuracy: 0.5410\n",
      "Epoch 47/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.9432 - accuracy: 0.5418\n",
      "Epoch 48/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.9078 - accuracy: 0.5410\n",
      "Epoch 49/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.8619 - accuracy: 0.5491\n",
      "Epoch 50/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.8241 - accuracy: 0.5510\n",
      "Epoch 51/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.7866 - accuracy: 0.5477\n",
      "Epoch 52/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.7491 - accuracy: 0.5513\n",
      "Epoch 53/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.7062 - accuracy: 0.5539\n",
      "Epoch 54/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.6708 - accuracy: 0.5554\n",
      "Epoch 55/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.6319 - accuracy: 0.5550\n",
      "Epoch 56/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.5984 - accuracy: 0.5572\n",
      "Epoch 57/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.5596 - accuracy: 0.5594\n",
      "Epoch 58/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.5248 - accuracy: 0.5628\n",
      "Epoch 59/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.4867 - accuracy: 0.5642\n",
      "Epoch 60/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.4496 - accuracy: 0.5650\n",
      "Epoch 61/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.4167 - accuracy: 0.5624\n",
      "Epoch 62/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.3839 - accuracy: 0.5679\n",
      "Epoch 63/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.3486 - accuracy: 0.5657\n",
      "Epoch 64/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.3141 - accuracy: 0.5683\n",
      "Epoch 65/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.2827 - accuracy: 0.5686\n",
      "Epoch 66/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.2512 - accuracy: 0.5731\n",
      "Epoch 67/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.2192 - accuracy: 0.5720\n",
      "Epoch 68/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.1843 - accuracy: 0.5745\n",
      "Epoch 69/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.1555 - accuracy: 0.5727\n",
      "Epoch 70/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.1209 - accuracy: 0.5738\n",
      "Epoch 71/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.0890 - accuracy: 0.5771\n",
      "Epoch 72/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.0623 - accuracy: 0.5767\n",
      "Epoch 73/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.0292 - accuracy: 0.5808\n",
      "Epoch 74/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.0012 - accuracy: 0.5782\n",
      "Epoch 75/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.9709 - accuracy: 0.5804\n",
      "Epoch 76/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.9415 - accuracy: 0.5786\n",
      "Epoch 77/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.9160 - accuracy: 0.5812\n",
      "Epoch 78/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.8857 - accuracy: 0.5815\n",
      "Epoch 79/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.8563 - accuracy: 0.5841\n",
      "Epoch 80/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.8283 - accuracy: 0.5834\n",
      "Epoch 81/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.8032 - accuracy: 0.5804\n",
      "Epoch 82/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.7735 - accuracy: 0.5848\n",
      "Epoch 83/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.7503 - accuracy: 0.5841\n",
      "Epoch 84/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.7216 - accuracy: 0.5830\n",
      "Epoch 85/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.6957 - accuracy: 0.5848\n",
      "Epoch 86/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.6714 - accuracy: 0.5867\n",
      "Epoch 87/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.6450 - accuracy: 0.5874\n",
      "Epoch 88/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.6194 - accuracy: 0.5867\n",
      "Epoch 89/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5950 - accuracy: 0.5867\n",
      "Epoch 90/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5684 - accuracy: 0.5870\n",
      "Epoch 91/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5444 - accuracy: 0.5896\n",
      "Epoch 92/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5206 - accuracy: 0.5878\n",
      "Epoch 93/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.4968 - accuracy: 0.5885\n",
      "Epoch 94/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.4742 - accuracy: 0.5885\n",
      "Epoch 95/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.4498 - accuracy: 0.5893\n",
      "Epoch 96/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.4273 - accuracy: 0.5915\n",
      "Epoch 97/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.4064 - accuracy: 0.5900\n",
      "Epoch 98/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.3841 - accuracy: 0.5896\n",
      "Epoch 99/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.3626 - accuracy: 0.5911\n",
      "Epoch 100/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.3412 - accuracy: 0.5915\n",
      "Epoch 101/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.3190 - accuracy: 0.5907\n",
      "Epoch 102/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.2986 - accuracy: 0.5922\n",
      "Epoch 103/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.2779 - accuracy: 0.5900\n",
      "Epoch 104/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.2591 - accuracy: 0.5904\n",
      "Epoch 105/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.2376 - accuracy: 0.5918\n",
      "Epoch 106/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.2183 - accuracy: 0.5922\n",
      "Epoch 107/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.1980 - accuracy: 0.5929\n",
      "Epoch 108/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1787 - accuracy: 0.5922\n",
      "Epoch 109/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1603 - accuracy: 0.5911\n",
      "Epoch 110/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1430 - accuracy: 0.5929\n",
      "Epoch 111/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1220 - accuracy: 0.5929\n",
      "Epoch 112/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1038 - accuracy: 0.5929\n",
      "Epoch 113/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0853 - accuracy: 0.5929\n",
      "Epoch 114/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0673 - accuracy: 0.5918\n",
      "Epoch 115/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0521 - accuracy: 0.5926\n",
      "Epoch 116/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0335 - accuracy: 0.5926\n",
      "Epoch 117/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0163 - accuracy: 0.5933\n",
      "Epoch 118/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.9992 - accuracy: 0.5937\n",
      "Epoch 119/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.9835 - accuracy: 0.5933\n",
      "Epoch 120/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.9662 - accuracy: 0.5922\n",
      "Epoch 121/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.9525 - accuracy: 0.5937\n",
      "Epoch 122/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.9361 - accuracy: 0.5937\n",
      "Epoch 123/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.9194 - accuracy: 0.5929\n",
      "Epoch 124/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.9045 - accuracy: 0.5951\n",
      "Epoch 125/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.8901 - accuracy: 0.5944\n",
      "Epoch 126/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.8751 - accuracy: 0.5948\n",
      "Epoch 127/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.8611 - accuracy: 0.5933\n",
      "Epoch 128/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.8465 - accuracy: 0.5951\n",
      "Epoch 129/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.8329 - accuracy: 0.5948\n",
      "Epoch 130/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.8194 - accuracy: 0.5951\n",
      "Epoch 131/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.8059 - accuracy: 0.5948\n",
      "Epoch 132/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7937 - accuracy: 0.5937\n",
      "Epoch 133/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7808 - accuracy: 0.5955\n",
      "Epoch 134/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7682 - accuracy: 0.5940\n",
      "Epoch 135/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7560 - accuracy: 0.5966\n",
      "Epoch 136/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7435 - accuracy: 0.5959\n",
      "Epoch 137/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7328 - accuracy: 0.5962\n",
      "Epoch 138/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7205 - accuracy: 0.5970\n",
      "Epoch 139/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7079 - accuracy: 0.5974\n",
      "Epoch 140/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.5959\n",
      "Epoch 141/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.5985\n",
      "Epoch 142/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6767 - accuracy: 0.5944\n",
      "Epoch 143/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.5988\n",
      "Epoch 144/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.5959\n",
      "Epoch 145/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6448 - accuracy: 0.5988\n",
      "Epoch 146/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.5970\n",
      "Epoch 147/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.5996\n",
      "Epoch 148/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.5981\n",
      "Epoch 149/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.5996\n",
      "Epoch 150/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.5988\n",
      "Epoch 151/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5899 - accuracy: 0.5992\n",
      "Epoch 152/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.5992\n",
      "Epoch 153/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.6003\n",
      "Epoch 154/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.5985\n",
      "Epoch 155/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.5996\n",
      "Epoch 156/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.6007\n",
      "Epoch 157/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.5988\n",
      "Epoch 158/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.6014\n",
      "Epoch 159/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.5996\n",
      "Epoch 160/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.6003\n",
      "Epoch 161/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.6025\n",
      "Epoch 162/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.6025\n",
      "Epoch 163/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.6021\n",
      "Epoch 164/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.6018\n",
      "Epoch 165/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.6032\n",
      "Epoch 166/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.6025\n",
      "Epoch 167/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.6025\n",
      "Epoch 168/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.6036\n",
      "Epoch 169/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.6021\n",
      "Epoch 170/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.6032\n",
      "Epoch 171/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.6032\n",
      "Epoch 172/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.6029\n",
      "Epoch 173/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.6040\n",
      "Epoch 174/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.6036\n",
      "Epoch 175/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.6040\n",
      "Epoch 176/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.6043\n",
      "Epoch 177/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.6036\n",
      "Epoch 178/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.6054\n",
      "Epoch 179/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.6036\n",
      "Epoch 180/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.6043\n",
      "Epoch 181/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.6032\n",
      "Epoch 182/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.6036\n",
      "Epoch 183/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.6062\n",
      "Epoch 184/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.6051\n",
      "Epoch 185/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.6047\n",
      "Epoch 186/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.6051\n",
      "Epoch 187/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.6058\n",
      "Epoch 188/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.6043\n",
      "Epoch 189/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.6054\n",
      "Epoch 190/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.6054\n",
      "Epoch 191/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.6066\n",
      "Epoch 192/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.6066\n",
      "Epoch 193/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.6054\n",
      "Epoch 194/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.6069\n",
      "Epoch 195/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.6058\n",
      "Epoch 196/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.6062\n",
      "Epoch 197/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.6062\n",
      "Epoch 198/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.6069\n",
      "Epoch 199/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3458 - accuracy: 0.6066\n",
      "Epoch 200/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.6073\n",
      "Epoch 201/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.6066\n",
      "Epoch 202/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.6062\n",
      "Epoch 203/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.6062\n",
      "Epoch 204/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.6077\n",
      "Epoch 205/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.6077\n",
      "Epoch 206/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.6077\n",
      "Epoch 207/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.3261 - accuracy: 0.6077\n",
      "Epoch 208/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.3245 - accuracy: 0.6073\n",
      "Epoch 209/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.6069\n",
      "Epoch 210/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.3206 - accuracy: 0.6080\n",
      "Epoch 211/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.3185 - accuracy: 0.6080\n",
      "Epoch 212/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3169 - accuracy: 0.6077\n",
      "Epoch 213/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.3149 - accuracy: 0.6080\n",
      "Epoch 214/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.3135 - accuracy: 0.6077\n",
      "Epoch 215/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.3117 - accuracy: 0.6088\n",
      "Epoch 216/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.3100 - accuracy: 0.6077\n",
      "Epoch 217/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.3087 - accuracy: 0.6080\n",
      "Epoch 218/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.3071 - accuracy: 0.6077\n",
      "Epoch 219/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.6084\n",
      "Epoch 220/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.6088\n",
      "Epoch 221/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3025 - accuracy: 0.6084\n",
      "Epoch 222/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.3012 - accuracy: 0.6088\n",
      "Epoch 223/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2999 - accuracy: 0.6084\n",
      "Epoch 224/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.6084\n",
      "Epoch 225/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.6080\n",
      "Epoch 226/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2959 - accuracy: 0.6084\n",
      "Epoch 227/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2948 - accuracy: 0.6084\n",
      "Epoch 228/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2935 - accuracy: 0.6088\n",
      "Epoch 229/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2923 - accuracy: 0.6088\n",
      "Epoch 230/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2912 - accuracy: 0.6088\n",
      "Epoch 231/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2899 - accuracy: 0.6084\n",
      "Epoch 232/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2888 - accuracy: 0.6088\n",
      "Epoch 233/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2877 - accuracy: 0.6095\n",
      "Epoch 234/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2865 - accuracy: 0.6091\n",
      "Epoch 235/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2858 - accuracy: 0.6084\n",
      "Epoch 236/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2845 - accuracy: 0.6091\n",
      "Epoch 237/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.6091\n",
      "Epoch 238/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2825 - accuracy: 0.6088\n",
      "Epoch 239/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.6091\n",
      "Epoch 240/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2805 - accuracy: 0.6095\n",
      "Epoch 241/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2794 - accuracy: 0.6095\n",
      "Epoch 242/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2784 - accuracy: 0.6080\n",
      "Epoch 243/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.6084\n",
      "Epoch 244/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.6088\n",
      "Epoch 245/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2755 - accuracy: 0.6088\n",
      "Epoch 246/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.6095\n",
      "Epoch 247/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2735 - accuracy: 0.6088\n",
      "Epoch 248/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2725 - accuracy: 0.6091\n",
      "Epoch 249/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.6095\n",
      "Epoch 250/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.6088\n",
      "Epoch 251/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2700 - accuracy: 0.6091\n",
      "Epoch 252/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.6095\n",
      "Epoch 253/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.6091\n",
      "Epoch 254/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.6091\n",
      "Epoch 255/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.6091\n",
      "Epoch 256/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.6095\n",
      "Epoch 257/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.6091\n",
      "Epoch 258/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.6091\n",
      "Epoch 259/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2630 - accuracy: 0.6095\n",
      "Epoch 260/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.6091\n",
      "Epoch 261/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2614 - accuracy: 0.6091\n",
      "Epoch 262/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.6091\n",
      "Epoch 263/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2598 - accuracy: 0.6091\n",
      "Epoch 264/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.6095\n",
      "Epoch 265/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.6095\n",
      "Epoch 266/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.6095\n",
      "Epoch 267/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.6091\n",
      "Epoch 268/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.6091\n",
      "Epoch 269/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2551 - accuracy: 0.6091\n",
      "Epoch 270/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2544 - accuracy: 0.6091\n",
      "Epoch 271/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.6095\n",
      "Epoch 272/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.6091\n",
      "Epoch 273/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.6095\n",
      "Epoch 274/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.6091\n",
      "Epoch 275/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.6091\n",
      "Epoch 276/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.6095\n",
      "Epoch 277/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.6091\n",
      "Epoch 278/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.6091\n",
      "Epoch 279/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.6091\n",
      "Epoch 280/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.6091\n",
      "Epoch 281/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.6091\n",
      "Epoch 282/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.6091\n",
      "Epoch 283/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.6091\n",
      "Epoch 284/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.6095\n",
      "Epoch 285/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.6088\n",
      "Epoch 286/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2429 - accuracy: 0.6091\n",
      "Epoch 287/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2423 - accuracy: 0.6091\n",
      "Epoch 288/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2416 - accuracy: 0.6084\n",
      "Epoch 289/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2410 - accuracy: 0.6091\n",
      "Epoch 290/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2402 - accuracy: 0.6084\n",
      "Epoch 291/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2397 - accuracy: 0.6091\n",
      "Epoch 292/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2390 - accuracy: 0.6095\n",
      "Epoch 293/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2384 - accuracy: 0.6088\n",
      "Epoch 294/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 0.6095\n",
      "Epoch 295/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.6088\n",
      "Epoch 296/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.6095\n",
      "Epoch 297/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.6091\n",
      "Epoch 298/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2353 - accuracy: 0.6099\n",
      "Epoch 299/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2347 - accuracy: 0.6099\n",
      "Epoch 300/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.6095\n",
      "Epoch 301/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2336 - accuracy: 0.6095\n",
      "Epoch 302/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.6095\n",
      "Epoch 303/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2325 - accuracy: 0.6095\n",
      "Epoch 304/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.6095\n",
      "Epoch 305/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.6095\n",
      "Epoch 306/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.6099\n",
      "Epoch 307/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.6095\n",
      "Epoch 308/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2296 - accuracy: 0.6099\n",
      "Epoch 309/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 0.6099\n",
      "Epoch 310/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2286 - accuracy: 0.6099\n",
      "Epoch 311/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.6091\n",
      "Epoch 312/400\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2276 - accuracy: 0.6099\n",
      "Epoch 313/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2270 - accuracy: 0.6099\n",
      "Epoch 314/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2266 - accuracy: 0.6095\n",
      "Epoch 315/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.6095\n",
      "Epoch 316/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2255 - accuracy: 0.6099\n",
      "Epoch 317/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.6095\n",
      "Epoch 318/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2246 - accuracy: 0.6095\n",
      "Epoch 319/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.6095\n",
      "Epoch 320/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.6095\n",
      "Epoch 321/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2230 - accuracy: 0.6099\n",
      "Epoch 322/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.6099\n",
      "Epoch 323/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.6099\n",
      "Epoch 324/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2217 - accuracy: 0.6099\n",
      "Epoch 325/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 0.6095\n",
      "Epoch 326/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.6095\n",
      "Epoch 327/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.6099\n",
      "Epoch 328/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2198 - accuracy: 0.6095\n",
      "Epoch 329/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2193 - accuracy: 0.6095\n",
      "Epoch 330/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2188 - accuracy: 0.6099\n",
      "Epoch 331/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2184 - accuracy: 0.6095\n",
      "Epoch 332/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2179 - accuracy: 0.6099\n",
      "Epoch 333/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.6095\n",
      "Epoch 334/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.6099\n",
      "Epoch 335/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2166 - accuracy: 0.6091\n",
      "Epoch 336/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.6091\n",
      "Epoch 337/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 0.6095\n",
      "Epoch 338/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2152 - accuracy: 0.6095\n",
      "Epoch 339/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2148 - accuracy: 0.6095\n",
      "Epoch 340/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.6095\n",
      "Epoch 341/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2138 - accuracy: 0.6095\n",
      "Epoch 342/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.6088\n",
      "Epoch 343/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2128 - accuracy: 0.6099\n",
      "Epoch 344/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.6095\n",
      "Epoch 345/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.6091\n",
      "Epoch 346/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2115 - accuracy: 0.6091\n",
      "Epoch 347/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2111 - accuracy: 0.6095\n",
      "Epoch 348/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2105 - accuracy: 0.6095\n",
      "Epoch 349/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2101 - accuracy: 0.6091\n",
      "Epoch 350/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2096 - accuracy: 0.6095\n",
      "Epoch 351/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2091 - accuracy: 0.6095\n",
      "Epoch 352/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.6095\n",
      "Epoch 353/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.6099\n",
      "Epoch 354/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.6099\n",
      "Epoch 355/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.6095\n",
      "Epoch 356/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2069 - accuracy: 0.6095\n",
      "Epoch 357/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2066 - accuracy: 0.6095\n",
      "Epoch 358/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2062 - accuracy: 0.6099\n",
      "Epoch 359/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2058 - accuracy: 0.6095\n",
      "Epoch 360/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2055 - accuracy: 0.6099\n",
      "Epoch 361/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.6095\n",
      "Epoch 362/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.6095\n",
      "Epoch 363/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.6095\n",
      "Epoch 364/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.6099\n",
      "Epoch 365/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.6099\n",
      "Epoch 366/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.6095\n",
      "Epoch 367/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2027 - accuracy: 0.6099\n",
      "Epoch 368/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 0.6099\n",
      "Epoch 369/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.6099\n",
      "Epoch 370/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2017 - accuracy: 0.6099\n",
      "Epoch 371/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2013 - accuracy: 0.6099\n",
      "Epoch 372/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.6099\n",
      "Epoch 373/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.6099\n",
      "Epoch 374/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2002 - accuracy: 0.6099\n",
      "Epoch 375/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.6099\n",
      "Epoch 376/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1995 - accuracy: 0.6099\n",
      "Epoch 377/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.6099\n",
      "Epoch 378/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1988 - accuracy: 0.6099\n",
      "Epoch 379/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.6099\n",
      "Epoch 380/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.6099\n",
      "Epoch 381/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.6099\n",
      "Epoch 382/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.6099\n",
      "Epoch 383/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1971 - accuracy: 0.6099\n",
      "Epoch 384/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.6099\n",
      "Epoch 385/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.6099\n",
      "Epoch 386/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.6099\n",
      "Epoch 387/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.6099\n",
      "Epoch 388/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.6099\n",
      "Epoch 389/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1951 - accuracy: 0.6099\n",
      "Epoch 390/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1947 - accuracy: 0.6099\n",
      "Epoch 391/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.6099\n",
      "Epoch 392/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1941 - accuracy: 0.6099\n",
      "Epoch 393/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.6099\n",
      "Epoch 394/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.6099\n",
      "Epoch 395/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.6099\n",
      "Epoch 396/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 0.6099\n",
      "Epoch 397/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.6099\n",
      "Epoch 398/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1922 - accuracy: 0.6099\n",
      "Epoch 399/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.6099\n",
      "Epoch 400/400\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.6099\n"
     ]
    }
   ],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=20000,\n",
    "    decay_rate=0.9)\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(200, input_dim=np.shape(compoundDataTrain)[1], activation='softmax', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model1.add(Dense(150, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model1.add(Dense(75, activation='relu', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model1.add(Dense(100, activation='relu', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model1.add(Dense(100, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model1.add(Dense(1, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "\n",
    "model1.compile(loss='MeanSquaredError', optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model1.fit(compoundDataTrain, toClassification(activitiesTrain),epochs=400, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9dd37d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 1.0603 - accuracy: 0.4026\n",
      "Epoch 2/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.4133 - accuracy: 0.5370\n",
      "Epoch 3/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3582 - accuracy: 0.5462\n",
      "Epoch 4/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3242 - accuracy: 0.5565\n",
      "Epoch 5/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.2993 - accuracy: 0.5594\n",
      "Epoch 6/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.2772 - accuracy: 0.5668\n",
      "Epoch 7/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.2527 - accuracy: 0.5709\n",
      "Epoch 8/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.2325 - accuracy: 0.5793\n",
      "Epoch 9/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.2391 - accuracy: 0.5767\n",
      "Epoch 10/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.2306 - accuracy: 0.5797\n",
      "Epoch 11/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.2053 - accuracy: 0.5859\n",
      "Epoch 12/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.2047 - accuracy: 0.5867\n",
      "Epoch 13/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1977 - accuracy: 0.5893\n",
      "Epoch 14/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1912 - accuracy: 0.5896\n",
      "Epoch 15/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1893 - accuracy: 0.5881\n",
      "Epoch 16/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1908 - accuracy: 0.5904\n",
      "Epoch 17/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1860 - accuracy: 0.5900\n",
      "Epoch 18/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.5911\n",
      "Epoch 19/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1813 - accuracy: 0.5907\n",
      "Epoch 20/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.5929\n",
      "Epoch 21/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1751 - accuracy: 0.5926\n",
      "Epoch 22/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1677 - accuracy: 0.5940\n",
      "Epoch 23/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1679 - accuracy: 0.5951\n",
      "Epoch 24/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1667 - accuracy: 0.5944\n",
      "Epoch 25/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1640 - accuracy: 0.5951\n",
      "Epoch 26/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1677 - accuracy: 0.5929\n",
      "Epoch 27/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1553 - accuracy: 0.5959\n",
      "Epoch 28/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1608 - accuracy: 0.5959\n",
      "Epoch 29/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.5962\n",
      "Epoch 30/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1611 - accuracy: 0.5959\n",
      "Epoch 31/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1641 - accuracy: 0.5922\n",
      "Epoch 32/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1602 - accuracy: 0.5955\n",
      "Epoch 33/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1416 - accuracy: 0.5992\n",
      "Epoch 34/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1510 - accuracy: 0.5988\n",
      "Epoch 35/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1461 - accuracy: 0.5966\n",
      "Epoch 36/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1306 - accuracy: 0.6021\n",
      "Epoch 37/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1506 - accuracy: 0.5966\n",
      "Epoch 38/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1398 - accuracy: 0.5996\n",
      "Epoch 39/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1510 - accuracy: 0.5951\n",
      "Epoch 40/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1383 - accuracy: 0.5996\n",
      "Epoch 41/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1302 - accuracy: 0.6010\n",
      "Epoch 42/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1287 - accuracy: 0.6047\n",
      "Epoch 43/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1306 - accuracy: 0.6003\n",
      "Epoch 44/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1207 - accuracy: 0.6043\n",
      "Epoch 45/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1250 - accuracy: 0.6032\n",
      "Epoch 46/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1368 - accuracy: 0.5981\n",
      "Epoch 47/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1312 - accuracy: 0.6040\n",
      "Epoch 48/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1214 - accuracy: 0.6036\n",
      "Epoch 49/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1307 - accuracy: 0.6018\n",
      "Epoch 50/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1427 - accuracy: 0.5996\n",
      "Epoch 51/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1256 - accuracy: 0.6018\n",
      "Epoch 52/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1277 - accuracy: 0.6032\n",
      "Epoch 53/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1248 - accuracy: 0.6040\n",
      "Epoch 54/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1343 - accuracy: 0.6007\n",
      "Epoch 55/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1223 - accuracy: 0.6043\n",
      "Epoch 56/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1181 - accuracy: 0.6054\n",
      "Epoch 57/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.1319 - accuracy: 0.6014\n",
      "Epoch 58/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1209 - accuracy: 0.6051\n",
      "Epoch 59/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1164 - accuracy: 0.6062\n",
      "Epoch 60/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1171 - accuracy: 0.6036\n",
      "Epoch 61/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1128 - accuracy: 0.6066\n",
      "Epoch 62/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1127 - accuracy: 0.6073\n",
      "Epoch 63/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1183 - accuracy: 0.6054\n",
      "Epoch 64/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1168 - accuracy: 0.6036\n",
      "Epoch 65/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1144 - accuracy: 0.6066\n",
      "Epoch 66/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1049 - accuracy: 0.6091\n",
      "Epoch 67/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1152 - accuracy: 0.6043\n",
      "Epoch 68/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1150 - accuracy: 0.6040\n",
      "Epoch 69/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1006 - accuracy: 0.6099\n",
      "Epoch 70/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1074 - accuracy: 0.6069\n",
      "Epoch 71/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1092 - accuracy: 0.6073\n",
      "Epoch 72/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1117 - accuracy: 0.6058\n",
      "Epoch 73/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1049 - accuracy: 0.6077\n",
      "Epoch 74/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1154 - accuracy: 0.6066\n",
      "Epoch 75/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1022 - accuracy: 0.6088\n",
      "Epoch 76/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1230 - accuracy: 0.6025\n",
      "Epoch 77/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1104 - accuracy: 0.6069\n",
      "Epoch 78/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1130 - accuracy: 0.6073\n",
      "Epoch 79/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1147 - accuracy: 0.6054\n",
      "Epoch 80/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1090 - accuracy: 0.6073\n",
      "Epoch 81/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1129 - accuracy: 0.6058\n",
      "Epoch 82/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.1095 - accuracy: 0.6066\n",
      "Epoch 83/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1090 - accuracy: 0.6077\n",
      "Epoch 84/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1047 - accuracy: 0.6069\n",
      "Epoch 85/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1103 - accuracy: 0.6080\n",
      "Epoch 86/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.6095\n",
      "Epoch 87/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1180 - accuracy: 0.6043\n",
      "Epoch 88/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1113 - accuracy: 0.6073\n",
      "Epoch 89/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.6110\n",
      "Epoch 90/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.6091\n",
      "Epoch 91/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1006 - accuracy: 0.6099\n",
      "Epoch 92/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0891 - accuracy: 0.6132\n",
      "Epoch 93/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1083 - accuracy: 0.6073\n",
      "Epoch 94/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1231 - accuracy: 0.6062\n",
      "Epoch 95/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1153 - accuracy: 0.6040\n",
      "Epoch 96/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.6095\n",
      "Epoch 97/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0878 - accuracy: 0.6110\n",
      "Epoch 98/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.6106\n",
      "Epoch 99/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1114 - accuracy: 0.6051\n",
      "Epoch 100/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1160 - accuracy: 0.6036\n",
      "Epoch 101/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1057 - accuracy: 0.6084\n",
      "Epoch 102/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1062 - accuracy: 0.6066\n",
      "Epoch 103/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1145 - accuracy: 0.6051\n",
      "Epoch 104/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1114 - accuracy: 0.6051\n",
      "Epoch 105/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.6091\n",
      "Epoch 106/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0859 - accuracy: 0.6117\n",
      "Epoch 107/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1179 - accuracy: 0.6062\n",
      "Epoch 108/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1120 - accuracy: 0.6040\n",
      "Epoch 109/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1017 - accuracy: 0.6102\n",
      "Epoch 110/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0858 - accuracy: 0.6132\n",
      "Epoch 111/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.6088\n",
      "Epoch 112/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1207 - accuracy: 0.6054\n",
      "Epoch 113/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1023 - accuracy: 0.6084\n",
      "Epoch 114/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.6091\n",
      "Epoch 115/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.6099\n",
      "Epoch 116/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1054 - accuracy: 0.6069\n",
      "Epoch 117/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.6095\n",
      "Epoch 118/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1120 - accuracy: 0.6047\n",
      "Epoch 119/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1021 - accuracy: 0.6069\n",
      "Epoch 120/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0872 - accuracy: 0.6124\n",
      "Epoch 121/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0819 - accuracy: 0.6128\n",
      "Epoch 122/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0832 - accuracy: 0.6110\n",
      "Epoch 123/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1154 - accuracy: 0.6043\n",
      "Epoch 124/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1086 - accuracy: 0.6054\n",
      "Epoch 125/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.6099\n",
      "Epoch 126/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1060 - accuracy: 0.6054\n",
      "Epoch 127/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0947 - accuracy: 0.6099\n",
      "Epoch 128/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0902 - accuracy: 0.6088\n",
      "Epoch 129/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1161 - accuracy: 0.6073\n",
      "Epoch 130/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.6088\n",
      "Epoch 131/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1004 - accuracy: 0.6066\n",
      "Epoch 132/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1066 - accuracy: 0.6058\n",
      "Epoch 133/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1040 - accuracy: 0.6054\n",
      "Epoch 134/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.6088\n",
      "Epoch 135/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.6099\n",
      "Epoch 136/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.6088\n",
      "Epoch 137/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0870 - accuracy: 0.6099\n",
      "Epoch 138/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1216 - accuracy: 0.6029\n",
      "Epoch 139/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.6073\n",
      "Epoch 140/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.6084\n",
      "Epoch 141/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1005 - accuracy: 0.6054\n",
      "Epoch 142/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1000 - accuracy: 0.6084\n",
      "Epoch 143/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0987 - accuracy: 0.6084\n",
      "Epoch 144/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.6106\n",
      "Epoch 145/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0935 - accuracy: 0.6102\n",
      "Epoch 146/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0877 - accuracy: 0.6102\n",
      "Epoch 147/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1076 - accuracy: 0.6066\n",
      "Epoch 148/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1068 - accuracy: 0.6066\n",
      "Epoch 149/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1053 - accuracy: 0.6069\n",
      "Epoch 150/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1010 - accuracy: 0.6066\n",
      "Epoch 151/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1025 - accuracy: 0.6073\n",
      "Epoch 152/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1024 - accuracy: 0.6062\n",
      "Epoch 153/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.6110\n",
      "Epoch 154/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1040 - accuracy: 0.6069\n",
      "Epoch 155/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.6095\n",
      "Epoch 156/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.6106\n",
      "Epoch 157/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.6084\n",
      "Epoch 158/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.6099\n",
      "Epoch 159/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1013 - accuracy: 0.6066\n",
      "Epoch 160/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0888 - accuracy: 0.6110\n",
      "Epoch 161/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0933 - accuracy: 0.6095\n",
      "Epoch 162/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0852 - accuracy: 0.6128\n",
      "Epoch 163/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1125 - accuracy: 0.6047\n",
      "Epoch 164/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.6077\n",
      "Epoch 165/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0901 - accuracy: 0.6091\n",
      "Epoch 166/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.6091\n",
      "Epoch 167/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.6088\n",
      "Epoch 168/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0922 - accuracy: 0.6077\n",
      "Epoch 169/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.6091\n",
      "Epoch 170/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1064 - accuracy: 0.6080\n",
      "Epoch 171/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.6080\n",
      "Epoch 172/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.6106\n",
      "Epoch 173/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1105 - accuracy: 0.6062\n",
      "Epoch 174/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.6099\n",
      "Epoch 175/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1042 - accuracy: 0.6080\n",
      "Epoch 176/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0897 - accuracy: 0.6113\n",
      "Epoch 177/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.6095\n",
      "Epoch 178/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1057 - accuracy: 0.6084\n",
      "Epoch 179/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0895 - accuracy: 0.6117\n",
      "Epoch 180/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0845 - accuracy: 0.6128\n",
      "Epoch 181/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.6073\n",
      "Epoch 182/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0837 - accuracy: 0.6117\n",
      "Epoch 183/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.6080\n",
      "Epoch 184/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.6073\n",
      "Epoch 185/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0895 - accuracy: 0.6110\n",
      "Epoch 186/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0890 - accuracy: 0.6099\n",
      "Epoch 187/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1100 - accuracy: 0.6091\n",
      "Epoch 188/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.6077\n",
      "Epoch 189/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0911 - accuracy: 0.6110\n",
      "Epoch 190/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1037 - accuracy: 0.6084\n",
      "Epoch 191/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0957 - accuracy: 0.6088\n",
      "Epoch 192/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1030 - accuracy: 0.6077\n",
      "Epoch 193/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.6095\n",
      "Epoch 194/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.6102\n",
      "Epoch 195/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0886 - accuracy: 0.6095\n",
      "Epoch 196/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1058 - accuracy: 0.6080\n",
      "Epoch 197/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0900 - accuracy: 0.6110\n",
      "Epoch 198/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1007 - accuracy: 0.6073\n",
      "Epoch 199/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0789 - accuracy: 0.6128\n",
      "Epoch 200/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1027 - accuracy: 0.6066\n",
      "Epoch 201/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0998 - accuracy: 0.6080\n",
      "Epoch 202/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0898 - accuracy: 0.6091\n",
      "Epoch 203/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1116 - accuracy: 0.6080\n",
      "Epoch 204/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.6099\n",
      "Epoch 205/400\n",
      "680/680 [==============================] - 2s 3ms/step - loss: 0.0911 - accuracy: 0.6099\n",
      "Epoch 206/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.6102\n",
      "Epoch 207/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0859 - accuracy: 0.6128\n",
      "Epoch 208/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0827 - accuracy: 0.6121\n",
      "Epoch 209/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0935 - accuracy: 0.6106\n",
      "Epoch 210/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0965 - accuracy: 0.6080\n",
      "Epoch 211/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.1059 - accuracy: 0.6073\n",
      "Epoch 212/400\n",
      "680/680 [==============================] - 2s 3ms/step - loss: 0.0934 - accuracy: 0.6095\n",
      "Epoch 213/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0991 - accuracy: 0.6091\n",
      "Epoch 214/400\n",
      "680/680 [==============================] - 2s 3ms/step - loss: 0.0851 - accuracy: 0.6117\n",
      "Epoch 215/400\n",
      "680/680 [==============================] - 2s 3ms/step - loss: 0.0974 - accuracy: 0.6091\n",
      "Epoch 216/400\n",
      "680/680 [==============================] - 2s 3ms/step - loss: 0.1043 - accuracy: 0.6077\n",
      "Epoch 217/400\n",
      "680/680 [==============================] - 2s 3ms/step - loss: 0.0921 - accuracy: 0.6099\n",
      "Epoch 218/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0950 - accuracy: 0.6095\n",
      "Epoch 219/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0891 - accuracy: 0.6084\n",
      "Epoch 220/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.1041 - accuracy: 0.6069\n",
      "Epoch 221/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1008 - accuracy: 0.6091\n",
      "Epoch 222/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.6084\n",
      "Epoch 223/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0851 - accuracy: 0.6110\n",
      "Epoch 224/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.6124\n",
      "Epoch 225/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.6095\n",
      "Epoch 226/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.6077\n",
      "Epoch 227/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0957 - accuracy: 0.6099\n",
      "Epoch 228/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0875 - accuracy: 0.6113\n",
      "Epoch 229/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.6088\n",
      "Epoch 230/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0879 - accuracy: 0.6113\n",
      "Epoch 231/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0918 - accuracy: 0.6088\n",
      "Epoch 232/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.6095\n",
      "Epoch 233/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0845 - accuracy: 0.6128\n",
      "Epoch 234/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1026 - accuracy: 0.6091\n",
      "Epoch 235/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1031 - accuracy: 0.6077\n",
      "Epoch 236/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1108 - accuracy: 0.6073\n",
      "Epoch 237/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.6088\n",
      "Epoch 238/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.6102\n",
      "Epoch 239/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.6091\n",
      "Epoch 240/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0886 - accuracy: 0.6102\n",
      "Epoch 241/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.6091\n",
      "Epoch 242/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0922 - accuracy: 0.6102\n",
      "Epoch 243/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.6073\n",
      "Epoch 244/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0880 - accuracy: 0.6117\n",
      "Epoch 245/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0850 - accuracy: 0.6121\n",
      "Epoch 246/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.6099\n",
      "Epoch 247/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.6110\n",
      "Epoch 248/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.6117\n",
      "Epoch 249/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1003 - accuracy: 0.6099\n",
      "Epoch 250/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.6077\n",
      "Epoch 251/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.6066\n",
      "Epoch 252/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0923 - accuracy: 0.6102\n",
      "Epoch 253/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0856 - accuracy: 0.6110\n",
      "Epoch 254/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.6073\n",
      "Epoch 255/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0874 - accuracy: 0.6124\n",
      "Epoch 256/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0987 - accuracy: 0.6077\n",
      "Epoch 257/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.6106\n",
      "Epoch 258/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.6091\n",
      "Epoch 259/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.6084\n",
      "Epoch 260/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0867 - accuracy: 0.6117\n",
      "Epoch 261/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.6073\n",
      "Epoch 262/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1037 - accuracy: 0.6062\n",
      "Epoch 263/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1003 - accuracy: 0.6084\n",
      "Epoch 264/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0856 - accuracy: 0.6110\n",
      "Epoch 265/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0860 - accuracy: 0.6117\n",
      "Epoch 266/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1033 - accuracy: 0.6099\n",
      "Epoch 267/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1032 - accuracy: 0.6073\n",
      "Epoch 268/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1051 - accuracy: 0.6077\n",
      "Epoch 269/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.6106\n",
      "Epoch 270/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.6091\n",
      "Epoch 271/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1041 - accuracy: 0.6069\n",
      "Epoch 272/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0822 - accuracy: 0.6132\n",
      "Epoch 273/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0832 - accuracy: 0.6128\n",
      "Epoch 274/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0937 - accuracy: 0.6088\n",
      "Epoch 275/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1066 - accuracy: 0.6054\n",
      "Epoch 276/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0867 - accuracy: 0.6113\n",
      "Epoch 277/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0803 - accuracy: 0.6128\n",
      "Epoch 278/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.6102\n",
      "Epoch 279/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1052 - accuracy: 0.6073\n",
      "Epoch 280/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.1009 - accuracy: 0.6058\n",
      "Epoch 281/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0918 - accuracy: 0.6110\n",
      "Epoch 282/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0840 - accuracy: 0.6117\n",
      "Epoch 283/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.6102\n",
      "Epoch 284/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0947 - accuracy: 0.6099\n",
      "Epoch 285/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.6080\n",
      "Epoch 286/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0850 - accuracy: 0.6113\n",
      "Epoch 287/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0838 - accuracy: 0.6124\n",
      "Epoch 288/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0804 - accuracy: 0.6128\n",
      "Epoch 289/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1064 - accuracy: 0.6073\n",
      "Epoch 290/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.6080\n",
      "Epoch 291/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0863 - accuracy: 0.6124\n",
      "Epoch 292/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0861 - accuracy: 0.6106\n",
      "Epoch 293/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0900 - accuracy: 0.6102\n",
      "Epoch 294/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1139 - accuracy: 0.6043\n",
      "Epoch 295/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.6088\n",
      "Epoch 296/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.6069\n",
      "Epoch 297/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0902 - accuracy: 0.6106\n",
      "Epoch 298/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0804 - accuracy: 0.6128\n",
      "Epoch 299/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0923 - accuracy: 0.6095\n",
      "Epoch 300/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1066 - accuracy: 0.6047\n",
      "Epoch 301/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1037 - accuracy: 0.6066\n",
      "Epoch 302/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0929 - accuracy: 0.6110\n",
      "Epoch 303/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0880 - accuracy: 0.6110\n",
      "Epoch 304/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0882 - accuracy: 0.6110\n",
      "Epoch 305/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.6058\n",
      "Epoch 306/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0873 - accuracy: 0.6124\n",
      "Epoch 307/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0900 - accuracy: 0.6102\n",
      "Epoch 308/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1018 - accuracy: 0.6066\n",
      "Epoch 309/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0892 - accuracy: 0.6102\n",
      "Epoch 310/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0861 - accuracy: 0.6110\n",
      "Epoch 311/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0836 - accuracy: 0.6124\n",
      "Epoch 312/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.6077\n",
      "Epoch 313/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1126 - accuracy: 0.6040\n",
      "Epoch 314/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0891 - accuracy: 0.6106\n",
      "Epoch 315/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.6095\n",
      "Epoch 316/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.6132\n",
      "Epoch 317/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0863 - accuracy: 0.6113\n",
      "Epoch 318/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1039 - accuracy: 0.6073\n",
      "Epoch 319/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0882 - accuracy: 0.6088\n",
      "Epoch 320/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0953 - accuracy: 0.6084\n",
      "Epoch 321/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0998 - accuracy: 0.6080\n",
      "Epoch 322/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0840 - accuracy: 0.6106\n",
      "Epoch 323/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.6102\n",
      "Epoch 324/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0853 - accuracy: 0.6121\n",
      "Epoch 325/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1001 - accuracy: 0.6084\n",
      "Epoch 326/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0939 - accuracy: 0.6113\n",
      "Epoch 327/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0892 - accuracy: 0.6102\n",
      "Epoch 328/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.6110\n",
      "Epoch 329/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.6091\n",
      "Epoch 330/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0860 - accuracy: 0.6106\n",
      "Epoch 331/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1021 - accuracy: 0.6069\n",
      "Epoch 332/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.6099\n",
      "Epoch 333/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.6128\n",
      "Epoch 334/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1013 - accuracy: 0.6080\n",
      "Epoch 335/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1024 - accuracy: 0.6069\n",
      "Epoch 336/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.6099\n",
      "Epoch 337/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.6099\n",
      "Epoch 338/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0874 - accuracy: 0.6121\n",
      "Epoch 339/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0849 - accuracy: 0.6113\n",
      "Epoch 340/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1010 - accuracy: 0.6084\n",
      "Epoch 341/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.6073\n",
      "Epoch 342/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0951 - accuracy: 0.6080\n",
      "Epoch 343/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.6106\n",
      "Epoch 344/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0833 - accuracy: 0.6124\n",
      "Epoch 345/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.6095\n",
      "Epoch 346/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.6095\n",
      "Epoch 347/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1010 - accuracy: 0.6073\n",
      "Epoch 348/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0852 - accuracy: 0.6110\n",
      "Epoch 349/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.6113\n",
      "Epoch 350/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0879 - accuracy: 0.6113\n",
      "Epoch 351/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0832 - accuracy: 0.6102\n",
      "Epoch 352/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1206 - accuracy: 0.6043\n",
      "Epoch 353/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1012 - accuracy: 0.6080\n",
      "Epoch 354/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.6106\n",
      "Epoch 355/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.6102\n",
      "Epoch 356/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1013 - accuracy: 0.6073\n",
      "Epoch 357/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0863 - accuracy: 0.6113\n",
      "Epoch 358/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.6091\n",
      "Epoch 359/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.6088\n",
      "Epoch 360/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0869 - accuracy: 0.6095\n",
      "Epoch 361/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1018 - accuracy: 0.6077\n",
      "Epoch 362/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.6080\n",
      "Epoch 363/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0844 - accuracy: 0.6106\n",
      "Epoch 364/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.6102\n",
      "Epoch 365/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1142 - accuracy: 0.6058\n",
      "Epoch 366/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0859 - accuracy: 0.6110\n",
      "Epoch 367/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0900 - accuracy: 0.6095\n",
      "Epoch 368/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0834 - accuracy: 0.6124\n",
      "Epoch 369/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0813 - accuracy: 0.6117\n",
      "Epoch 370/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1034 - accuracy: 0.6066\n",
      "Epoch 371/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.1016 - accuracy: 0.6069\n",
      "Epoch 372/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0822 - accuracy: 0.6132\n",
      "Epoch 373/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0902 - accuracy: 0.6117\n",
      "Epoch 374/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0941 - accuracy: 0.6106\n",
      "Epoch 375/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1136 - accuracy: 0.6058\n",
      "Epoch 376/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.6091\n",
      "Epoch 377/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0908 - accuracy: 0.6110\n",
      "Epoch 378/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0878 - accuracy: 0.6099\n",
      "Epoch 379/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.6091\n",
      "Epoch 380/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.6084\n",
      "Epoch 381/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0935 - accuracy: 0.6095\n",
      "Epoch 382/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0807 - accuracy: 0.6117\n",
      "Epoch 383/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0939 - accuracy: 0.6095\n",
      "Epoch 384/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1011 - accuracy: 0.6084\n",
      "Epoch 385/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0886 - accuracy: 0.6106\n",
      "Epoch 386/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0882 - accuracy: 0.6117\n",
      "Epoch 387/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0947 - accuracy: 0.6091\n",
      "Epoch 388/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0973 - accuracy: 0.6073\n",
      "Epoch 389/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.6077\n",
      "Epoch 390/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.6117\n",
      "Epoch 391/400\n",
      "680/680 [==============================] - 2s 2ms/step - loss: 0.0822 - accuracy: 0.6113\n",
      "Epoch 392/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0822 - accuracy: 0.6121\n",
      "Epoch 393/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1005 - accuracy: 0.6054\n",
      "Epoch 394/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.6106\n",
      "Epoch 395/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0863 - accuracy: 0.6106\n",
      "Epoch 396/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0836 - accuracy: 0.6117\n",
      "Epoch 397/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1007 - accuracy: 0.6077\n",
      "Epoch 398/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.1059 - accuracy: 0.6066\n",
      "Epoch 399/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0844 - accuracy: 0.6117\n",
      "Epoch 400/400\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.0865 - accuracy: 0.6110\n"
     ]
    }
   ],
   "source": [
    "classTrain = Transformer.toClassification(activitiesTrain)\n",
    "classVal = Transformer.toClassification(activitiesValidate)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.01,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False\n",
    ")\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "l1Reg = 0.001\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(200, input_dim=np.shape(compoundDataTrain)[1], activation='softmax', kernel_regularizer = keras.regularizers.L2(l1Reg)))\n",
    "model2.add(Dense(150, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model2.add(Dense(75, activation='relu', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model2.add(Dense(100, activation='relu', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model2.add(Dense(100, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model2.add(Dense(1, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "\n",
    "model2.compile(loss='MeanSquaredError', optimizer=\"adam\", metrics=['accuracy'])\n",
    "history = model2.fit(compoundDataTrain, Transformer.toClassification(activitiesTrain), epochs=400, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "09e1d532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "85/85 [==============================] - 1s 2ms/step - loss: 1.8043 - accuracy: 0.6198\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 1.5772 - accuracy: 0.6198\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5297 - accuracy: 0.6198\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5219 - accuracy: 0.6198\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5209 - accuracy: 0.6198\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 72/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 73/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 74/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 75/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 76/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 77/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 78/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 79/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 80/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 81/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 82/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 84/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 85/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 86/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 87/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 88/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 89/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 90/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 91/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 92/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 93/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 94/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 95/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 96/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 97/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 98/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 99/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n",
      "Epoch 100/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.6198\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(50, input_dim=np.shape(compoundDataTrain)[1], activation='softmax', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model3.add(Dense(100, activation='softmax', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model3.add(Dense(50, activation='relu', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model3.add(Dense(75, activation='relu', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model3.add(Dense(100, activation='relu', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model3.add(Dense(75, activation='relu', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model3.add(Dense(100, activation='relu', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model3.add(Dense(1, activation='softmax', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "\n",
    "model3.compile(loss='MeanSquaredError', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model3.fit(compoundDataTrain, toClassification(activitiesTrain), epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "92288cff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "Aggregation:  0.5276124567474049\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "0.5216955017301038\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "0.5223529411764706\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "0.611764705882353\n"
     ]
    }
   ],
   "source": [
    "print(\"Aggregation: \", np.mean(toClassification(activitiesValidate) == takeVote([model1,model2,model3], compoundDataValidate, toClassification(activitiesValidate))))\n",
    "print(np.mean(toClassification(activitiesValidate) == np.sign(model1.predict(compoundDataValidate))))\n",
    "print(np.mean(toClassification(activitiesValidate) == np.sign(model2.predict(compoundDataValidate))))\n",
    "print(np.mean(toClassification(activitiesValidate) == np.sign(model3.predict(compoundDataValidate))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded82795",
   "metadata": {},
   "source": [
    "# Using the PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "36ee06a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bcut2d retention: [0.99364773]\n",
      "\ttotal: 99.36477273412339%\n",
      "chi retention: [0.9541968]\n",
      "\ttotal: 95.41967968597889%\n",
      "paoe retention: [0.31495127 0.19509321 0.1390042  0.08838179 0.07155396 0.04590061\n",
      " 0.03243    0.02673268 0.02402293]\n",
      "\ttotal: 93.80706737004672%\n",
      "smr retention: [0.50634726 0.24568468 0.08792319 0.07435827]\n",
      "\ttotal: 91.43133907840063%\n",
      "slogp retention: [0.44620276 0.22134465 0.15753302 0.04213752 0.03159298 0.02850562]\n",
      "\ttotal: 92.73165471968964%\n",
      "estate_vsa retention: [0.29224011 0.18964809 0.14361318 0.10642656 0.07394495 0.06391846\n",
      " 0.05513575]\n",
      "\ttotal: 92.49271047439834%\n",
      "vsa_estate retention: [0.49255304 0.32866098 0.09719245]\n",
      "\ttotal: 91.84064669216797%\n",
      "fr retention: [0.32153498 0.12578177 0.09944384 0.0570485  0.05494644 0.04503917\n",
      " 0.03646285 0.02896244 0.02597271 0.02289905 0.01957315 0.01726897\n",
      " 0.01514305 0.01174696 0.01137838 0.00991623]\n",
      "\ttotal: 90.31185029428742%\n",
      "(2717, 95)\n",
      "0 \b:\t docking_score_max \t [1.8401924  1.40725282 0.10843408]\n",
      "1 \b:\t fusion_score_max \t [0.04179651 0.94715309 0.36833644]\n",
      "2 \b:\t maxestateindex \t [ 0.47106969 -0.39012844 -0.01682807]\n",
      "3 \b:\t minestateindex \t [-0.82162669  0.66805633  0.68625441]\n",
      "4 \b:\t maxabsestateindex \t [ 0.47106969 -0.39012844 -0.01682807]\n",
      "5 \b:\t minabsestateindex \t [0.21141959 1.09317326 0.04827083]\n",
      "6 \b:\t qed \t [-1.15591823 -0.59280689  0.85035599]\n",
      "7 \b:\t molwt \t [ 1.99801031 -0.06443776 -0.71012253]\n",
      "8 \b:\t heavyatommolwt \t [ 1.93030512 -0.11695211 -0.65392929]\n",
      "9 \b:\t exactmolwt \t [ 1.99574335 -0.06216303 -0.71565145]\n",
      "10 \b:\t numvalenceelectrons \t [ 1.96121366  0.07013939 -0.91837671]\n",
      "11 \b:\t numradicalelectrons \t [0. 0. 0.]\n",
      "12 \b:\t maxpartialcharge \t [-0.01918824 -0.01918824 -0.01918824]\n",
      "13 \b:\t minpartialcharge \t [-0.32451733 -0.4218597  -0.86702629]\n",
      "14 \b:\t maxabspartialcharge \t [-0.01918824 -0.01918824 -0.01918824]\n",
      "15 \b:\t minabspartialcharge \t [ 1.7818052   0.75171384 -0.76437674]\n",
      "16 \b:\t fpdensitymorgan1 \t [-0.17784179 -1.04453865  0.26762505]\n",
      "17 \b:\t fpdensitymorgan2 \t [-0.08737051 -0.78050444  0.63589968]\n",
      "18 \b:\t fpdensitymorgan3 \t [-0.05967969 -0.3359487   1.12143217]\n",
      "19 \b:\t bcut2d_0 \t [ 0.56823354 -1.10778048  0.56153227]\n",
      "20 \b:\t balabanj \t [-1.13058364 -0.32511406 -0.01486306]\n",
      "21 \b:\t bertzct \t [ 0.83984051  0.79847155 -0.40031737]\n",
      "22 \b:\t chi_0 \t [ 2.09115283  0.18997116 -0.87708089]\n",
      "23 \b:\t hallkieralpha \t [0.35978559 0.04680885 0.7770879 ]\n",
      "24 \b:\t ipc \t [-0.01922516 -0.01922525 -0.01922525]\n",
      "25 \b:\t kappa1 \t [ 1.91913447 -0.12207164 -0.95788224]\n",
      "26 \b:\t kappa2 \t [ 1.87390305 -0.2456708  -0.91775003]\n",
      "27 \b:\t kappa3 \t [ 1.88104706 -0.44739161 -0.98678511]\n",
      "28 \b:\t labuteasa \t [ 1.92861571  0.04690599 -0.72822654]\n",
      "29 \b:\t paoe_0 \t [ 1.7715528  -1.06384524  0.09761968]\n",
      "30 \b:\t paoe_1 \t [ 1.57532802  1.82127068 -2.07120945]\n",
      "31 \b:\t paoe_2 \t [-0.13695413  0.47732132  0.01573759]\n",
      "32 \b:\t paoe_3 \t [-0.14671787  1.95577123  0.42694656]\n",
      "33 \b:\t paoe_4 \t [-0.02969803 -0.8198314   1.23168777]\n",
      "34 \b:\t paoe_5 \t [ 0.53363795 -0.39443345 -0.42896462]\n",
      "35 \b:\t paoe_6 \t [ 0.04218307  1.19519689 -0.01025929]\n",
      "36 \b:\t paoe_7 \t [ 2.39130787  1.4642419  -0.26943893]\n",
      "37 \b:\t paoe_8 \t [-1.10108457  1.12829391 -0.03790073]\n",
      "38 \b:\t smr_0 \t [ 2.3494224  -0.36872345 -0.7931771 ]\n",
      "39 \b:\t smr_1 \t [ 0.84729418 -0.17927662 -0.34441144]\n",
      "40 \b:\t smr_2 \t [0.90558858 0.71730896 0.08903048]\n",
      "41 \b:\t smr_3 \t [-0.57758111  1.71922476 -1.23408327]\n",
      "42 \b:\t slogp_0 \t [ 2.34317973 -0.19238882 -1.06083782]\n",
      "43 \b:\t slogp_1 \t [ 0.48454409 -0.39095267 -0.6095749 ]\n",
      "44 \b:\t slogp_2 \t [-0.17521691  0.49342969 -0.66728402]\n",
      "45 \b:\t slogp_3 \t [ 1.28267141 -2.31144628  1.03428237]\n",
      "46 \b:\t slogp_4 \t [0.06385772 1.84262372 1.2797733 ]\n",
      "47 \b:\t slogp_5 \t [ 0.08483765 -0.32767368  0.40323626]\n",
      "48 \b:\t tpsa \t [ 1.2501606  -0.30653067 -1.11606705]\n",
      "49 \b:\t estate_vsa_0 \t [ 0.59394763 -1.30948619 -0.80599062]\n",
      "50 \b:\t estate_vsa_1 \t [ 1.63009257  0.91865585 -0.80749988]\n",
      "51 \b:\t estate_vsa_2 \t [ 0.28357391  2.41729163 -0.73671368]\n",
      "52 \b:\t estate_vsa_3 \t [2.68278065 2.22507577 0.05200186]\n",
      "53 \b:\t estate_vsa_4 \t [-0.49342337 -1.13144319 -0.84380262]\n",
      "54 \b:\t estate_vsa_5 \t [-1.83034    -0.04888996 -0.88537305]\n",
      "55 \b:\t estate_vsa_6 \t [ 0.58401521  1.46321122 -0.51464791]\n",
      "56 \b:\t vsa_estate_0 \t [ 0.42276422 -0.1287576  -0.38442719]\n",
      "57 \b:\t vsa_estate_1 \t [ 1.30131507 -0.63381469 -0.96981614]\n",
      "58 \b:\t vsa_estate_2 \t [-0.42725676  0.317791   -0.27063666]\n",
      "59 \b:\t fractioncsp3 \t [ 1.79907176  0.14664095 -1.01949257]\n",
      "60 \b:\t heavyatomcount \t [ 1.77698155  0.11426325 -0.83586149]\n",
      "61 \b:\t nhohcount \t [ 0.58956448  0.58956448 -0.68073424]\n",
      "62 \b:\t nocount \t [ 1.3230271  -0.12658057 -1.21378633]\n",
      "63 \b:\t numaliphaticcarbocycles \t [ 2.49426594 -0.52172007 -0.52172007]\n",
      "64 \b:\t numaliphaticheterocycles \t [1.43572912 0.10754525 0.10754525]\n",
      "65 \b:\t numaliphaticrings \t [ 2.55668969 -0.24772125 -0.24772125]\n",
      "66 \b:\t numaromaticcarbocycles \t [-0.6783444  -0.6783444   0.54061178]\n",
      "67 \b:\t numaromaticheterocycles \t [-1.22685468  2.71174025  0.08601029]\n",
      "68 \b:\t numaromaticrings \t [-1.33342254  1.34955132  0.4552267 ]\n",
      "69 \b:\t numhacceptors \t [ 0.79090621 -0.12624794 -1.04340208]\n",
      "70 \b:\t numhdonors \t [ 0.68607865  0.68607865 -0.66911996]\n",
      "71 \b:\t numheteroatoms \t [ 1.37863436 -0.56300688 -0.88661375]\n",
      "72 \b:\t numrotatablebonds \t [ 1.46014819 -0.42158094 -1.22803628]\n",
      "73 \b:\t numsaturatedcarbocycles \t [ 2.74355908 -0.50306549 -0.50306549]\n",
      "74 \b:\t numsaturatedheterocycles \t [ 1.93455293  0.51817451 -0.89820391]\n",
      "75 \b:\t numsaturatedrings \t [ 2.88453723  0.05280617 -0.89110418]\n",
      "76 \b:\t ringcount \t [1.02512286 1.02512286 0.20108179]\n",
      "77 \b:\t mollogp \t [ 0.42279694 -1.50976599  0.96203042]\n",
      "78 \b:\t molmr \t [ 1.89356375  0.19369986 -0.70163143]\n",
      "79 \b:\t fr_0 \t [ 1.44263174 -0.95429867 -0.55803743]\n",
      "80 \b:\t fr_1 \t [-0.16649715 -1.17342811 -0.53915678]\n",
      "81 \b:\t fr_2 \t [ 0.10048759 -0.21746896  0.70765117]\n",
      "82 \b:\t fr_3 \t [ 0.27308047 -1.30120346 -0.48403785]\n",
      "83 \b:\t fr_4 \t [-0.67198613 -0.39193125  1.10729028]\n",
      "84 \b:\t fr_5 \t [-0.41927633  0.75862047  0.19625445]\n",
      "85 \b:\t fr_6 \t [-0.18861713  1.42095493 -0.45381476]\n",
      "86 \b:\t fr_7 \t [0.05433694 0.80557447 0.04596197]\n",
      "87 \b:\t fr_8 \t [-0.39468002 -0.20130347 -0.37106788]\n",
      "88 \b:\t fr_9 \t [-0.0991188   0.79935111  0.07799913]\n",
      "89 \b:\t fr_10 \t [ 0.15272125 -0.91387713 -0.46979395]\n",
      "90 \b:\t fr_11 \t [-0.16007092  0.62335832 -1.14311677]\n",
      "91 \b:\t fr_12 \t [-0.26588733  0.91860171 -0.57174036]\n",
      "92 \b:\t fr_13 \t [-0.5495537  -4.30726115 -0.37486007]\n",
      "93 \b:\t fr_14 \t [ 0.35791729  2.71423905 -0.05892239]\n",
      "94 \b:\t fr_15 \t [ 1.7689255   0.33653336 -0.03693436]\n"
     ]
    }
   ],
   "source": [
    "compoundsTrain, smilesTrain, labelsTrain, compoundDataTrain, activitiesTrain = Loader.getTrain(defaultValue=0)\n",
    "compoundsTest, smilesTest, labelsTest, compoundDataTest, activitiesTest = Loader.getTest(defaultValue=0)\n",
    "compoundsValidate, smilesValidate, labelsValidate, compoundDataValidate, activitiesValidate = Loader.getValidate(defaultValue=0)\n",
    "\n",
    "\n",
    "labelsPCA, trainPCA, testPCA, valPCA = Transformer.applyPCA(labelsTrain,  compoundDataTrain, \n",
    "                                                            compoundDataTest, compoundDataValidate,\n",
    "                                                            endDims=[1,1,9,4,6,7,3,16])\n",
    "\n",
    "labelsMeanPCA, trainMeanPCA = Transformer.useAverageFD(labelsPCA, trainPCA)\n",
    "_, testMeanPCA = Transformer.useAverageFD(labelsPCA, testPCA)\n",
    "_, valMeanPCA = Transformer.useAverageFD(labelsPCA, valPCA)\n",
    "\n",
    "labelsMaxPCA, trainMaxPCA = Transformer.useMaxFD(labelsPCA, trainPCA)\n",
    "_, testMaxPCA = Transformer.useMaxFD(labelsPCA, testPCA)\n",
    "_, valMaxPCA = Transformer.useMaxFD(labelsPCA, valPCA)\n",
    "\n",
    "#after transformations are done assign data\n",
    "dataLabels = labelsMaxPCA\n",
    "trainData = trainMaxPCA\n",
    "testData = testMaxPCA\n",
    "valData = valMaxPCA\n",
    "\n",
    "trainData, testData, valData = Transformer.normalizeData(trainData, testData, valData, newMean=0, newStd=1)\n",
    "\n",
    "print(np.shape(trainData))\n",
    "for i in range(len(dataLabels)):\n",
    "    print(i, \"\\b:\\t\", dataLabels[i], \"\\t\", trainData[0:3,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14325779",
   "metadata": {},
   "source": [
    "# Training on Fr data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cfcceee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "85/85 [==============================] - 1s 2ms/step - loss: 2.5404 - accuracy: 0.3890\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.7911 - accuracy: 0.4921\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.3597 - accuracy: 0.5127\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1017 - accuracy: 0.5171\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.9131 - accuracy: 0.5234\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7799 - accuracy: 0.5230\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5271\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.5278\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.5274\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.5348\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.5366\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.5385\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.5388\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.5436\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.5385\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.5455\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.5462\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.5451\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.5547\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.5506\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.5521\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.5517\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.5572\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3508 - accuracy: 0.5532\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.5539\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.5631\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.5628\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.5672\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.5661\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.5675\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.5650\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.5686\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2903 - accuracy: 0.5734\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2848 - accuracy: 0.5709\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2897 - accuracy: 0.5709\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2761 - accuracy: 0.5797\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2755 - accuracy: 0.5749\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.5789\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.5808\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.5801\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.5756\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.5786\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.5812\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.5797\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.5845\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2416 - accuracy: 0.5867\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2411 - accuracy: 0.5841\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2323 - accuracy: 0.5867\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.5881\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2414 - accuracy: 0.5823\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 0.5837\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2199 - accuracy: 0.5937\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2297 - accuracy: 0.5900\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2205 - accuracy: 0.5915\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2247 - accuracy: 0.5900\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2274 - accuracy: 0.5881\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.5948\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.5922\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.5893\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.5918\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.5962\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.5962\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.5915\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2136 - accuracy: 0.5951\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.5974\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.5966\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2036 - accuracy: 0.5974\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.5977\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2091 - accuracy: 0.5966\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2073 - accuracy: 0.5962\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.5988\n",
      "Epoch 72/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.6021\n",
      "Epoch 73/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.5966\n",
      "Epoch 74/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.5981\n",
      "Epoch 75/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.5981\n",
      "Epoch 76/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1927 - accuracy: 0.6003\n",
      "Epoch 77/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.5977\n",
      "Epoch 78/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.5977\n",
      "Epoch 79/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.5962\n",
      "Epoch 80/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2021 - accuracy: 0.5974\n",
      "Epoch 81/100\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 0.1893 - accuracy: 0.5999\n",
      "Epoch 82/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.1839 - accuracy: 0.6032\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.6018\n",
      "Epoch 84/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.6007\n",
      "Epoch 85/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.5996\n",
      "Epoch 86/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.5992\n",
      "Epoch 87/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.5999\n",
      "Epoch 88/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.6007\n",
      "Epoch 89/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1937 - accuracy: 0.5944\n",
      "Epoch 90/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.5996\n",
      "Epoch 91/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1875 - accuracy: 0.6007\n",
      "Epoch 92/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.6021\n",
      "Epoch 93/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.6010\n",
      "Epoch 94/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.5996\n",
      "Epoch 95/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.5988\n",
      "Epoch 96/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.6007\n",
      "Epoch 97/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2174 - accuracy: 0.5904\n",
      "Epoch 98/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.5977\n",
      "Epoch 99/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.5988\n",
      "Epoch 100/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.6032\n"
     ]
    }
   ],
   "source": [
    "dataX = np.array(trainData)[:,79:len(trainData)]\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(200, input_dim=np.shape(dataX)[1], activation='relu', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model1.add(Dense(100, activation='relu', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model1.add(Dense(100, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model1.add(Dense(1, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "\n",
    "model1.compile(loss='MeanSquaredError', optimizer=\"adam\", metrics=['accuracy'])\n",
    "history = model1.fit(dataX, toClassification(activitiesTrain),epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1fa93b",
   "metadata": {},
   "source": [
    "# Training on Structure Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "149c1c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "85/85 [==============================] - 1s 2ms/step - loss: 2.6477 - accuracy: 0.3198\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.9294 - accuracy: 0.4188\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5379 - accuracy: 0.4284\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.2741 - accuracy: 0.4457\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1011 - accuracy: 0.4479\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.9612 - accuracy: 0.4575\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.8719 - accuracy: 0.4626\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7876 - accuracy: 0.4682\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7347 - accuracy: 0.4663\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.4744\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.4748\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.4847\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6029 - accuracy: 0.4899\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.4906\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.4910\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.4895\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.4972\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.5031\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.5072\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.5068\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.5064\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.5035\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.5175\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.5142\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.5134\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.5075\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.5142\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.5179\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.5167\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.5142\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.5271\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.5237\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.5241\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.5307\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.5278\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.5307\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.5274\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.5326\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.5329\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.5271\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.5377\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.5392\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.3770 - accuracy: 0.5444\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.3692 - accuracy: 0.5432\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.5466\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.5414\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.5429\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.5473\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3489 - accuracy: 0.5491\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.5466\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.5528\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3485 - accuracy: 0.5462\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.5477\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.5491\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.5491\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3485 - accuracy: 0.5517\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.5576\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.5473\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.5521\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.5591\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.5565\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.5521\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.5558\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.5602\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.5569\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.5609\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.5616\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.5642\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.5646\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.5536\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.5602\n",
      "Epoch 72/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.5624\n",
      "Epoch 73/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.5583\n",
      "Epoch 74/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2992 - accuracy: 0.5653\n",
      "Epoch 75/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.5521\n",
      "Epoch 76/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2959 - accuracy: 0.5679\n",
      "Epoch 77/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.5635\n",
      "Epoch 78/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.5598\n",
      "Epoch 79/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3166 - accuracy: 0.5609\n",
      "Epoch 80/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2990 - accuracy: 0.5646\n",
      "Epoch 81/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2832 - accuracy: 0.5675\n",
      "Epoch 82/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2805 - accuracy: 0.5690\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2969 - accuracy: 0.5668\n",
      "Epoch 84/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2821 - accuracy: 0.5705\n",
      "Epoch 85/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.5686\n",
      "Epoch 86/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.5709\n",
      "Epoch 87/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2745 - accuracy: 0.5720\n",
      "Epoch 88/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.5690\n",
      "Epoch 89/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2840 - accuracy: 0.5734\n",
      "Epoch 90/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2931 - accuracy: 0.5675\n",
      "Epoch 91/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2805 - accuracy: 0.5675\n",
      "Epoch 92/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.5675\n",
      "Epoch 93/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2760 - accuracy: 0.5701\n",
      "Epoch 94/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.5738\n",
      "Epoch 95/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2758 - accuracy: 0.5672\n",
      "Epoch 96/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2649 - accuracy: 0.5778\n",
      "Epoch 97/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.5723\n",
      "Epoch 98/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.5716\n",
      "Epoch 99/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2745 - accuracy: 0.5701\n",
      "Epoch 100/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2789 - accuracy: 0.5731\n"
     ]
    }
   ],
   "source": [
    "dataX = np.array(trainData)[:,59:79]\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(200, input_dim=np.shape(dataX)[1], activation='relu', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model2.add(Dense(100, activation='relu', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model2.add(Dense(100, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model2.add(Dense(1, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "\n",
    "model2.compile(loss='MeanSquaredError', optimizer=\"adam\", metrics=['accuracy'])\n",
    "history = model2.fit(dataX, toClassification(activitiesTrain),epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e22e09",
   "metadata": {},
   "source": [
    "# Training on TPSA, VSA ESTATE and ESTATE VSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba9c8f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-77cc73b5d4f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m59\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "dataX = np.array(trainData)[:,48:59]\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(200, input_dim=np.shape(dataX)[1], activation='relu', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model3.add(Dense(100, activation='relu', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model3.add(Dense(100, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model3.add(Dense(1, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "\n",
    "model3.compile(loss='MeanSquaredError', optimizer=\"adam\", metrics=['accuracy'])\n",
    "history = model3.fit(dataX, toClassification(activitiesTrain),epochs=200, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c0e7cf",
   "metadata": {},
   "source": [
    "# Training on Slogp, SMR, and PAOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5db0ece1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "85/85 [==============================] - 1s 2ms/step - loss: 2.5360 - accuracy: 0.3993\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.8129 - accuracy: 0.4799\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.3916 - accuracy: 0.4906\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1047 - accuracy: 0.5013\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.9185 - accuracy: 0.5050\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7782 - accuracy: 0.5094\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.5116\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.5219\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.5153\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.5282\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.5304\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.5278\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.5359\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.5432\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.5399\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.5451\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.5488\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.5473\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.5488\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.5510\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.5628\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.5613\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.5628\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.3006 - accuracy: 0.5697\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2899 - accuracy: 0.5705\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2866 - accuracy: 0.5694\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2764 - accuracy: 0.5701\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2909 - accuracy: 0.5653\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2809 - accuracy: 0.5690\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2732 - accuracy: 0.5742\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2685 - accuracy: 0.5727\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.5819\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.5830\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2533 - accuracy: 0.5815\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2553 - accuracy: 0.5793\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2436 - accuracy: 0.5848\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2347 - accuracy: 0.5874\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2258 - accuracy: 0.5918\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2323 - accuracy: 0.5870\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2328 - accuracy: 0.5911\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2413 - accuracy: 0.5819\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.5859\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.5900\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2126 - accuracy: 0.5962\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2170 - accuracy: 0.5933\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2148 - accuracy: 0.5948\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2244 - accuracy: 0.5878\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.5896\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.5940\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.5933\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.5999\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.5985\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.5992\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1951 - accuracy: 0.5992\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.5951\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1875 - accuracy: 0.6032\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.5996\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.5992\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.5985\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.5951\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2099 - accuracy: 0.5900\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2008 - accuracy: 0.5944\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.6018\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.6021\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.6043\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.5999\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.5992\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2075 - accuracy: 0.5926\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1989 - accuracy: 0.5959\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.6014\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.6007\n",
      "Epoch 72/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.6010\n",
      "Epoch 73/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1708 - accuracy: 0.6047\n",
      "Epoch 74/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1682 - accuracy: 0.6040\n",
      "Epoch 75/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1693 - accuracy: 0.6066\n",
      "Epoch 76/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1635 - accuracy: 0.6062\n",
      "Epoch 77/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1607 - accuracy: 0.6080\n",
      "Epoch 78/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.6040\n",
      "Epoch 79/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.6036\n",
      "Epoch 80/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1588 - accuracy: 0.6062\n",
      "Epoch 81/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1594 - accuracy: 0.6088\n",
      "Epoch 82/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.5996\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.5977\n",
      "Epoch 84/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1715 - accuracy: 0.6014\n",
      "Epoch 85/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1662 - accuracy: 0.6040\n",
      "Epoch 86/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1670 - accuracy: 0.6025\n",
      "Epoch 87/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1637 - accuracy: 0.6062\n",
      "Epoch 88/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1587 - accuracy: 0.6066\n",
      "Epoch 89/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1592 - accuracy: 0.6069\n",
      "Epoch 90/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1484 - accuracy: 0.6113\n",
      "Epoch 91/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.6110\n",
      "Epoch 92/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1407 - accuracy: 0.6132\n",
      "Epoch 93/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.6117\n",
      "Epoch 94/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1394 - accuracy: 0.6139\n",
      "Epoch 95/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1364 - accuracy: 0.6124\n",
      "Epoch 96/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.6117\n",
      "Epoch 97/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1346 - accuracy: 0.6143\n",
      "Epoch 98/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1375 - accuracy: 0.6121\n",
      "Epoch 99/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.5977\n",
      "Epoch 100/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.5962\n"
     ]
    }
   ],
   "source": [
    "dataX = np.array(trainData)[:,29:48]\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(200, input_dim=np.shape(dataX)[1], activation='relu', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model4.add(Dense(100, activation='relu', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model4.add(Dense(100, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model4.add(Dense(1, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "\n",
    "model4.compile(loss='MeanSquaredError', optimizer=\"adam\", metrics=['accuracy'])\n",
    "history = model4.fit(dataX, toClassification(activitiesTrain),epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f47d21b",
   "metadata": {},
   "source": [
    "# Training on the remaining Compound Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ddc95aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "85/85 [==============================] - 1s 2ms/step - loss: 2.6314 - accuracy: 0.3909\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.9729 - accuracy: 0.4479\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5700 - accuracy: 0.4619\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.2946 - accuracy: 0.4737\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1142 - accuracy: 0.4799\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.9671 - accuracy: 0.4825\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.8723 - accuracy: 0.4851\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7988 - accuracy: 0.4917\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.7280 - accuracy: 0.4943\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6700 - accuracy: 0.4987\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6346 - accuracy: 0.4965\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.4947\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.5064\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.5035\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.5072\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.5145\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.5134\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.5212\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.5278\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.5193\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.5248\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.5267\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.5248\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.5271\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.5241\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.5333\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.5370\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.5388\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.5392\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.5425\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.5480\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.5447\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.5447\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.5506\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.3575 - accuracy: 0.5499\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.3678 - accuracy: 0.5480\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.5477\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.5528\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.5554\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.5506\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.5550\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.5576\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.5616\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.5591\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.3245 - accuracy: 0.5572\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.5620\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.5679\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.5683\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.3018 - accuracy: 0.5690\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.5675\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.5653\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.5653\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.5668\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.3055 - accuracy: 0.5661\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2918 - accuracy: 0.5657\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.3035 - accuracy: 0.5653\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2934 - accuracy: 0.5734\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.5705\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 0.5716\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.5749\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.5786\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.5742\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.5782\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2683 - accuracy: 0.5767\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.5775\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2579 - accuracy: 0.5782\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2583 - accuracy: 0.5823\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2639 - accuracy: 0.5808\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2616 - accuracy: 0.5775\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2568 - accuracy: 0.5775\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.5845\n",
      "Epoch 72/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2525 - accuracy: 0.5837\n",
      "Epoch 73/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2619 - accuracy: 0.5801\n",
      "Epoch 74/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.5797\n",
      "Epoch 75/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2511 - accuracy: 0.5819\n",
      "Epoch 76/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2442 - accuracy: 0.5859\n",
      "Epoch 77/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2662 - accuracy: 0.5826\n",
      "Epoch 78/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2417 - accuracy: 0.5848\n",
      "Epoch 79/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2511 - accuracy: 0.5848\n",
      "Epoch 80/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2380 - accuracy: 0.5874\n",
      "Epoch 81/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2531 - accuracy: 0.5830\n",
      "Epoch 82/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2326 - accuracy: 0.5881\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.5845\n",
      "Epoch 84/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.5863\n",
      "Epoch 85/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.5951\n",
      "Epoch 86/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2281 - accuracy: 0.5918\n",
      "Epoch 87/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2326 - accuracy: 0.5863\n",
      "Epoch 88/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2379 - accuracy: 0.5867\n",
      "Epoch 89/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2575 - accuracy: 0.5819\n",
      "Epoch 90/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2359 - accuracy: 0.5881\n",
      "Epoch 91/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.5830\n",
      "Epoch 92/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2271 - accuracy: 0.5911\n",
      "Epoch 93/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2128 - accuracy: 0.5929\n",
      "Epoch 94/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2172 - accuracy: 0.5948\n",
      "Epoch 95/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2125 - accuracy: 0.5962\n",
      "Epoch 96/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2193 - accuracy: 0.5911\n",
      "Epoch 97/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2093 - accuracy: 0.5948\n",
      "Epoch 98/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.5878\n",
      "Epoch 99/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.5915\n",
      "Epoch 100/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.2210 - accuracy: 0.5889\n"
     ]
    }
   ],
   "source": [
    "dataX = np.array(trainData)[:,:29]\n",
    "\n",
    "model5 = Sequential()\n",
    "model5.add(Dense(200, input_dim=np.shape(dataX)[1], activation='relu', kernel_regularizer = keras.regularizers.L2(0.001)))\n",
    "model5.add(Dense(100, activation='relu', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model5.add(Dense(100, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "model5.add(Dense(1, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.001)))\n",
    "\n",
    "model5.compile(loss='MeanSquaredError', optimizer=\"adam\", metrics=['accuracy'])\n",
    "history = model5.fit(dataX, toClassification(activitiesTrain),epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d6dc8b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 978us/step\n",
      "[[-1. -1. -1. ... -1. -1. -1.]\n",
      " [ 1.  1.  1. ...  1.  1.  1.]\n",
      " [ 1.  1.  1. ...  1.  1.  1.]\n",
      " ...\n",
      " [-1. -1. -1. ... -1. -1. -1.]\n",
      " [-1. -1. -1. ... -1. -1. -1.]\n",
      " [ 1.  1.  1. ...  1.  1.  1.]]\n",
      "0.5216955017301038\n"
     ]
    }
   ],
   "source": [
    "dataInds = [[79,len(trainData)],[59,79],[48,59],[29,48],[0,29]]\n",
    "yAgg = takeVote([model1,model2,model3,model4,model5], valData, toClassification(activitiesValidate), False, dataInds)\n",
    "print(yAgg)\n",
    "print(np.mean(toClassification(activitiesValidate) == yAgg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8568036d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 1ms/step\n",
      "0.5256401384083045\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "0.5256401384083045\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "0.5322145328719723\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "0.5282698961937716\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "0.5249826989619377\n"
     ]
    }
   ],
   "source": [
    "valData = np.array(valData)\n",
    "print(np.mean(toClassification(activitiesValidate) == np.sign(model1.predict(valData[:,79:]))))\n",
    "print(np.mean(toClassification(activitiesValidate) == np.sign(model2.predict(valData[:,59:79]))))\n",
    "print(np.mean(toClassification(activitiesValidate) == np.sign(model3.predict(valData[:,48:59]))))\n",
    "print(np.mean(toClassification(activitiesValidate) == np.sign(model4.predict(valData[:,29:48]))))\n",
    "print(np.mean(toClassification(activitiesValidate) == np.sign(model5.predict(valData[:,0:29]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4704e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
