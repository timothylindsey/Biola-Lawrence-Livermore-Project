{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "satellite-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Loader\n",
    "import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "global-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "#note loading data also shuffles order of the data\n",
    "compoundsTrain, smilesTrain, labelsTrain, compoundDataTrain, activitiesTrain = Loader.getTrain(defaultValue=0)\n",
    "compoundsTest, smilesTest, labelsTest, compoundDataTest, activitiesTest = Loader.getTest(defaultValue=0)\n",
    "compoundsValidate, smilesValidate, labelsValidate, compoundDataValidate, activitiesValidate = Loader.getValidate(defaultValue=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-burden",
   "metadata": {},
   "source": [
    "### Notes on Principal Component Analysis\n",
    "\n",
    "Does it make sense to run PCA on like-type parts of the data?\n",
    "As there are clearly different \"sets\" of the data per row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "decimal-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(labelsTrain)):\n",
    "#    print(i, '\\b:\\t', labelsTrain[i], compoundDataTrain[35:40, i])\n",
    "    \n",
    "#for all the following ranges begin is inclusive and end is not inclusive\n",
    "#[0:10] docking_score_? (0-9)\n",
    "#[10:20] fusion_score_? (0-9)\n",
    "#[37:45] bcut2d_? (8 in total)\n",
    "#[47:59] chi? (12, odd labels)\n",
    "#[65:79] paoe_vsa? (1-14)\n",
    "#[79:89] smr_vsa? (1-10)\n",
    "#[89:101] slogp_vsa? (1-12)\n",
    "#[102:113] estate_vsa? (1-11)\n",
    "#[113:123] vsa_estate? (1-10)\n",
    "#[143:228] fr_some_chemical? (85 total)\n",
    "\n",
    "#print(labelsTrain[0:10],\"\\n\")\n",
    "#print(labelsTrain[10:20],\"\\n\")\n",
    "#print(labelsTrain[37:45],\"\\n\")\n",
    "#print(labelsTrain[47:59],\"\\n\")\n",
    "#print(labelsTrain[65:79],\"\\n\")\n",
    "#print(labelsTrain[79:89],\"\\n\")\n",
    "#print(labelsTrain[89:101],\"\\n\")\n",
    "#print(labelsTrain[102:113],\"\\n\")\n",
    "#print(labelsTrain[113:123],\"\\n\")\n",
    "#print(labelsTrain[143:228],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-dinner",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "PCA, modify fusion/docking, normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-thermal",
   "metadata": {},
   "source": [
    "### Apply Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "expressed-involvement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bcut2d retention: [0.99364773]\n",
      "\ttotal: 99.36477273412319%\n",
      "chi retention: [0.9541968]\n",
      "\ttotal: 95.4196796859789%\n",
      "paoe retention: [0.31495127 0.19509321 0.1390042  0.08838179]\n",
      "\ttotal: 73.74304791821308%\n",
      "smr retention: [0.50634726 0.24568468 0.08792319 0.07435827]\n",
      "\ttotal: 91.43133907840053%\n",
      "slogp retention: [0.44620276 0.22134465 0.15753302]\n",
      "\ttotal: 82.50804204396218%\n",
      "estate_vsa retention: [0.29224011 0.18964809 0.14361318]\n",
      "\ttotal: 62.55013868306436%\n",
      "vsa_estate retention: [0.49255304 0.32866098 0.09719245]\n",
      "\ttotal: 91.84064669216812%\n",
      "fr retention: [0.32153498 0.12578177 0.09944384]\n",
      "\ttotal: 54.67605936050468%\n",
      "PCA done, new dimensions: 88\n"
     ]
    }
   ],
   "source": [
    "#reduce dimension through PCA\n",
    "#in order endDims sections are chi, paoe, smr, slogp, estate_vsa, vsa_estate, fr\n",
    "labelsPCA, trainPCA, testPCA, valPCA = Transformer.applyPCA(labelsTrain,  compoundDataTrain, \n",
    "                                                            compoundDataTest, compoundDataValidate,\n",
    "                                                            endDims=[1,1,4,4,3,3,3,3])\n",
    "print(\"PCA done, new dimensions:\", len(labelsPCA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-joining",
   "metadata": {},
   "source": [
    "### Use either mean or max magnitude of docking and fusion\n",
    "\n",
    "Actually quite similar e.g. for the first 3 rows:\n",
    "\n",
    "fusion max:  $[5.3211, 5.3258, 5.3936]$\n",
    "\n",
    "fusion avg:  $[5.0530, 5.2303, 5.1805]$\n",
    "\n",
    "docking max: $[6.7, 7.2, 7.3]$\n",
    "\n",
    "docking avg: $[-6.51, -6.92, -7.18]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "advised-warrant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Fusion and Docking, new dimensions:  70\n"
     ]
    }
   ],
   "source": [
    "#use mean of the docking and fusion\n",
    "labelsMeanPCA, trainMeanPCA = Transformer.useAverageFD(labelsPCA, trainPCA)\n",
    "_, testMeanPCA = Transformer.useAverageFD(labelsPCA, testPCA)\n",
    "_, valMeanPCA = Transformer.useAverageFD(labelsPCA, valPCA)\n",
    "print(\"Mean of Fusion and Docking, new dimensions: \", len(labelsMeanPCA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acknowledged-header",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max of Fusion and Docking, new dimensions:  70\n"
     ]
    }
   ],
   "source": [
    "#use max magnitude of the docking and fusion\n",
    "labelsMaxPCA, trainMaxPCA = Transformer.useMaxFD(labelsPCA, trainPCA)\n",
    "_, testMaxPCA = Transformer.useMaxFD(labelsPCA, testPCA)\n",
    "_, valMaxPCA = Transformer.useMaxFD(labelsPCA, valPCA)\n",
    "print(\"Max of Fusion and Docking, new dimensions: \", len(labelsMeanPCA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-brave",
   "metadata": {},
   "source": [
    "### Assign final data and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "neutral-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after transformations are done assign data\n",
    "dataLabels = labelsMeanPCA\n",
    "trainData = trainMeanPCA\n",
    "testData = testMeanPCA\n",
    "valData = valMeanPCA\n",
    "\n",
    "trainData, testData, valData = Transformer.normalizeData(trainData, testData, valData, newMean=0, newStd=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-sight",
   "metadata": {},
   "source": [
    "## See modified labels and example data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "local-appraisal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2717, 70)\n",
      "0 \b:\t docking_score_average \t [-0.62594294 -1.31017257  0.05828669]\n",
      "1 \b:\t fusion_score_average \t [-1.7705222   0.71250749  0.44915279]\n",
      "2 \b:\t maxestateindex \t [0.15872059 0.56272994 0.15117699]\n",
      "3 \b:\t minestateindex \t [-1.00952972  0.28822883  0.81669587]\n",
      "4 \b:\t maxabsestateindex \t [0.15872059 0.56272994 0.15117699]\n",
      "5 \b:\t minabsestateindex \t [ 0.10009438 -0.75095761 -0.07528566]\n",
      "6 \b:\t qed \t [ 0.17343876 -0.64263598  0.90556025]\n",
      "7 \b:\t molwt \t [ 0.23196364  0.64695605 -0.34387461]\n",
      "8 \b:\t heavyatommolwt \t [ 0.22836806  0.60940443 -0.38919743]\n",
      "9 \b:\t exactmolwt \t [ 0.2338092   0.64928841 -0.34162785]\n",
      "10 \b:\t numvalenceelectrons \t [ 0.24205523  0.80078172 -0.18773438]\n",
      "11 \b:\t numradicalelectrons \t [0. 0. 0.]\n",
      "12 \b:\t maxpartialcharge \t [-0.01918824 -0.01918824 -0.01918824]\n",
      "13 \b:\t minpartialcharge \t [-0.90218411  0.74529048 -0.90225003]\n",
      "14 \b:\t maxabspartialcharge \t [-0.01918824 -0.01918824 -0.01918824]\n",
      "15 \b:\t minabspartialcharge \t [-0.53409545  0.06934049  0.59814444]\n",
      "16 \b:\t fpdensitymorgan1 \t [-0.15923105 -0.07400337 -1.06779572]\n",
      "17 \b:\t fpdensitymorgan2 \t [-0.11396133  0.20008303 -0.46067125]\n",
      "18 \b:\t fpdensitymorgan3 \t [0.00035242 0.19327615 0.06103005]\n",
      "19 \b:\t bcut2d_0 \t [ 0.2837219  -1.12372233 -1.10076888]\n",
      "20 \b:\t balabanj \t [-0.39716609 -1.01839338 -0.68153092]\n",
      "21 \b:\t bertzct \t [0.46528748 0.73118418 0.04401268]\n",
      "22 \b:\t chi_0 \t [ 0.25856784  0.8970233  -0.08839832]\n",
      "23 \b:\t hallkieralpha \t [-0.27660044 -0.67303763 -0.21400509]\n",
      "24 \b:\t ipc \t [-0.01922525 -0.01922524 -0.01922525]\n",
      "25 \b:\t kappa1 \t [ 0.17567958  0.43432041 -0.43722637]\n",
      "26 \b:\t kappa2 \t [ 0.23326731  0.07946757 -0.43690834]\n",
      "27 \b:\t kappa3 \t [ 0.0027753   0.01556397 -0.66602482]\n",
      "28 \b:\t labuteasa \t [ 0.18593244  0.75748262 -0.14405919]\n",
      "29 \b:\t paoe_0 \t [0.21004881 0.09278744 0.06973013]\n",
      "30 \b:\t paoe_1 \t [0.13385797 2.73820792 0.65121034]\n",
      "31 \b:\t paoe_2 \t [ 0.6485932  -0.24769018 -0.71801606]\n",
      "32 \b:\t paoe_3 \t [-0.61249672 -0.42857554 -0.57054934]\n",
      "33 \b:\t smr_0 \t [ 0.30647925  1.38905862 -0.94649283]\n",
      "34 \b:\t smr_1 \t [-0.31034244  0.06771858 -0.85129261]\n",
      "35 \b:\t smr_2 \t [-0.03391326  0.26494779  2.24412951]\n",
      "36 \b:\t smr_3 \t [ 1.09718635 -0.76060789  1.67419074]\n",
      "37 \b:\t slogp_0 \t [ 0.17181845  1.60488998 -0.63632213]\n",
      "38 \b:\t slogp_1 \t [ 0.11845999 -0.09836835 -0.12417833]\n",
      "39 \b:\t slogp_2 \t [ 0.8406107  -0.02469311  1.56831641]\n",
      "40 \b:\t tpsa \t [ 0.49897345  1.00087178 -1.19125693]\n",
      "41 \b:\t estate_vsa_0 \t [-0.36609208  0.18042939 -1.26132961]\n",
      "42 \b:\t estate_vsa_1 \t [0.47524849 1.507699   0.22984479]\n",
      "43 \b:\t estate_vsa_2 \t [0.94830906 0.37489298 2.48649424]\n",
      "44 \b:\t vsa_estate_0 \t [ 0.88847115 -1.14618157 -0.42660511]\n",
      "45 \b:\t vsa_estate_1 \t [-0.72550792  1.94575513 -0.85209776]\n",
      "46 \b:\t vsa_estate_2 \t [ 0.67410742 -0.51803657 -0.35746175]\n",
      "47 \b:\t fractioncsp3 \t [ 0.18104551  1.00616178 -0.1857071 ]\n",
      "48 \b:\t heavyatomcount \t [ 0.23302885  0.82685681 -0.12326793]\n",
      "49 \b:\t nhohcount \t [-0.68073424  1.22471384 -0.68073424]\n",
      "50 \b:\t nocount \t [ 0.96062518  0.96062518 -0.48898249]\n",
      "51 \b:\t numaliphaticcarbocycles \t [-0.52172007  2.49426594 -0.52172007]\n",
      "52 \b:\t numaliphaticheterocycles \t [0.10754525 1.43572912 1.43572912]\n",
      "53 \b:\t numaliphaticrings \t [-0.24772125  2.55668969  0.6870824 ]\n",
      "54 \b:\t numaromaticcarbocycles \t [ 0.54061178 -0.6783444   1.75956795]\n",
      "55 \b:\t numaromaticheterocycles \t [ 0.08601029  0.08601029 -1.22685468]\n",
      "56 \b:\t numaromaticrings \t [ 0.4552267  -0.43909792  0.4552267 ]\n",
      "57 \b:\t numhacceptors \t [ 1.24948328 -0.12624794 -0.58482501]\n",
      "58 \b:\t numhdonors \t [-0.66911996  1.36367795 -0.66911996]\n",
      "59 \b:\t numheteroatoms \t [ 0.73142062  0.40781374 -0.88661375]\n",
      "60 \b:\t numrotatablebonds \t [ 0.11605596  0.38487441 -0.95921783]\n",
      "61 \b:\t numsaturatedcarbocycles \t [-0.50306549  2.74355908 -0.50306549]\n",
      "62 \b:\t numsaturatedheterocycles \t [0.51817451 1.93455293 0.51817451]\n",
      "63 \b:\t numsaturatedrings \t [0.05280617 2.88453723 0.05280617]\n",
      "64 \b:\t ringcount \t [0.20108179 1.84916394 1.02512286]\n",
      "65 \b:\t mollogp \t [-0.31100087 -0.9753314   0.46606841]\n",
      "66 \b:\t molmr \t [0.19675372 0.71808762 0.19278998]\n",
      "67 \b:\t fr_0 \t [-1.11503381  2.02507125 -0.63344038]\n",
      "68 \b:\t fr_1 \t [ 1.33724792  0.43552053 -0.31293128]\n",
      "69 \b:\t fr_2 \t [-1.6141909  -0.94310857 -0.6695615 ]\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(trainData))\n",
    "for i in range(len(dataLabels)):\n",
    "    print(i, \"\\b:\\t\", dataLabels[i], \"\\t\", trainData[0:3,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-proceeding",
   "metadata": {},
   "source": [
    "# Apply NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "noble-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dangerous-georgia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6198012513801987\n"
     ]
    }
   ],
   "source": [
    "#note the constant guess:\n",
    "classify = Transformer.toClassification(activitiesTrain)\n",
    "constantGuess = (len(classify[classify == 1]))/len(classify)\n",
    "print(constantGuess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "filled-cologne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1600\n",
      "680/680 [==============================] - 3s 3ms/step - loss: 0.7546 - accuracy: 0.1152 - val_loss: 0.6271 - val_accuracy: 0.2647\n",
      "Epoch 2/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.5799 - accuracy: 0.3154 - val_loss: 0.5583 - val_accuracy: 0.3765\n",
      "Epoch 3/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.5213 - accuracy: 0.3901 - val_loss: 0.5263 - val_accuracy: 0.3941\n",
      "Epoch 4/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.4883 - accuracy: 0.4100 - val_loss: 0.5048 - val_accuracy: 0.4059\n",
      "Epoch 5/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.4655 - accuracy: 0.4236 - val_loss: 0.4895 - val_accuracy: 0.4118\n",
      "Epoch 6/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.4480 - accuracy: 0.4332 - val_loss: 0.4780 - val_accuracy: 0.4147\n",
      "Epoch 7/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.4335 - accuracy: 0.4376 - val_loss: 0.4670 - val_accuracy: 0.4176\n",
      "Epoch 8/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.4215 - accuracy: 0.4417 - val_loss: 0.4576 - val_accuracy: 0.4235\n",
      "Epoch 9/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.4112 - accuracy: 0.4479 - val_loss: 0.4497 - val_accuracy: 0.4324\n",
      "Epoch 10/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.4023 - accuracy: 0.4619 - val_loss: 0.4432 - val_accuracy: 0.4324\n",
      "Epoch 11/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3947 - accuracy: 0.4623 - val_loss: 0.4371 - val_accuracy: 0.4353\n",
      "Epoch 12/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3879 - accuracy: 0.4641 - val_loss: 0.4316 - val_accuracy: 0.4529\n",
      "Epoch 13/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3819 - accuracy: 0.4671 - val_loss: 0.4268 - val_accuracy: 0.4529\n",
      "Epoch 14/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3763 - accuracy: 0.4693 - val_loss: 0.4226 - val_accuracy: 0.4588\n",
      "Epoch 15/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3715 - accuracy: 0.4733 - val_loss: 0.4186 - val_accuracy: 0.4588\n",
      "Epoch 16/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3669 - accuracy: 0.4733 - val_loss: 0.4151 - val_accuracy: 0.4618\n",
      "Epoch 17/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3627 - accuracy: 0.4763 - val_loss: 0.4118 - val_accuracy: 0.4647\n",
      "Epoch 18/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3588 - accuracy: 0.4807 - val_loss: 0.4088 - val_accuracy: 0.4647\n",
      "Epoch 19/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3551 - accuracy: 0.4807 - val_loss: 0.4062 - val_accuracy: 0.4647\n",
      "Epoch 20/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3517 - accuracy: 0.4833 - val_loss: 0.4040 - val_accuracy: 0.4647\n",
      "Epoch 21/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3485 - accuracy: 0.4862 - val_loss: 0.4018 - val_accuracy: 0.4676\n",
      "Epoch 22/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.4877 - val_loss: 0.3995 - val_accuracy: 0.4676\n",
      "Epoch 23/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3427 - accuracy: 0.4873 - val_loss: 0.3977 - val_accuracy: 0.4676\n",
      "Epoch 24/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3400 - accuracy: 0.4888 - val_loss: 0.3959 - val_accuracy: 0.4676\n",
      "Epoch 25/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3375 - accuracy: 0.4895 - val_loss: 0.3945 - val_accuracy: 0.4676\n",
      "Epoch 26/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3351 - accuracy: 0.4917 - val_loss: 0.3930 - val_accuracy: 0.4676\n",
      "Epoch 27/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3326 - accuracy: 0.4928 - val_loss: 0.3915 - val_accuracy: 0.4706\n",
      "Epoch 28/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3304 - accuracy: 0.4939 - val_loss: 0.3902 - val_accuracy: 0.4706\n",
      "Epoch 29/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3282 - accuracy: 0.4954 - val_loss: 0.3887 - val_accuracy: 0.4706\n",
      "Epoch 30/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3261 - accuracy: 0.4969 - val_loss: 0.3874 - val_accuracy: 0.4706\n",
      "Epoch 31/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3242 - accuracy: 0.4947 - val_loss: 0.3863 - val_accuracy: 0.4765\n",
      "Epoch 32/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3223 - accuracy: 0.4965 - val_loss: 0.3855 - val_accuracy: 0.4794\n",
      "Epoch 33/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3204 - accuracy: 0.4976 - val_loss: 0.3844 - val_accuracy: 0.4824\n",
      "Epoch 34/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3186 - accuracy: 0.4972 - val_loss: 0.3835 - val_accuracy: 0.4853\n",
      "Epoch 35/1600\n",
      "680/680 [==============================] - 1s 2ms/step - loss: 0.3165 - accuracy: 0.5009 - val_loss: 0.3824 - val_accuracy: 0.4794\n",
      "Epoch 36/1600\n",
      "168/680 [======>.......................] - ETA: 0s - loss: 0.3398 - accuracy: 0.4658"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-bbce5669408b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'MeanSquaredError'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m history = model.fit(trainData, Transformer.toClassification(activitiesTrain), \n\u001b[0m\u001b[0;32m     23\u001b[0m                     validation_data = (valData, classVal), epochs=1600, batch_size=4)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2494\u001b[0m       (graph_function,\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2497\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1863\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classTrain = Transformer.toClassification(activitiesTrain)\n",
    "classVal = Transformer.toClassification(activitiesValidate)\n",
    "\n",
    "\n",
    "tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False\n",
    ")\n",
    "l1Reg = 0\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(len(10), input_dim=len(), activation='relu', \n",
    "                kernel_regularizer = keras.regularizers.L2(l1Reg)))\n",
    "model.add(Dense(50, activation='relu', kernel_regularizer = keras.regularizers.L1(l1Reg)))\n",
    "model.add(Dense(20, activation='relu', kernel_regularizer = keras.regularizers.L1(l1Reg)))\n",
    "model.add(Dense(1, activation='tanh', kernel_regularizer = keras.regularizers.L1(l1Reg)))\n",
    "\n",
    "model.compile(loss='MeanSquaredError', optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model.fit(trainData, Transformer.toClassification(activitiesTrain), \n",
    "                    validation_data = (valData, classVal), epochs=1600, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "heard-profile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x24ebc8453d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "classify = Transformer.toClassification(activitiesTrain)\n",
    "constantGuess = (len(classify[classify == 1]))/len(classify)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,8))\n",
    "\n",
    "ax.plot(history.history[\"accuracy\"], color=\"green\")\n",
    "ax.plot(history.history[\"val_accuracy\"], color=\"purple\")\n",
    "ax.axhline(constantGuess, color=\"blue\", linestyle=\"dashed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "vocational-caribbean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2717\n",
      "1684\n",
      "1033\n"
     ]
    }
   ],
   "source": [
    "classData = Transformer.toClassification(activitiesTrain)\n",
    "print(len(trainData))\n",
    "print(len(classData[classData == 1]))\n",
    "print(len(classData[classData != 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
